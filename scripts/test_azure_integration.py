#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Azure OpenAI é›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯• Azure OpenAI åœ¨æ ‡ä¹¦ç³»ç»Ÿä¸­çš„é›†æˆæƒ…å†µ
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from ai_tender_system.common import create_llm_client, get_available_models


def test_azure_models_available():
    """æµ‹è¯• Azure æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ£€æŸ¥ Azure æ¨¡å‹é…ç½®")
    print("=" * 60)

    models = get_available_models()
    azure_models = [m for m in models if m['provider'] == 'Azure OpenAI']

    print(f"\næ‰¾åˆ° {len(azure_models)} ä¸ª Azure æ¨¡å‹:")
    for model in azure_models:
        print(f"  - {model['name']}: {model['display_name']}")
        print(f"    æè¿°: {model['description']}")
        print(f"    é…ç½®çŠ¶æ€: {'âœ“ å·²é…ç½®' if model['has_api_key'] else 'âœ— æœªé…ç½®'}")

    return len(azure_models) > 0


def test_azure_client_creation():
    """æµ‹è¯• Azure å®¢æˆ·ç«¯åˆ›å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: åˆ›å»º Azure LLM å®¢æˆ·ç«¯")
    print("=" * 60)

    try:
        # å°è¯•åˆ›å»ºä¸åŒçš„ Azure å®¢æˆ·ç«¯
        models_to_test = ['azure-gpt4', 'azure-gpt4o', 'azure-gpt35-turbo']

        for model_name in models_to_test:
            print(f"\nåˆ›å»ºå®¢æˆ·ç«¯: {model_name}")
            client = create_llm_client(model_name)
            info = client.get_model_info()

            print(f"  æ¨¡å‹åç§°: {info['model_name']}")
            print(f"  æ˜¾ç¤ºåç§°: {info['display_name']}")
            print(f"  æä¾›å•†: {info['provider']}")
            print(f"  Max Tokens: {info['max_tokens']}")
            print(f"  Timeout: {info['timeout']}s")
            print(f"  API Key: {'âœ“ å·²è®¾ç½®' if info['has_api_key'] else 'âœ— æœªè®¾ç½®'}")

        return True
    except Exception as e:
        print(f"âœ— å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_azure_api_call():
    """æµ‹è¯• Azure API è°ƒç”¨ï¼ˆéœ€è¦æœ‰æ•ˆçš„å¯†é’¥ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: Azure API è°ƒç”¨æµ‹è¯•")
    print("=" * 60)

    try:
        client = create_llm_client("azure-gpt35-turbo")

        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å¯†é’¥
        info = client.get_model_info()
        if not info['has_api_key']:
            print("âš ï¸  è·³è¿‡APIè°ƒç”¨æµ‹è¯•ï¼šæœªé…ç½® Azure OpenAI API å¯†é’¥")
            print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š")
            print("   - AZURE_OPENAI_API_KEY")
            print("   - AZURE_OPENAI_ENDPOINT")
            print("   - AZURE_OPENAI_DEPLOYMENT_35")
            return None

        print("\nå‘é€æµ‹è¯•è¯·æ±‚...")
        response = client.call(
            prompt="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚",
            purpose="Azureé›†æˆæµ‹è¯•",
            max_retries=1
        )

        print(f"âœ“ API è°ƒç”¨æˆåŠŸï¼")
        print(f"å“åº”å†…å®¹: {response[:200]}...")

        return True
    except Exception as e:
        print(f"âœ— API è°ƒç”¨å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„åŸå› ï¼š")
        print("  1. Azure API å¯†é’¥æœªé…ç½®æˆ–æ— æ•ˆ")
        print("  2. Azure ç«¯ç‚¹åœ°å€ä¸æ­£ç¡®")
        print("  3. éƒ¨ç½²åç§°ä¸åŒ¹é…")
        print("  4. ç½‘ç»œè¿æ¥é—®é¢˜")
        return False


def test_azure_stream_call():
    """æµ‹è¯• Azure æµå¼è°ƒç”¨ï¼ˆéœ€è¦æœ‰æ•ˆçš„å¯†é’¥ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: Azure æµå¼è°ƒç”¨æµ‹è¯•")
    print("=" * 60)

    try:
        client = create_llm_client("azure-gpt35-turbo")

        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å¯†é’¥
        info = client.get_model_info()
        if not info['has_api_key']:
            print("âš ï¸  è·³è¿‡æµå¼è°ƒç”¨æµ‹è¯•ï¼šæœªé…ç½® Azure OpenAI API å¯†é’¥")
            return None

        print("\nå‘é€æµå¼æµ‹è¯•è¯·æ±‚...")
        print("å“åº”å†…å®¹: ", end='', flush=True)

        full_response = ""
        for chunk in client.call_stream(
            prompt="æ•°åˆ°5ï¼Œæ¯ä¸ªæ•°å­—ä¹‹é—´ç”¨é€—å·åˆ†éš”ã€‚",
            purpose="Azureæµå¼æµ‹è¯•"
        ):
            print(chunk, end='', flush=True)
            full_response += chunk

        print("\nâœ“ æµå¼è°ƒç”¨æˆåŠŸï¼")
        return True
    except Exception as e:
        print(f"\nâœ— æµå¼è°ƒç”¨å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ Azure OpenAI é›†æˆæµ‹è¯•å¼€å§‹\n")

    results = {
        "æ¨¡å‹é…ç½®": test_azure_models_available(),
        "å®¢æˆ·ç«¯åˆ›å»º": test_azure_client_creation(),
        "APIè°ƒç”¨": test_azure_api_call(),
        "æµå¼è°ƒç”¨": test_azure_stream_call()
    }

    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    for test_name, result in results.items():
        if result is True:
            status = "âœ“ é€šè¿‡"
        elif result is False:
            status = "âœ— å¤±è´¥"
        else:
            status = "âŠ˜ è·³è¿‡"
        print(f"  {test_name}: {status}")

    # åˆ¤æ–­æ•´ä½“çŠ¶æ€
    passed = sum(1 for r in results.values() if r is True)
    failed = sum(1 for r in results.values() if r is False)
    skipped = sum(1 for r in results.values() if r is None)

    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥, {skipped} è·³è¿‡")

    if failed == 0 and passed > 0:
        print("\nâœ… Azure OpenAI é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return 0
    elif skipped > 0 and failed == 0:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•è·³è¿‡ï¼ˆéœ€è¦é…ç½® Azure API å¯†é’¥ï¼‰")
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return 1


if __name__ == "__main__":
    sys.exit(main())
