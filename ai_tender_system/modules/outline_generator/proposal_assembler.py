#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–¹æ¡ˆç»„è£…å™¨ - é˜¶æ®µ4
ç»„è£…æœ€ç»ˆçš„æŠ€æœ¯æ–¹æ¡ˆæ–‡æ¡£
"""

from typing import Dict, List, Any, Optional, Tuple, Generator
from pathlib import Path
import json
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥å…¬å…±æ¨¡å—
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))
from common import get_module_logger, get_prompt_manager
from common.llm_client import create_llm_client


class ProposalAssembler:
    """æ–¹æ¡ˆç»„è£…å™¨"""

    def __init__(self, model_name: str = "gpt-4o-mini", api_key: Optional[str] = None, use_batch_generation: bool = True):
        """
        åˆå§‹åŒ–æ–¹æ¡ˆç»„è£…å™¨

        Args:
            model_name: LLMæ¨¡å‹åç§°
            api_key: APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
            use_batch_generation: æ˜¯å¦ä½¿ç”¨æ‰¹é‡ç”Ÿæˆï¼ˆé»˜è®¤Trueï¼‰
        """
        self.logger = get_module_logger("proposal_assembler")
        self.prompt_manager = get_prompt_manager()
        self.llm_client = create_llm_client(model_name, api_key)
        self.use_batch_generation = use_batch_generation
        self.logger.info(
            f"æ–¹æ¡ˆç»„è£…å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_name}, "
            f"æ‰¹é‡ç”Ÿæˆ: {'å¼€å¯' if use_batch_generation else 'å…³é—­'}"
        )

    def assemble_proposal(
        self,
        outline: Dict[str, Any],
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]],
        options: Optional[Dict[str, bool]] = None
    ) -> Dict[str, Any]:
        """
        ç»„è£…æŠ€æœ¯æ–¹æ¡ˆ

        Args:
            outline: å¤§çº²æ•°æ®
            analysis: éœ€æ±‚åˆ†æç»“æœ
            matched_docs: åŒ¹é…çš„äº§å“æ–‡æ¡£
            options: ç”Ÿæˆé€‰é¡¹

        Returns:
            æ–¹æ¡ˆæ•°æ®
        """
        try:
            self.logger.info("å¼€å§‹ç»„è£…æŠ€æœ¯æ–¹æ¡ˆ...")

            if options is None:
                options = {}

            proposal = {
                'metadata': {
                    'title': outline.get('outline_title', 'æŠ€æœ¯æ–¹æ¡ˆ'),
                    'generation_time': outline.get('generation_time', ''),
                    'total_chapters': outline.get('total_chapters', 0),
                    'estimated_pages': outline.get('estimated_pages', 0)
                },
                'chapters': [],
                'attachments': []
            }

            # ç»„è£…ä¸»è¦ç« èŠ‚
            proposal['chapters'] = self._assemble_chapters(
                outline.get('chapters', []),
                analysis,
                matched_docs
            )

            # ç»„è£…é™„ä»¶åˆ—è¡¨
            if options.get('include_analysis', False):
                proposal['attachments'].append({
                    'type': 'analysis',
                    'title': 'éœ€æ±‚åˆ†ææŠ¥å‘Š',
                    'data': analysis
                })

            if options.get('include_mapping', False):
                proposal['attachments'].append({
                    'type': 'mapping',
                    'title': 'éœ€æ±‚åŒ¹é…è¡¨',
                    'data': self._create_mapping_table(analysis, matched_docs)
                })

            if options.get('include_summary', False):
                proposal['attachments'].append({
                    'type': 'summary',
                    'title': 'ç”ŸæˆæŠ¥å‘Š',
                    'data': self._create_summary_report(proposal, analysis, matched_docs)
                })

            self.logger.info("æŠ€æœ¯æ–¹æ¡ˆç»„è£…å®Œæˆ")
            return proposal

        except Exception as e:
            self.logger.error(f"æ–¹æ¡ˆç»„è£…å¤±è´¥: {e}", exc_info=True)
            raise

    def assemble_proposal_stream(
        self,
        outline: Dict[str, Any],
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]],
        options: Optional[Dict[str, bool]] = None,
        proposal_mode: str = 'basic'
    ) -> Generator[Dict[str, Any], None, None]:
        """
        æµå¼ç»„è£…æŠ€æœ¯æ–¹æ¡ˆï¼ˆGeneratorç‰ˆæœ¬ï¼‰
        æ¯ç”Ÿæˆä¸€ä¸ªç« èŠ‚çš„å†…å®¹å°±yieldç»™è°ƒç”¨è€…

        Args:
            outline: å¤§çº²æ•°æ®
            analysis: éœ€æ±‚åˆ†æç»“æœ
            matched_docs: åŒ¹é…çš„äº§å“æ–‡æ¡£
            options: ç”Ÿæˆé€‰é¡¹
            proposal_mode: æ–¹æ¡ˆæ¨¡å¼ï¼Œ'basic'æˆ–'advanced'

        Yields:
            Dict: åŒ…å«ç« èŠ‚ä¿¡æ¯å’Œå†…å®¹çš„å­—å…¸
                {'type': 'chapter_start', 'chapter': {...}}
                {'type': 'content_chunk', 'chunk': 'text...'}
                {'type': 'chapter_end', 'chapter': {...}}
                {'type': 'completed', 'proposal': {...}}
        """
        try:
            self.logger.info("å¼€å§‹æµå¼ç»„è£…æŠ€æœ¯æ–¹æ¡ˆ...")

            if options is None:
                options = {}

            # åˆå§‹åŒ–æ–¹æ¡ˆç»“æ„
            proposal = {
                'metadata': {
                    'title': outline.get('outline_title', 'æŠ€æœ¯æ–¹æ¡ˆ'),
                    'generation_time': outline.get('generation_time', ''),
                    'total_chapters': outline.get('total_chapters', 0),
                    'estimated_pages': outline.get('estimated_pages', 0)
                },
                'chapters': [],
                'attachments': []
            }

            chapters = outline.get('chapters', [])
            total_matched_docs = sum(len(docs) for docs in matched_docs.values())

            # å¦‚æœæ²¡æœ‰äº§å“æ–‡æ¡£åŒ¹é…ï¼Œä½¿ç”¨æµå¼AIç”Ÿæˆï¼ˆä¸²è¡Œæ¨¡å¼ï¼Œç¨³å®šå¯é ï¼‰
            if total_matched_docs == 0:
                self.logger.info(f"æ— äº§å“æ–‡æ¡£åŒ¹é…ï¼Œå¼€å§‹æµå¼ç”Ÿæˆ {len(chapters)} ä¸ªç« èŠ‚...")

                # âœ… ä¸²è¡Œç”Ÿæˆï¼ˆé¡ºåºæ­£ç¡®ï¼Œç¨³å®šå¯é ï¼‰
                for i, chapter in enumerate(chapters, 1):
                    chapter_title = chapter.get('title', f'ç¬¬{i}ç« ')
                    chapter_num = chapter.get('chapter_number', str(i))

                    # æ¨é€ç« èŠ‚å¼€å§‹äº‹ä»¶
                    yield {
                        'type': 'chapter_start',
                        'chapter_number': chapter_num,
                        'chapter_title': chapter_title,
                        'total_chapters': len(chapters),
                        'current_index': i
                    }

                    # æµå¼ç”Ÿæˆç« èŠ‚å†…å®¹
                    chapter_content = []
                    for content_chunk in self.generate_chapter_content_stream(chapter, analysis, proposal_mode):
                        chapter_content.append(content_chunk)
                        # æ¨é€å†…å®¹ç‰‡æ®µ
                        yield {
                            'type': 'content_chunk',
                            'chapter_number': chapter_num,
                            'chunk': content_chunk
                        }

                    # ç»„è£…ç« èŠ‚æ•°æ®
                    assembled_chapter = {
                        'chapter_number': chapter_num,
                        'level': chapter.get('level', 1),
                        'title': chapter_title,
                        'description': chapter.get('description', ''),
                        'response_strategy': chapter.get('response_strategy', ''),
                        'content_hints': chapter.get('content_hints', []),
                        'response_tips': chapter.get('response_tips', []),
                        'suggested_references': chapter.get('suggested_references', []),
                        'evidence_needed': chapter.get('evidence_needed', []),
                        'ai_generated_content': ''.join(chapter_content),
                        'subsections': []
                    }

                    # å¤„ç†å­ç« èŠ‚ï¼ˆæµå¼ç”Ÿæˆï¼‰
                    if 'subsections' in chapter and chapter['subsections']:
                        self.logger.info(f"å¼€å§‹æµå¼ç”Ÿæˆ {len(chapter['subsections'])} ä¸ªå­ç« èŠ‚...")

                        for j, subsection in enumerate(chapter['subsections'], 1):
                            subsection_title = subsection.get('title', f'å­ç« èŠ‚{j}')
                            subsection_num = subsection.get('chapter_number', f"{chapter_num}.{j}")

                            # æ¨é€å­ç« èŠ‚å¼€å§‹äº‹ä»¶
                            yield {
                                'type': 'subsection_start',
                                'chapter_number': chapter_num,
                                'subsection_number': subsection_num,
                                'subsection_title': subsection_title
                            }

                            # æµå¼ç”Ÿæˆå­ç« èŠ‚å†…å®¹
                            subsection_content = []
                            for content_chunk in self.generate_chapter_content_stream(subsection, analysis, proposal_mode):
                                subsection_content.append(content_chunk)
                                # æ¨é€å­ç« èŠ‚å†…å®¹ç‰‡æ®µ
                                yield {
                                    'type': 'content_chunk',
                                    'chapter_number': subsection_num,
                                    'chunk': content_chunk
                                }

                            # ç»„è£…å­ç« èŠ‚
                            assembled_subsection = {
                                'chapter_number': subsection_num,
                                'level': subsection.get('level', 2),
                                'title': subsection_title,
                                'description': subsection.get('description', ''),
                                'response_strategy': subsection.get('response_strategy', ''),
                                'content_hints': subsection.get('content_hints', []),
                                'response_tips': subsection.get('response_tips', []),
                                'suggested_references': subsection.get('suggested_references', []),
                                'evidence_needed': subsection.get('evidence_needed', []),
                                'ai_generated_content': ''.join(subsection_content)
                            }

                            assembled_chapter['subsections'].append(assembled_subsection)

                            # æ¨é€å­ç« èŠ‚å®Œæˆäº‹ä»¶
                            yield {
                                'type': 'subsection_end',
                                'chapter_number': chapter_num,
                                'subsection_number': subsection_num,
                                'subsection_title': subsection_title
                            }

                    proposal['chapters'].append(assembled_chapter)

                    # æ¨é€ç« èŠ‚å®Œæˆäº‹ä»¶
                    yield {
                        'type': 'chapter_end',
                        'chapter_number': chapter_num,
                        'chapter_title': chapter_title
                    }
            else:
                # æœ‰åŒ¹é…æ–‡æ¡£æ—¶ï¼Œä½¿ç”¨éæµå¼æ–¹æ³•
                proposal['chapters'] = self._assemble_chapters(chapters, analysis, matched_docs)

            # ç»„è£…é™„ä»¶
            if options.get('include_analysis', False):
                proposal['attachments'].append({
                    'type': 'analysis',
                    'title': 'éœ€æ±‚åˆ†ææŠ¥å‘Š',
                    'data': analysis
                })

            if options.get('include_mapping', False):
                proposal['attachments'].append({
                    'type': 'mapping',
                    'title': 'éœ€æ±‚åŒ¹é…è¡¨',
                    'data': self._create_mapping_table(analysis, matched_docs)
                })

            if options.get('include_summary', False):
                proposal['attachments'].append({
                    'type': 'summary',
                    'title': 'ç”ŸæˆæŠ¥å‘Š',
                    'data': self._create_summary_report(proposal, analysis, matched_docs)
                })

            # æ¨é€å®Œæˆäº‹ä»¶
            yield {
                'type': 'completed',
                'proposal': proposal
            }

            self.logger.info("æµå¼æŠ€æœ¯æ–¹æ¡ˆç»„è£…å®Œæˆ")

        except Exception as e:
            self.logger.error(f"æµå¼æ–¹æ¡ˆç»„è£…å¤±è´¥: {e}", exc_info=True)
            yield {
                'type': 'error',
                'error': str(e)
            }

    def _generate_batch_chapters_content(
        self, chapters: List[Dict], analysis: Dict[str, Any]
    ) -> Dict[str, str]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šä¸ªç« èŠ‚çš„AIå†…å®¹ï¼ˆå‡å°‘LLMè°ƒç”¨æ¬¡æ•°ï¼‰

        Args:
            chapters: ç« èŠ‚åˆ—è¡¨
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            {chapter_number: ai_content} çš„å­—å…¸
        """
        try:
            if not chapters:
                return {}

            self.logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(chapters)} ä¸ªç« èŠ‚çš„å†…å®¹...")

            # æ„å»ºæ‰¹é‡æç¤ºè¯
            chapters_info = []
            for chapter in chapters:
                chapter_info = {
                    'chapter_number': chapter.get('chapter_number', ''),
                    'title': chapter.get('title', ''),
                    'description': chapter.get('description', ''),
                    'content_hints': chapter.get('content_hints', []),
                    'response_tips': chapter.get('response_tips', [])
                }
                chapters_info.append(chapter_info)

            # æ„å»ºæ‰¹é‡ç”Ÿæˆæç¤ºè¯
            prompt = f"""è¯·ä¸ºæŠ€æœ¯æ–¹æ¡ˆçš„ä»¥ä¸‹ç« èŠ‚æ‰¹é‡ç”Ÿæˆè¯¦ç»†å†…å®¹ã€‚æ¯ä¸ªç« èŠ‚ç‹¬ç«‹ç”Ÿæˆï¼Œäº’ä¸å½±å“ã€‚

ç« èŠ‚åˆ—è¡¨:
{json.dumps(chapters_info, ensure_ascii=False, indent=2)}

è¦æ±‚:
1. æ¯ä¸ªç« èŠ‚å†…å®¹ä¸“ä¸šã€è¯¦å®ï¼Œç¬¦åˆæŠ€æœ¯æ–¹æ¡ˆçš„æ ‡å‡†
2. çªå‡ºæŠ€æœ¯å…ˆè¿›æ€§å’Œå¯è¡Œæ€§
3. è¯­è¨€ç®€æ´æ˜äº†ï¼Œé€»è¾‘æ¸…æ™°
4. æ¯ä¸ªç« èŠ‚å­—æ•°æ§åˆ¶åœ¨800-1500å­—
5. ä½¿ç”¨ä¸­æ–‡æ’°å†™

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹:
{{
  "chapters": [
    {{
      "chapter_number": "1",
      "title": "ç« èŠ‚æ ‡é¢˜",
      "content": "ç« èŠ‚è¯¦ç»†å†…å®¹..."
    }},
    ...
  ]
}}

è¯·ç”Ÿæˆæ‰€æœ‰ç« èŠ‚çš„å†…å®¹:"""

            # è°ƒç”¨LLMï¼ˆå¢åŠ max_tokensä»¥æ”¯æŒå¤šä¸ªç« èŠ‚ï¼‰
            chapter_count = len(chapters)
            max_tokens = min(12000, 2000 * chapter_count)  # æ¯ç« èŠ‚çº¦2000 tokensï¼Œæœ€å¤š12000

            self.logger.info(f"æ‰¹é‡ç”Ÿæˆé…ç½®: max_tokens={max_tokens}, ç« èŠ‚æ•°={chapter_count}")

            response = self.llm_client.call(
                prompt=prompt,
                temperature=0.7,
                max_tokens=max_tokens,
                max_retries=2,
                purpose=f"æ‰¹é‡ç« èŠ‚å†…å®¹ç”Ÿæˆ ({chapter_count}ç« )"
            )

            # è§£æå“åº”
            if not response:
                self.logger.warning("æ‰¹é‡ç”Ÿæˆè¿”å›ç©ºå“åº”")
                return {}

            # æå–JSON
            import re
            response = re.sub(r'^```json\s*', '', response.strip())
            response = re.sub(r'\s*```$', '', response.strip())

            json_start = response.find('{')
            json_end = response.rfind('}') + 1

            if json_start != -1 and json_end > json_start:
                json_str = response[json_start:json_end]
                try:
                    result = json.loads(json_str)
                    generated_chapters = result.get('chapters', [])

                    # æ„å»ºç»“æœå­—å…¸
                    content_map = {}
                    for gen_chapter in generated_chapters:
                        chapter_num = gen_chapter.get('chapter_number', '')
                        content = gen_chapter.get('content', '')
                        if chapter_num and content:
                            content_map[chapter_num] = content

                    self.logger.info(f"âœ“ æ‰¹é‡ç”ŸæˆæˆåŠŸï¼Œç”Ÿæˆäº† {len(content_map)} ä¸ªç« èŠ‚çš„å†…å®¹")
                    return content_map

                except json.JSONDecodeError as e:
                    self.logger.error(f"æ‰¹é‡ç”ŸæˆJSONè§£æå¤±è´¥: {e}")
                    return {}
            else:
                self.logger.warning("æ‰¹é‡ç”Ÿæˆå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆJSON")
                return {}

        except Exception as e:
            self.logger.error(f"æ‰¹é‡ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {e}")
            return {}

    def _generate_chapter_with_content(
        self, chapter: Dict, analysis: Dict[str, Any]
    ) -> Tuple[Dict, Optional[str]]:
        """
        ä¸ºå•ä¸ªç« èŠ‚ç”ŸæˆAIå†…å®¹ï¼ˆç”¨äºå¹¶å‘è°ƒç”¨ï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            (ç»„è£…åçš„ç« èŠ‚åŸºç¡€ç»“æ„, AIç”Ÿæˆçš„å†…å®¹æˆ–None)
        """
        assembled_chapter = {
            'chapter_number': chapter.get('chapter_number', ''),
            'level': chapter.get('level', 1),
            'title': chapter.get('title', ''),
            'description': chapter.get('description', ''),
            'response_strategy': chapter.get('response_strategy', ''),
            'content_hints': chapter.get('content_hints', []),
            'response_tips': chapter.get('response_tips', []),
            'suggested_references': chapter.get('suggested_references', []),
            'evidence_needed': chapter.get('evidence_needed', []),
            'subsections': []
        }

        # ç”ŸæˆAIå†…å®¹
        ai_content = self._generate_chapter_content_with_ai(chapter, analysis)
        return assembled_chapter, ai_content

    def _assemble_chapters(
        self,
        chapters: List[Dict],
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]]
    ) -> List[Dict]:
        """
        ç»„è£…ç« èŠ‚å†…å®¹ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰

        Args:
            chapters: å¤§çº²ç« èŠ‚åˆ—è¡¨
            analysis: éœ€æ±‚åˆ†æ
            matched_docs: åŒ¹é…çš„æ–‡æ¡£

        Returns:
            ç»„è£…åçš„ç« èŠ‚åˆ—è¡¨
        """
        assembled_chapters = []
        total_matched_docs = sum(len(docs) for docs in matched_docs.values())

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°äº§å“æ–‡æ¡£ï¼Œä½¿ç”¨AIç”Ÿæˆç« èŠ‚å†…å®¹
        if total_matched_docs == 0:
            # é€‰æ‹©ç”Ÿæˆæ¨¡å¼ï¼šæ‰¹é‡ç”Ÿæˆ vs å¹¶å‘ç”Ÿæˆ
            if self.use_batch_generation and len(chapters) > 2:
                # æ‰¹é‡ç”Ÿæˆæ¨¡å¼ï¼ˆé€‚åˆ3ä¸ªä»¥ä¸Šç« èŠ‚ï¼‰
                self.logger.info(f"ä½¿ç”¨æ‰¹é‡ç”Ÿæˆæ¨¡å¼ï¼Œä¸€æ¬¡æ€§ç”Ÿæˆ {len(chapters)} ä¸ªç« èŠ‚çš„AIå†…å®¹...")

                batch_content_map = self._generate_batch_chapters_content(chapters, analysis)

                # æŒ‰åŸé¡ºåºç»„è£…ç« èŠ‚
                for chapter in chapters:
                    chapter_num = chapter.get('chapter_number', '')
                    assembled_chapter = {
                        'chapter_number': chapter_num,
                        'level': chapter.get('level', 1),
                        'title': chapter.get('title', ''),
                        'description': chapter.get('description', ''),
                        'response_strategy': chapter.get('response_strategy', ''),
                        'content_hints': chapter.get('content_hints', []),
                        'response_tips': chapter.get('response_tips', []),
                        'suggested_references': chapter.get('suggested_references', []),
                        'evidence_needed': chapter.get('evidence_needed', []),
                        'subsections': []
                    }

                    # æ·»åŠ æ‰¹é‡ç”Ÿæˆçš„å†…å®¹
                    ai_content = batch_content_map.get(chapter_num)
                    if ai_content:
                        assembled_chapter['ai_generated_content'] = ai_content
                        self.logger.info(f"âœ“ ç« èŠ‚'{chapter.get('title')}'å·²æ·»åŠ æ‰¹é‡ç”Ÿæˆå†…å®¹")
                    else:
                        self.logger.warning(f"âš ï¸  ç« èŠ‚'{chapter.get('title')}'æ‰¹é‡ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•å•ç‹¬ç”Ÿæˆ")
                        # æ‰¹é‡ç”Ÿæˆå¤±è´¥ï¼Œå•ç‹¬ç”Ÿæˆ
                        fallback_content = self._generate_chapter_content_with_ai(chapter, analysis)
                        if fallback_content:
                            assembled_chapter['ai_generated_content'] = fallback_content

                    # å¤„ç†å­ç« èŠ‚
                    if 'subsections' in chapter and chapter['subsections']:
                        assembled_chapter['subsections'] = self._assemble_subsections(
                            chapter['subsections'],
                            analysis,
                            matched_docs
                        )

                    assembled_chapters.append(assembled_chapter)
            else:
                # å¹¶å‘ç”Ÿæˆæ¨¡å¼ï¼ˆé€‚åˆå°‘é‡ç« èŠ‚æˆ–ç¦ç”¨æ‰¹é‡ç”Ÿæˆï¼‰
                self.logger.info(f"ä½¿ç”¨å¹¶å‘ç”Ÿæˆæ¨¡å¼ï¼Œå¹¶å‘ç”Ÿæˆ {len(chapters)} ä¸ªç« èŠ‚çš„AIå†…å®¹...")

                with ThreadPoolExecutor(max_workers=5) as executor:
                    # æäº¤æ‰€æœ‰ç« èŠ‚çš„ç”Ÿæˆä»»åŠ¡
                    future_to_chapter = {
                        executor.submit(self._generate_chapter_with_content, ch, analysis): ch
                        for ch in chapters
                    }

                    # æ”¶é›†ç»“æœ
                    chapter_results = {}
                    completed_count = 0
                    failed_count = 0

                    for future in as_completed(future_to_chapter):
                        original_chapter = future_to_chapter[future]
                        try:
                            assembled_chapter, ai_content = future.result(timeout=150)
                            chapter_results[id(original_chapter)] = (assembled_chapter, ai_content)

                            if ai_content:
                                chapter_title = original_chapter.get('title', 'æœªçŸ¥ç« èŠ‚')
                                self.logger.info(f"âœ“ ç« èŠ‚'{chapter_title}'AIå†…å®¹ç”ŸæˆæˆåŠŸ")
                                completed_count += 1
                            else:
                                failed_count += 1
                        except Exception as e:
                            chapter_title = original_chapter.get('title', 'æœªçŸ¥ç« èŠ‚')
                            self.logger.warning(f"âŒ ç« èŠ‚'{chapter_title}'AIå†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
                            # åˆ›å»ºåŸºç¡€ç»“æ„
                            chapter_results[id(original_chapter)] = ({
                                'chapter_number': original_chapter.get('chapter_number', ''),
                                'level': original_chapter.get('level', 1),
                                'title': original_chapter.get('title', ''),
                                'description': original_chapter.get('description', ''),
                                'response_strategy': original_chapter.get('response_strategy', ''),
                                'content_hints': original_chapter.get('content_hints', []),
                                'response_tips': original_chapter.get('response_tips', []),
                                'suggested_references': original_chapter.get('suggested_references', []),
                                'evidence_needed': original_chapter.get('evidence_needed', []),
                                'subsections': []
                            }, None)
                            failed_count += 1

                self.logger.info(
                    f"ç« èŠ‚AIå†…å®¹ç”Ÿæˆå®Œæˆ: æˆåŠŸ {completed_count}ä¸ª, å¤±è´¥ {failed_count}ä¸ª, "
                    f"æ€»è®¡ {len(chapters)}ä¸ª"
                )

                # æŒ‰åŸé¡ºåºç»„è£…ç« èŠ‚ï¼ˆä¿æŒé¡ºåºå¾ˆé‡è¦ï¼‰
                for chapter in chapters:
                    assembled_chapter, ai_content = chapter_results.get(id(chapter), ({}, None))
                    if ai_content:
                        assembled_chapter['ai_generated_content'] = ai_content

                    # å¤„ç†å­ç« èŠ‚ï¼ˆå­ç« èŠ‚åŒæ ·å¹¶å‘ç”Ÿæˆï¼‰
                    if 'subsections' in chapter and chapter['subsections']:
                        assembled_chapter['subsections'] = self._assemble_subsections(
                            chapter['subsections'],
                            analysis,
                            matched_docs
                        )

                    assembled_chapters.append(assembled_chapter)
        else:
            # æœ‰åŒ¹é…æ–‡æ¡£æ—¶ï¼Œä½¿ç”¨åŸä¸²è¡Œé€»è¾‘ï¼ˆä¸ç”ŸæˆAIå†…å®¹ï¼‰
            for chapter in chapters:
                assembled_chapter = {
                    'chapter_number': chapter.get('chapter_number', ''),
                    'level': chapter.get('level', 1),
                    'title': chapter.get('title', ''),
                    'description': chapter.get('description', ''),
                    'response_strategy': chapter.get('response_strategy', ''),
                    'content_hints': chapter.get('content_hints', []),
                    'response_tips': chapter.get('response_tips', []),
                    'suggested_references': chapter.get('suggested_references', []),
                    'evidence_needed': chapter.get('evidence_needed', []),
                    'subsections': []
                }

                # å¤„ç†å­ç« èŠ‚
                if 'subsections' in chapter and chapter['subsections']:
                    assembled_chapter['subsections'] = self._assemble_subsections(
                        chapter['subsections'],
                        analysis,
                        matched_docs
                    )

                assembled_chapters.append(assembled_chapter)

        return assembled_chapters

    def _assemble_subsections(
        self,
        subsections: List[Dict],
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]]
    ) -> List[Dict]:
        """
        ç»„è£…å­ç« èŠ‚ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰

        Args:
            subsections: å­ç« èŠ‚åˆ—è¡¨
            analysis: éœ€æ±‚åˆ†æ
            matched_docs: åŒ¹é…çš„æ–‡æ¡£

        Returns:
            ç»„è£…åçš„å­ç« èŠ‚åˆ—è¡¨
        """
        assembled = []
        total_matched_docs = sum(len(docs) for docs in matched_docs.values())

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°äº§å“æ–‡æ¡£ï¼Œä½¿ç”¨AIå¹¶å‘ç”Ÿæˆå­ç« èŠ‚å†…å®¹
        if total_matched_docs == 0 and subsections:
            self.logger.info(f"å¹¶å‘ç”Ÿæˆ {len(subsections)} ä¸ªå­ç« èŠ‚çš„AIå†…å®¹...")

            with ThreadPoolExecutor(max_workers=5) as executor:
                # æäº¤æ‰€æœ‰å­ç« èŠ‚çš„ç”Ÿæˆä»»åŠ¡
                future_to_subsection = {
                    executor.submit(self._generate_chapter_with_content, sub, analysis): sub
                    for sub in subsections
                }

                # æ”¶é›†ç»“æœ
                subsection_results = {}
                completed_count = 0

                for future in as_completed(future_to_subsection):
                    original_subsection = future_to_subsection[future]
                    try:
                        assembled_sub, ai_content = future.result(timeout=150)
                        subsection_results[id(original_subsection)] = (assembled_sub, ai_content)

                        if ai_content:
                            sub_title = original_subsection.get('title', 'æœªçŸ¥å­ç« èŠ‚')
                            self.logger.info(f"âœ“ å­ç« èŠ‚'{sub_title}'AIå†…å®¹ç”ŸæˆæˆåŠŸ")
                            completed_count += 1
                    except Exception as e:
                        sub_title = original_subsection.get('title', 'æœªçŸ¥å­ç« èŠ‚')
                        self.logger.warning(f"âŒ å­ç« èŠ‚'{sub_title}'AIå†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
                        # åˆ›å»ºåŸºç¡€ç»“æ„
                        subsection_results[id(original_subsection)] = ({
                            'chapter_number': original_subsection.get('chapter_number', ''),
                            'level': original_subsection.get('level', 2),
                            'title': original_subsection.get('title', ''),
                            'description': original_subsection.get('description', ''),
                            'response_strategy': original_subsection.get('response_strategy', ''),
                            'content_hints': original_subsection.get('content_hints', []),
                            'response_tips': original_subsection.get('response_tips', []),
                            'suggested_references': original_subsection.get('suggested_references', []),
                            'evidence_needed': original_subsection.get('evidence_needed', [])
                        }, None)

            self.logger.info(f"å­ç« èŠ‚AIå†…å®¹ç”Ÿæˆå®Œæˆ: æˆåŠŸ {completed_count}ä¸ª, æ€»è®¡ {len(subsections)}ä¸ª")

            # æŒ‰åŸé¡ºåºç»„è£…å­ç« èŠ‚
            for subsection in subsections:
                assembled_sub, ai_content = subsection_results.get(id(subsection), ({}, None))
                if ai_content:
                    assembled_sub['ai_generated_content'] = ai_content
                assembled.append(assembled_sub)
        else:
            # æœ‰åŒ¹é…æ–‡æ¡£æ—¶ï¼Œä½¿ç”¨åŸä¸²è¡Œé€»è¾‘ï¼ˆä¸ç”ŸæˆAIå†…å®¹ï¼‰
            for subsection in subsections:
                assembled_sub = {
                    'chapter_number': subsection.get('chapter_number', ''),
                    'level': subsection.get('level', 2),
                    'title': subsection.get('title', ''),
                    'description': subsection.get('description', ''),
                    'response_strategy': subsection.get('response_strategy', ''),
                    'content_hints': subsection.get('content_hints', []),
                    'response_tips': subsection.get('response_tips', []),
                    'suggested_references': subsection.get('suggested_references', []),
                    'evidence_needed': subsection.get('evidence_needed', [])
                }
                assembled.append(assembled_sub)

        return assembled

    def _create_mapping_table(
        self,
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]]
    ) -> List[Dict]:
        """
        åˆ›å»ºéœ€æ±‚åŒ¹é…è¡¨

        Args:
            analysis: éœ€æ±‚åˆ†æ
            matched_docs: åŒ¹é…çš„æ–‡æ¡£

        Returns:
            åŒ¹é…è¡¨æ•°æ®
        """
        mapping_table = []

        for category in analysis.get('requirement_categories', []):
            category_code = category.get('category_code', '')
            category_name = category.get('category', '')

            # è·å–è¯¥ç±»åˆ«åŒ¹é…çš„æ–‡æ¡£
            docs = matched_docs.get(category_code, [])

            for point in category.get('key_points', []):
                row = {
                    'category': category_name,
                    'requirement': point,
                    'matched_docs': [doc['title'] for doc in docs[:2]],  # æœ€å¤š2ä¸ª
                    'match_status': 'å·²åŒ¹é…' if docs else 'å¾…åŒ¹é…'
                }
                mapping_table.append(row)

        return mapping_table

    def _create_summary_report(
        self,
        proposal: Dict[str, Any],
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]]
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºç”ŸæˆæŠ¥å‘Š

        Args:
            proposal: æ–¹æ¡ˆæ•°æ®
            analysis: éœ€æ±‚åˆ†æ
            matched_docs: åŒ¹é…çš„æ–‡æ¡£

        Returns:
            æŠ¥å‘Šæ•°æ®
        """
        summary = analysis.get('document_summary', {})

        total_matched_docs = sum(len(docs) for docs in matched_docs.values())

        report = {
            'generation_info': {
                'title': proposal['metadata']['title'],
                'generation_time': proposal['metadata']['generation_time'],
                'total_chapters': proposal['metadata']['total_chapters']
            },
            'requirements_summary': {
                'total_requirements': summary.get('total_requirements', 0),
                'mandatory_count': summary.get('mandatory_count', 0),
                'optional_count': summary.get('optional_count', 0),
                'complexity_level': summary.get('complexity_level', 'medium')
            },
            'matching_summary': {
                'total_documents_matched': total_matched_docs,
                'categories_with_matches': len(matched_docs),
                'match_rate': self._calculate_match_rate(analysis, matched_docs)
            }
        }

        return report

    def _calculate_match_rate(
        self,
        analysis: Dict[str, Any],
        matched_docs: Dict[str, List[Dict]]
    ) -> float:
        """
        è®¡ç®—åŒ¹é…æˆåŠŸç‡

        Args:
            analysis: éœ€æ±‚åˆ†æ
            matched_docs: åŒ¹é…çš„æ–‡æ¡£

        Returns:
            åŒ¹é…ç‡ï¼ˆ0-100ï¼‰
        """
        total_categories = len(analysis.get('requirement_categories', []))

        if total_categories == 0:
            return 0.0

        matched_categories = len([
            cat for cat in analysis.get('requirement_categories', [])
            if matched_docs.get(cat.get('category_code', ''))
        ])

        return round((matched_categories / total_categories) * 100, 2)

    def _generate_chapter_content_with_ai(
        self,
        chapter: Dict[str, Any],
        analysis: Dict[str, Any],
        proposal_mode: str = 'basic'
    ) -> Optional[str]:
        """
        ä½¿ç”¨AIç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆå¸¦é™çº§ç­–ç•¥å’ŒåŒæ¨¡å¼æ”¯æŒï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ
            proposal_mode: æ–¹æ¡ˆæ¨¡å¼ï¼Œ'basic'æˆ–'advanced'

        Returns:
            ç”Ÿæˆçš„ç« èŠ‚å†…å®¹ï¼Œå¤±è´¥è¿”å›æ¨¡æ¿å†…å®¹
        """
        chapter_title = chapter.get('title', '')
        chapter_desc = chapter.get('description', '')
        content_hints = chapter.get('content_hints', [])
        response_tips = chapter.get('response_tips', [])

        # ç­–ç•¥1: æ ¹æ®æ¨¡å¼é€‰æ‹©æç¤ºè¯ç”Ÿæˆï¼ˆé‡è¯•2æ¬¡ï¼‰
        try:
            # æ ¹æ®æ¨¡å¼æ„å»ºæç¤ºè¯
            if proposal_mode == 'advanced':
                prompt = self._build_advanced_prompt(chapter, analysis)
            else:
                prompt = self._build_basic_prompt(chapter, analysis)

            # è°ƒç”¨LLM
            mode_label = "è¿›é˜¶æ¨¡å¼" if proposal_mode == 'advanced' else "åŸºç¡€æ¨¡å¼"
            self.logger.info(f"ä¸ºç« èŠ‚'{chapter_title}'ç”ŸæˆAIå†…å®¹ï¼ˆ{mode_label}ï¼‰...")
            response = self.llm_client.call(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1500,  # ä»2000é™åˆ°1500
                max_retries=2,
                purpose=f"ç« èŠ‚å†…å®¹ç”Ÿæˆ: {chapter_title}"
            )

            if response and response.strip():
                self.logger.info(f"ç« èŠ‚'{chapter_title}'AIå†…å®¹ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response)}")
                return response.strip()

        except Exception as e:
            self.logger.warning(f"ç­–ç•¥1(å®Œæ•´ç”Ÿæˆ)å¤±è´¥: {e}ï¼Œå°è¯•ç­–ç•¥2(ç®€åŒ–ç”Ÿæˆ)")

        # ç­–ç•¥2: ç®€åŒ–æç¤ºè¯ç”Ÿæˆï¼ˆé‡è¯•1æ¬¡ï¼‰
        try:
            simplified_prompt = f"""ä¸º"{chapter_title}"ç”Ÿæˆ800å­—æŠ€æœ¯æ–¹æ¡ˆå†…å®¹ã€‚

è¦ç‚¹: {', '.join(content_hints[:3])}

è¦æ±‚: ä¸“ä¸šã€æ¸…æ™°ã€ä¸­æ–‡"""

            response = self.llm_client.call(
                prompt=simplified_prompt,
                temperature=0.7,
                max_tokens=1500,
                max_retries=1,
                purpose=f"ç« èŠ‚å†…å®¹ç®€åŒ–ç”Ÿæˆ: {chapter_title}"
            )

            if response and response.strip():
                self.logger.info(f"ç« èŠ‚'{chapter_title}'ç®€åŒ–ç”ŸæˆæˆåŠŸ")
                return response.strip()

        except Exception as e:
            self.logger.warning(f"ç­–ç•¥2(ç®€åŒ–ç”Ÿæˆ)å¤±è´¥: {e}ï¼Œä½¿ç”¨ç­–ç•¥3(æ¨¡æ¿å†…å®¹)")

        # ç­–ç•¥3: è¿”å›æ¨¡æ¿å†…å®¹ï¼ˆå…œåº•ï¼‰
        self.logger.error(f"ç« èŠ‚'{chapter_title}'æ‰€æœ‰ç”Ÿæˆç­–ç•¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿å†…å®¹")
        return self._generate_template_content(chapter)

    def generate_chapter_content_stream(
        self,
        chapter: Dict[str, Any],
        analysis: Dict[str, Any],
        proposal_mode: str = 'basic'
    ) -> Generator[str, None, None]:
        """
        ä½¿ç”¨AIæµå¼ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆGeneratorç‰ˆæœ¬ï¼Œå¸¦é™çº§ç­–ç•¥å’ŒåŒæ¨¡å¼æ”¯æŒï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ
            proposal_mode: æ–¹æ¡ˆæ¨¡å¼ï¼Œ'basic'æˆ–'advanced'

        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        chapter_title = chapter.get('title', '')

        # æ ¹æ®æ¨¡å¼æ„å»ºæç¤ºè¯
        if proposal_mode == 'advanced':
            prompt = self._build_advanced_prompt(chapter, analysis)
        else:
            prompt = self._build_basic_prompt(chapter, analysis)

        # ç­–ç•¥1: æµå¼ç”Ÿæˆï¼ˆè¶…æ—¶120ç§’ï¼‰
        try:
            mode_label = "è¿›é˜¶æ¨¡å¼" if proposal_mode == 'advanced' else "åŸºç¡€æ¨¡å¼"
            self.logger.info(f"ä¸ºç« èŠ‚'{chapter_title}'æµå¼ç”ŸæˆAIå†…å®¹ï¼ˆ{mode_label}ï¼‰...")

            for chunk in self.llm_client.call_stream(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1500,  # é™åˆ°1500
                timeout=120,
                purpose=f"ç« èŠ‚å†…å®¹æµå¼ç”Ÿæˆ: {chapter_title}"
            ):
                yield chunk

            self.logger.info(f"ç« èŠ‚'{chapter_title}'æµå¼ç”Ÿæˆå®Œæˆ")
            return

        except Exception as e:
            self.logger.warning(f"ç­–ç•¥1(æµå¼ç”Ÿæˆ)å¤±è´¥: {e}ï¼Œå°è¯•ç­–ç•¥2(éæµå¼ç”Ÿæˆ)")

        # ç­–ç•¥2: éæµå¼ç”Ÿæˆ
        try:
            self.logger.info(f"ç« èŠ‚'{chapter_title}'ä½¿ç”¨éæµå¼ç”Ÿæˆ...")

            response = self.llm_client.call(
                prompt=prompt,  # ä½¿ç”¨ç›¸åŒçš„ç²¾ç®€æç¤ºè¯
                temperature=0.7,
                max_tokens=1500,
                max_retries=1,
                purpose=f"ç« èŠ‚å†…å®¹éæµå¼ç”Ÿæˆ: {chapter_title}"
            )

            if response and response.strip():
                self.logger.info(f"ç« èŠ‚'{chapter_title}'éæµå¼ç”ŸæˆæˆåŠŸ")
                yield response.strip()
                return

        except Exception as e:
            self.logger.warning(f"ç­–ç•¥2(éæµå¼ç”Ÿæˆ)å¤±è´¥: {e}ï¼Œä½¿ç”¨ç­–ç•¥3(æ¨¡æ¿å†…å®¹)")

        # ç­–ç•¥3: æ¨¡æ¿å†…å®¹ï¼ˆå…œåº•ï¼‰
        self.logger.error(f"ç« èŠ‚'{chapter_title}'æ‰€æœ‰ç”Ÿæˆç­–ç•¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿å†…å®¹")
        template_content = self._generate_template_content(chapter)
        yield template_content

    def _generate_chapter_stream_safe(
        self,
        chapter: Dict[str, Any],
        analysis: Dict[str, Any]
    ) -> Tuple[str, str, str]:
        """
        å®‰å…¨åœ°ç”Ÿæˆå•ä¸ªç« èŠ‚ï¼ˆç”¨äºå¹¶å‘è°ƒç”¨ï¼‰
        å°†Generatorè½¬ä¸ºå®Œæ•´å­—ç¬¦ä¸²ï¼Œå¸¦è¶…æ—¶ä¿æŠ¤

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            (chapter_number, chapter_title, content)
        """
        try:
            chapter_num = chapter.get('chapter_number', '')
            chapter_title = chapter.get('title', '')

            # æ”¶é›†æµå¼ç”Ÿæˆçš„å†…å®¹
            content_parts = []
            for chunk in self.generate_chapter_content_stream(chapter, analysis):
                content_parts.append(chunk)

            content = ''.join(content_parts)
            return (chapter_num, chapter_title, content)

        except Exception as e:
            self.logger.error(f"ç« èŠ‚'{chapter.get('title')}'ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›æ¨¡æ¿å†…å®¹
            template = self._generate_template_content(chapter)
            return (chapter.get('chapter_number', ''), chapter.get('title', ''), template)

    def _build_basic_prompt(self, chapter: Dict[str, Any], analysis: Dict[str, Any]) -> str:
        """
        æ„å»ºåŸºç¡€æ¨¡å¼æç¤ºè¯ï¼ˆå¿«é€Ÿç”Ÿæˆï¼Œé€šç”¨æè¿°ï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        chapter_title = chapter.get('title', '')
        chapter_desc = chapter.get('description', '')
        content_hints = chapter.get('content_hints', [])

        # ğŸ”§ ä¿®å¤ï¼šä¿ç•™æ‰€æœ‰è¦ç‚¹ï¼Œä¸æˆªæ–­ï¼ˆä¹‹å‰åªå–å‰3ä¸ªå¯¼è‡´è¡¨æ ¼å†…å®¹ä¸¢å¤±ï¼‰
        # å¦‚æœè¦ç‚¹è¿‡å¤šï¼Œåˆ†ç»„æ˜¾ç¤ºï¼Œä½†ä¸ä¸¢å¼ƒä»»ä½•ä¿¡æ¯
        if content_hints:
            if len(content_hints) <= 5:
                hints_text = '\n'.join([f"  {i+1}. {hint}" for i, hint in enumerate(content_hints)])
            else:
                # è¶…è¿‡5ä¸ªè¦ç‚¹æ—¶ï¼Œåˆ†ç»„ä½†ä¿ç•™å®Œæ•´æ€§
                hints_text = '\n'.join([f"  {i+1}. {hint}" for i, hint in enumerate(content_hints)])
                hints_text += f"\n\nï¼ˆå…± {len(content_hints)} é¡¹è¦ç‚¹ï¼Œè¯·å…¨éƒ¨ä½“ç°åœ¨æ–¹æ¡ˆä¸­ï¼‰"
        else:
            hints_text = chapter_desc

        prompt = f"""ä¸º"{chapter_title}"ç”Ÿæˆ800-1200å­—ä¸“ä¸šæŠ€æœ¯æ–¹æ¡ˆã€‚

æ ¸å¿ƒè¦ç‚¹ï¼š
{hints_text}

è¦æ±‚ï¼š
1. **å®Œæ•´æ€§**: å¿…é¡»æ¶µç›–ä¸Šè¿°æ‰€æœ‰è¦ç‚¹ï¼Œä¸å¾—é—æ¼ä»»ä½•ä¸€é¡¹
2. **ä¸“ä¸šã€æ¸…æ™°ã€çªå‡ºæŠ€æœ¯ä¼˜åŠ¿**
3. ä½¿ç”¨ä¸­æ–‡
4. è¾“å‡ºçº¯æ–‡æœ¬æ®µè½ï¼Œé€‚åˆç›´æ¥æ”¾å…¥Wordæ–‡æ¡£
5. ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæ ‡è®°ï¼ˆå¦‚ ##ã€**ã€*ã€-ã€1.ç­‰ï¼‰
6. å¦‚éœ€åˆ—ä¸¾è¦ç‚¹ï¼Œä½¿ç”¨å¸¦åœˆæ•°å­—"â‘  â‘¡ â‘¢ â‘£ â‘¤"æˆ–"ç¬¬ä¸€ç‚¹ã€ç¬¬äºŒç‚¹"ç­‰è¡¨è¿°ï¼Œé¿å…ä½¿ç”¨(1)(2)(3)
7. å¦‚éœ€å¼ºè°ƒï¼Œä½¿ç”¨æ‹¬å·æˆ–å¼•å·ï¼Œä¸ä½¿ç”¨**åŠ ç²—**"""

        return prompt

    def _build_advanced_prompt(self, chapter: Dict[str, Any], analysis: Dict[str, Any]) -> str:
        """
        æ„å»ºè¿›é˜¶æ¨¡å¼æç¤ºè¯ï¼ˆä¸šåŠ¡å®šåˆ¶åŒ–ï¼Œç´§æ‰£éœ€æ±‚ï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        chapter_title = chapter.get('title', '')
        chapter_desc = chapter.get('description', '')
        content_hints = chapter.get('content_hints', [])
        response_tips = chapter.get('response_tips', [])

        # æå–é¡¹ç›®èƒŒæ™¯å’Œä¸šåŠ¡ä¸Šä¸‹æ–‡
        project_context = self._extract_project_context(analysis)

        # ğŸ”§ ä¿®å¤ï¼šæ ¼å¼åŒ–æ ¸å¿ƒè¦ç‚¹ - ä¿ç•™æ‰€æœ‰è¦ç‚¹ï¼Œä¸æˆªæ–­
        if content_hints:
            hints_list = '\n'.join([f"  - {hint}" for hint in content_hints])
            if len(content_hints) > 10:
                hints_list += f"\n\nï¼ˆå…± {len(content_hints)} é¡¹è¦ç‚¹ï¼Œè¯·åœ¨æ–¹æ¡ˆä¸­å…¨éƒ¨ä½“ç°ï¼Œå¯æŒ‰ç±»åˆ«åˆ†ç»„è¯´æ˜ï¼‰"
        else:
            hints_list = f"  - {chapter_desc}"

        # ğŸ”§ ä¿®å¤ï¼šæ ¼å¼åŒ–åº”ç­”æŠ€å·§ - ä¿ç•™æ‰€æœ‰æŠ€å·§
        tips_text = ""
        if response_tips:
            tips_text = "\n\nã€åº”ç­”æŠ€å·§ã€‘\n" + '\n'.join([f"  - {tip}" for tip in response_tips])

        prompt = f"""ä¸º"{chapter_title}"æ’°å†™800-1500å­—æŠ€æœ¯æ–¹æ¡ˆåº”ç­”å†…å®¹ã€‚

ã€æ ¸å¿ƒè¦ç‚¹ã€‘
{hints_list}
{tips_text}

ã€é¡¹ç›®èƒŒæ™¯ã€‘
{project_context}

ã€æ’°å†™è¦æ±‚ã€‘
1. **å®Œæ•´æ€§è¦æ±‚ï¼ˆæœ€é‡è¦ï¼‰**: å¿…é¡»æ¶µç›–ã€æ ¸å¿ƒè¦ç‚¹ã€‘ä¸­åˆ—å‡ºçš„æ‰€æœ‰é¡¹ï¼Œä¸å¾—é—æ¼ä»»ä½•ä¸€é¡¹ç»†èŠ‚æŒ‡æ ‡
2. **ä¸šåŠ¡é’ˆå¯¹æ€§**: ç´§æ‰£æ‹›æ ‡é¡¹ç›®çš„å…·ä½“åœºæ™¯å’Œéœ€æ±‚ï¼Œé¿å…é€šç”¨æŠ€æœ¯æè¿°
3. **èƒ½åŠ›è¯æ˜**: ä¼˜å…ˆä½¿ç”¨é‡åŒ–æ•°æ®ï¼ˆç”¨æˆ·æ•°ã€æ•°æ®é‡ã€é›†ç¾¤è§„æ¨¡ã€è¦†ç›–èŒƒå›´ç­‰ï¼‰å±•ç¤ºå®åŠ›
4. **å…·ä½“å¯è½åœ°**: è¯´æ˜å…·ä½“çš„äº¤ä»˜å†…å®¹ã€æŠ€æœ¯å‚æ•°ã€æœåŠ¡æ–¹å¼ã€æ›´æ–°é¢‘ç‡
5. **è¯­è¨€é£æ ¼**:
   - ç”¨è‚¯å®šé™ˆè¿°ï¼š"æˆ‘æ–¹å…·å¤‡..."ã€"å·²å®ç°..."è€Œé"æˆ‘ä»¬å°†..."
   - ç”¨æ•°æ®è¯´è¯ï¼š"Xäº¿ç”¨æˆ·ã€Yä¸ªèŠ‚ç‚¹ã€Z%è¦†ç›–ç‡"è€Œé"å¤§è§„æ¨¡ã€é«˜æ€§èƒ½"
   - çªå‡ºè¡Œä¸šç»éªŒï¼š"åœ¨XXè¡Œä¸šå¤šå¹´åº”ç”¨ç»éªŒ"
6. **å†…å®¹ç»“æ„**:
   - ç¬¬ä¸€æ®µ: ç›´æ¥å‘¼åº”è¯¥ç« èŠ‚å¯¹åº”çš„æ‹›æ ‡éœ€æ±‚æˆ–ä¸šåŠ¡åœºæ™¯
   - ä¸­é—´æ®µè½: åˆ† â‘  â‘¡ â‘¢ åˆ—ä¸¾å…·ä½“è§£å†³æ–¹æ¡ˆæˆ–èƒ½åŠ›è¯æ˜ï¼ˆå¦‚è¦ç‚¹å¤šï¼Œå¯æŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
   - æœ€åæ®µè½: ç®€è¦è¯´æ˜è¾¾æˆæ•ˆæœæˆ–ç«äº‰ä¼˜åŠ¿
7. **æ ¼å¼è§„èŒƒ**:
   - ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸ä½¿ç”¨Markdownæ ‡è®°ï¼ˆ##ã€**ã€*ã€-ç­‰ï¼‰
   - åˆ—ä¸¾æ—¶ä½¿ç”¨å¸¦åœˆæ•°å­—"â‘  â‘¡ â‘¢ â‘£ â‘¤"æˆ–"ç¬¬ä¸€ç‚¹ã€ç¬¬äºŒç‚¹"ï¼Œé¿å…ä½¿ç”¨(1)(2)(3)ä»¥å…ä¸ç« èŠ‚ç¼–å·æ··æ·†
   - å¼ºè°ƒæ—¶ä½¿ç”¨ã€ã€‘æˆ–""ï¼Œä¸ä½¿ç”¨**åŠ ç²—**"""

        return prompt

    def _extract_project_context(self, analysis: Dict[str, Any]) -> str:
        """
        ä»éœ€æ±‚åˆ†æä¸­æå–é¡¹ç›®èƒŒæ™¯å’Œä¸šåŠ¡ä¸Šä¸‹æ–‡

        Args:
            analysis: éœ€æ±‚åˆ†æç»“æœ

        Returns:
            é¡¹ç›®èƒŒæ™¯æè¿°å­—ç¬¦ä¸²
        """
        context_parts = []

        # æå–é¡¹ç›®åç§°
        project_title = analysis.get('project_title', '')
        if project_title:
            context_parts.append(f"é¡¹ç›®åç§°: {project_title}")

        # æå–é¡¹ç›®æ¦‚è¿°
        summary = analysis.get('document_summary', {})
        project_overview = summary.get('project_overview', '')
        if project_overview:
            context_parts.append(f"é¡¹ç›®æ¦‚è¿°: {project_overview}")

        # æå–æ ¸å¿ƒç›®æ ‡ï¼ˆä»ç¬¬ä¸€ä¸ªéœ€æ±‚ç±»åˆ«ä¸­ï¼‰
        categories = analysis.get('requirement_categories', [])
        if categories:
            first_category = categories[0]
            category_name = first_category.get('category', '')
            key_points = first_category.get('key_points', [])
            if category_name and key_points:
                main_goal = key_points[0] if key_points else category_name
                context_parts.append(f"æ ¸å¿ƒç›®æ ‡: {main_goal}")

        # ğŸ”§ ä¿®å¤ï¼šæå–å…³é”®æŠ€æœ¯è¦æ±‚ - ä¸å†æˆªæ–­ï¼Œä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
        key_requirements = []
        for category in categories[:3]:  # å¢åŠ åˆ°å‰3ä¸ªç±»åˆ«
            points = category.get('key_points', [])
            key_requirements.extend(points[:3])  # æ¯ä¸ªç±»åˆ«å–å‰3ä¸ªè¦ç‚¹ï¼ˆä»2å¢åŠ åˆ°3ï¼‰
        if key_requirements:
            req_text = 'ã€'.join(key_requirements[:6])  # æœ€å¤š6ä¸ªè¦æ±‚ï¼ˆä»3å¢åŠ åˆ°6ï¼‰
            if len(key_requirements) > 6:
                req_text += f" ç­‰{len(key_requirements)}é¡¹"
            context_parts.append(f"å…³é”®éœ€æ±‚: {req_text}")

        # ç»„åˆä¸Šä¸‹æ–‡
        if context_parts:
            return '\n'.join(context_parts)
        else:
            return "æŠ€æœ¯æ–¹æ¡ˆé¡¹ç›®ï¼ˆéœ€æ±‚åˆ†æä¿¡æ¯ä¸è¶³ï¼‰"

    def _generate_template_content(self, chapter: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ¨¡æ¿å†…å®¹ï¼ˆé™çº§ç­–ç•¥çš„å…œåº•æ–¹æ¡ˆï¼‰

        Args:
            chapter: ç« èŠ‚ä¿¡æ¯

        Returns:
            æ¨¡æ¿å†…å®¹
        """
        chapter_title = chapter.get('title', '')
        chapter_desc = chapter.get('description', '')
        content_hints = chapter.get('content_hints', [])

        template = f"""ã€æœ¬ç« èŠ‚å†…å®¹ç”Ÿæˆè¶…æ—¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹è¦ç‚¹æ‰‹åŠ¨è¡¥å……ã€‘

æœ¬ç« èŠ‚è¯´æ˜ï¼š{chapter_desc}

éœ€è¦åŒ…å«çš„è¦ç‚¹ï¼š
"""
        for i, hint in enumerate(content_hints, 1):
            template += f"\n{i}. {hint}"

        template += "\n\nã€è¯·åœ¨æ­¤å¤„è¡¥å……è¯¦ç»†å†…å®¹ã€‘"

        return template
