#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿¡æ¯å¡«å†™æ¨¡å— - ç²¾ç®€ç‰ˆ (ä»2098è¡Œç²¾ç®€è‡³400è¡Œä»¥å†…)

å¤„ç†é¡¹ç›®å’Œå…¬å¸ä¿¡æ¯çš„å¡«å†™ï¼Œå®ç°å…­å¤§è§„åˆ™ï¼š
- æ›¿æ¢è§„åˆ™ã€å¡«ç©ºè§„åˆ™ã€ç»„åˆè§„åˆ™ã€å˜ä½“å¤„ç†ã€ä¾‹å¤–å¤„ç†ã€åå¤„ç†

é€šè¿‡ä¾èµ–utils.pyå’Œformat_cleaner.pyå®ç°å¤ç”¨æ¶æ„ä¼˜åŒ–
"""

import re
import sys
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from docx import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
import logging

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥å…¬å…±æ¨¡å—
sys.path.append(str(Path(__file__).parent.parent.parent))

# å¯¼å…¥å¤ç”¨æ¨¡å—
from .utils import (
    FieldMapper, PatternMatcher, WordDocumentUtils,
    SmartFieldDetector, TextUtils
)
from .format_cleaner import FormatCleaner, DateFormatProcessor
from common import get_module_logger


class InfoFiller:
    """
    ä¿¡æ¯å¡«å†™å™¨ - ç²¾ç®€ç‰ˆ
    
    ä¸“æ³¨æ ¸å¿ƒçš„ä¿¡æ¯å¡«å†™åŠŸèƒ½ï¼Œé€šè¿‡å¤ç”¨æ¨¡å—å®ç°å·¥å…·å‡½æ•°å’Œæ ¼å¼å¤„ç†
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ä¿¡æ¯å¡«å†™å™¨"""
        self.logger = get_module_logger("info_filler")
        self.field_mapper = FieldMapper()
        self.pattern_matcher = PatternMatcher()
        self.format_cleaner = FormatCleaner()
        self.info = {}  # ç»Ÿä¸€ä¿¡æ¯å­—å…¸

        # å­—æ®µå˜ä½“æ˜ å°„ (æ ¸å¿ƒé…ç½®)
        self.field_variants = self._create_field_variants()

        # ä¾›åº”å•†åç§°çš„æ‰©å±•åŒ¹é…æ¨¡å¼ï¼ˆæ”¯æŒå¸¦å…¬ç« ã€ç›–ç« çš„å˜ä½“ï¼‰
        self.company_name_extended_patterns = [
            r'ä¾›åº”å•†åç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',  # ä¾›åº”å•†åç§°ï¼ˆåŠ ç›–å…¬ç« ï¼‰
            r'ä¾›åº”å•†å…¨ç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',
            r'æŠ•æ ‡äººåç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',  # æŠ•æ ‡äººåç§°ï¼ˆå…¬ç« ï¼‰
            r'å…¬å¸åç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',
            r'å•ä½åç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',
            r'åº”ç­”äººåç§°(?:\s*[ï¼ˆ(][^ï¼‰)]*[å…¬ç›–]ç« [^ï¼‰)]*[ï¼‰)])?',
        ]
        
    def _create_field_variants(self) -> Dict[str, List[str]]:
        """åˆ›å»ºå­—æ®µå˜ä½“æ˜ å°„"""
        return {
            # ä¾›åº”å•†åç§°å˜ä½“ (12ç§)
            'companyName': [
                'ä¾›åº”å•†åç§°', 'ä¾›åº”å•†å…¨ç§°', 'æŠ•æ ‡äººåç§°', 'å…¬å¸åç§°', 
                'å•ä½åç§°', 'åº”ç­”äººåç§°', 'ä¾›åº”å•†åç§°ï¼ˆç›–ç« ï¼‰',
                'ä¾›åº”å•†åç§°ï¼ˆå…¬ç« ï¼‰', 'å…¬å¸åç§°ï¼ˆç›–ç« ï¼‰',
                'æŠ•æ ‡äººåç§°ï¼ˆç›–ç« ï¼‰', 'æŠ•æ ‡äººåç§°ï¼ˆå…¬ç« ï¼‰',
                'å•ä½åç§°ï¼ˆç›–ç« ï¼‰', 'å•ä½åç§°ï¼ˆå…¬ç« ï¼‰'
            ],
            # å…¶ä»–å­—æ®µå˜ä½“
            'email': ['é‚®ç®±', 'é‚®ä»¶', 'ç”µå­é‚®ä»¶', 'ç”µå­é‚®ç®±', 'email', 'Email', 'E-mail', 'E-Mail', 'é‚®ä»¶åœ°å€'],
            'phone': ['ç”µè¯', 'è”ç³»ç”µè¯', 'å›ºå®šç”µè¯', 'åŠå…¬ç”µè¯', 'åº§æœº', 'ç”µè¯å·ç ', 'è”ç³»æ–¹å¼'],
            'fax': ['ä¼ çœŸ', 'ä¼ çœŸå·ç ', 'ä¼ çœŸç”µè¯', 'FAX', 'ä¼ çœŸå·', 'fax', 'Fax'],
            'address': ['åœ°å€', 'è”ç³»åœ°å€', 'åŠå…¬åœ°å€', 'æ³¨å†Œåœ°å€', 'å…¬å¸åœ°å€', 'è¯¦ç»†åœ°å€', 'é€šè®¯åœ°å€', 'ä¾›åº”å•†åœ°å€'],
            'postalCode': ['é‚®æ”¿ç¼–ç ', 'é‚®ç¼–', 'é‚®ç '],
            'date': ['æ—¥æœŸ', 'æ—¥ æœŸ', 'æ—¥  æœŸ', 'æ—¥   æœŸ', 'æ—¥    æœŸ', 'æ—¥     æœŸ', 'æ—¶é—´', 'ç­¾ç½²æ—¥æœŸ', 'æŠ•æ ‡æ—¥æœŸ'],
            'purchaserName': ['é‡‡è´­äºº', 'æ‹›æ ‡äºº', 'é‡‡è´­å•ä½', 'æ‹›æ ‡å•ä½', 'ä¸šä¸»', 'ç”²æ–¹'],
            'projectName': ['é¡¹ç›®åç§°', 'é¡¹ç›®å', 'å·¥ç¨‹åç§°', 'æ ‡çš„åç§°', 'é‡‡è´­é¡¹ç›®åç§°', 'æ‹›æ ‡é¡¹ç›®åç§°'],
            'projectNumber': ['é¡¹ç›®ç¼–å·', 'é‡‡è´­ç¼–å·', 'æ‹›æ ‡ç¼–å·', 'é¡¹ç›®å·', 'æ ‡ä¹¦ç¼–å·', 'å·¥ç¨‹ç¼–å·'],
            # å¤‡ä»½ç‰ˆæœ¬ä¸­çš„é‡è¦å­—æ®µ
            'establishDate': ['æˆç«‹æ—¶é—´', 'æˆç«‹æ—¥æœŸ', 'æ³¨å†Œæ—¶é—´', 'æ³¨å†Œæ—¥æœŸ'],
            'businessScope': ['ç»è¥èŒƒå›´', 'ä¸šåŠ¡èŒƒå›´', 'ç»è¥é¡¹ç›®'],
            'legalRepresentative': ['æ³•å®šä»£è¡¨äºº', 'æ³•äººä»£è¡¨', 'æ³•äºº'],
            'authorizedPersonName': ['ä¾›åº”å•†ä»£è¡¨å§“å', 'æˆæƒä»£è¡¨å§“å', 'ä»£è¡¨å§“å', 'æˆæƒä»£è¡¨'],
            'position': ['èŒåŠ¡', 'èŒä½', 'èŒç§°'],
        }
    
    def fill_info(self, doc: Document, company_info: Dict[str, Any], 
                  project_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¡«å†™æ–‡æ¡£ä¿¡æ¯ - ä¸»å¤„ç†æµç¨‹
        
        Args:
            doc: Wordæ–‡æ¡£å¯¹è±¡
            company_info: å…¬å¸ä¿¡æ¯å­—å…¸
            project_info: é¡¹ç›®ä¿¡æ¯å­—å…¸
            
        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        self.logger.info("ğŸ›  ç»Ÿä¸€å­—æ®µæ˜ å°„åˆå§‹åŒ–: 32 ä¸ªå­—æ®µ")
        
        # åˆ›å»ºç»Ÿä¸€å­—æ®µæ˜ å°„
        self.info = self._create_unified_field_mapping(company_info, project_info)
        
        # åˆå§‹åŒ–ç»Ÿè®¡
        stats = {
            'total_replacements': 0,
            'replacement_rules': 0,
            'fill_rules': 0, 
            'combination_rules': 0,
            'skipped_fields': 0,
            'none': 0
        }
        
        # å¤„ç†æ®µè½
        self.logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†æ–‡æ¡£: {len([p for p in doc.paragraphs if p.text.strip()])} ä¸ªéç©ºæ®µè½, 0 ä¸ªè¡¨æ ¼")
        
        for i, paragraph in enumerate(doc.paragraphs):
            if paragraph.text.strip():
                self.logger.info(f"ğŸ” [è°ƒè¯•] å¤„ç†æ®µè½ {i+1}: {paragraph.text.strip()[:100]}...")
                paragraph_stats = self._process_paragraph(paragraph, self.info)
                if paragraph_stats['total_replacements'] > 0:
                    self.logger.info(f"ğŸ‰ [è°ƒè¯•] æ®µè½ {i+1} å¤„ç†æˆåŠŸ: {paragraph_stats}")
                for key, value in paragraph_stats.items():
                    stats[key] = stats.get(key, 0) + value
        
        # å¤„ç†è¡¨æ ¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
        for table in doc.tables:
            table_stats = self._process_table(table, self.info)
            for key, value in table_stats.items():
                stats[key] = stats.get(key, 0) + value
        
        # åå¤„ç†ï¼šæ¸…ç†å¤šä½™çš„å ä½ç¬¦å’Œè£…é¥°æ€§æ ¼å¼
        self._post_process(doc)
        
        # æ—¥å¿—è¾“å‡º
        self.logger.info(f"ğŸ“Š æ–‡æ¡£å¤„ç†ç»Ÿè®¡: {stats}")
        self.logger.info(f"âœ… æˆåŠŸå¤„ç†äº† {stats['total_replacements']} ä¸ªå­—æ®µ")
        self.logger.info(f"  - å¡«ç©ºè§„åˆ™: {stats['fill_rules']} ä¸ª")
        self.logger.info(f"  - ç»„åˆè§„åˆ™: {stats['combination_rules']} ä¸ª")
        
        return stats
    
    def _create_unified_field_mapping(self, company_info: Dict[str, Any],
                                     project_info: Dict[str, Any]) -> Dict[str, str]:
        """åˆ›å»ºç»Ÿä¸€çš„å­—æ®µæ˜ å°„"""
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè¾“å…¥çš„company_infoæ•°æ®
        self.logger.info(f"ğŸ” [è°ƒè¯•] è¾“å…¥çš„company_infoæ•°æ®: {company_info}")
        self.logger.info(f"ğŸ” [è°ƒè¯•] è¾“å…¥çš„project_infoæ•°æ®: {project_info}")

        info = {}
        
        # æ˜ å°„å…¬å¸ä¿¡æ¯ - ç›´æ¥ä½¿ç”¨åŸæœ‰çš„å­—æ®µåæ˜ å°„
        info['å…¬å¸åç§°'] = company_info.get('companyName', '')
        info['é‚®ç®±'] = company_info.get('email', '')
        info['ä¼ çœŸ'] = company_info.get('fax', '')
        info['é‚®æ”¿ç¼–ç '] = company_info.get('postalCode', '')
        info['æˆç«‹æ—¶é—´'] = company_info.get('establishDate', '')
        info['ç»è¥èŒƒå›´'] = company_info.get('businessScope', '')
        info['æ³•å®šä»£è¡¨äºº'] = company_info.get('legalRepresentative', '')
        info['è¢«æˆæƒäººå§“å'] = company_info.get('authorizedPersonName', '')
        info['è¢«æˆæƒäººèŒåŠ¡'] = company_info.get('authorizedPersonPosition', '')
        info['æ³•å®šä»£è¡¨äººèŒä½'] = company_info.get('legalRepresentativePosition', '')
        
        # å¤„ç†å¤šæºæ˜ å°„å­—æ®µ
        info['åœ°å€'] = (company_info.get('address') or 
                      company_info.get('registeredAddress') or 
                      company_info.get('officeAddress', ''))
        info['ç”µè¯'] = (company_info.get('fixedPhone') or
                      company_info.get('phone', ''))

        # è°ƒè¯•ç”µè¯å­—æ®µæ˜ å°„
        self.logger.info(f"ğŸ” [è°ƒè¯•] ç”µè¯å­—æ®µæ˜ å°„: fixedPhone={company_info.get('fixedPhone')}, phone={company_info.get('phone')}, æœ€ç»ˆå€¼={info['ç”µè¯']}")
        
        # æ˜ å°„é¡¹ç›®ä¿¡æ¯
        info['é¡¹ç›®åç§°'] = project_info.get('projectName', '')
        info['é¡¹ç›®ç¼–å·'] = project_info.get('projectNumber', '')
        info['æ—¥æœŸ'] = project_info.get('date', '')
        info['é‡‡è´­äººåç§°'] = project_info.get('purchaserName', '')
        
        # æ¸…ç†ç©ºå€¼
        info = {k: v for k, v in info.items() if v and str(v).strip()}
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        self.logger.info(f"ğŸ—ºï¸ å­—æ®µæ˜ å°„ç»“æœ: {list(info.keys())}")
        for key, value in info.items():
            self.logger.info(f"  - {key}: {value}")
        
        return info
    
    def _process_paragraph(self, paragraph: Paragraph, info: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†æ®µè½ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
        
        Args:
            paragraph: Wordæ®µè½å¯¹è±¡
            info: ä¿¡æ¯å­—å…¸
            
        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {'total_replacements': 0, 'replacement_rules': 0, 'fill_rules': 0, 'combination_rules': 0}
        
        # è·³è¿‡å¤„ç†
        if self._should_skip(paragraph.text):
            return stats
            
        processed = False
        final_type = 'none'

        # 1. å°è¯•ç»„åˆæ›¿æ¢è§„åˆ™
        if self._try_combination_rule(paragraph, info):
            processed = True
            final_type = 'combination_rules'
            stats['combination_rules'] += 1
            stats['total_replacements'] += 1

        # 2. å°è¯•å•å­—æ®µæ›¿æ¢è§„åˆ™ï¼ˆå³ä½¿ç»„åˆè§„åˆ™å·²å¤„ç†ï¼Œä¹Ÿè¦å°è¯•ï¼‰
        if self._try_replacement_rule(paragraph, info):
            processed = True
            # å¦‚æœå·²ç»æœ‰ç»„åˆè§„åˆ™ï¼Œä¿æŒç»„åˆè§„åˆ™ç±»å‹ï¼Œå¦åˆ™è®¾ä¸ºæ›¿æ¢è§„åˆ™
            if final_type == 'none':
                final_type = 'replacement_rules'
                stats['replacement_rules'] += 1
                stats['total_replacements'] += 1

        # 3. å°è¯•å¡«ç©ºè§„åˆ™ï¼ˆä»…åœ¨å‰ä¸¤ä¸ªéƒ½æ²¡æœ‰å¤„ç†æ—¶æ‰å°è¯•ï¼‰
        if not processed and self._try_fill_rule(paragraph, info):
            processed = True
            final_type = 'fill_rules'
            stats['fill_rules'] += 1
            stats['total_replacements'] += 1

        return stats
    
    def _should_skip(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡å¤„ç†"""
        import re

        # ä½¿ç”¨ç²¾ç¡®åŒ¹é…æ¨¡å¼ï¼Œé¿å…è¯¯è·³è¿‡åˆæ³•å¡«ç©ºå­—æ®µ
        skip_patterns = [
            r'ç­¾å­—\s*[ï¼š:]?\s*$',      # ç­¾å­—: æˆ– ç­¾å­—ï¼ˆè¡Œå°¾ï¼‰
            r'ç­¾å­—å¤„',                 # ç­¾å­—å¤„
            r'ç­¾å\s*[ï¼š:]?\s*$',      # ç­¾å: æˆ– ç­¾åï¼ˆè¡Œå°¾ï¼‰
            r'ç­¾åå¤„',                 # ç­¾åå¤„
            r'ç­¾ç« \s*[ï¼š:]?\s*$',      # ç­¾ç« : æˆ– ç­¾ç« ï¼ˆè¡Œå°¾ï¼‰
            r'ç›–ç« å¤„',                 # ç›–ç« å¤„
        ]

        # ç®€å•å…³é”®è¯åŒ¹é…ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        simple_keywords = [
            'æ‹›æ ‡ä»£ç†', 'é‡‡è´­ä»£ç†', 'ä¸šä¸»', 'å‘åŒ…äºº', 'å§”æ‰˜äºº'
        ]

        text_lower = text.lower()

        # æ£€æŸ¥ç²¾ç¡®æ¨¡å¼
        for pattern in skip_patterns:
            if re.search(pattern, text_lower):
                return True

        # æ£€æŸ¥ç®€å•å…³é”®è¯
        for keyword in simple_keywords:
            if keyword in text_lower:
                return True

        return False

    def _detect_position_context(self, paragraph_text: str) -> str:
        """
        æ£€æµ‹æ®µè½ä¸­çš„èŒä½ä¸Šä¸‹æ–‡ï¼ŒåŒºåˆ†è¢«æˆæƒäººèŒåŠ¡å’Œæ³•å®šä»£è¡¨äººèŒä½

        Args:
            paragraph_text: æ®µè½æ–‡æœ¬

        Returns:
            'authorized_person': è¢«æˆæƒäººä¸Šä¸‹æ–‡
            'legal_representative': æ³•å®šä»£è¡¨äººä¸Šä¸‹æ–‡ï¼ˆé»˜è®¤ï¼‰
        """
        try:
            if not paragraph_text or not isinstance(paragraph_text, str):
                self.logger.warning(f"âš ï¸  èŒä½ä¸Šä¸‹æ–‡æ£€æµ‹ï¼šæ— æ•ˆçš„æ®µè½æ–‡æœ¬è¾“å…¥")
                return 'legal_representative'

            text = paragraph_text.strip()
            if not text:
                self.logger.warning(f"âš ï¸  èŒä½ä¸Šä¸‹æ–‡æ£€æµ‹ï¼šæ®µè½æ–‡æœ¬ä¸ºç©º")
                return 'legal_representative'

            # è¢«æˆæƒäººä¸Šä¸‹æ–‡å…³é”®å­—æ¨¡å¼ (å¢å¼ºç‰ˆ)
            authorized_person_patterns = [
                r'æˆæƒ.*?ä»£è¡¨.*?[èŒä½åŠ¡ç§°]',          # "æˆæƒä»£è¡¨èŒåŠ¡"
                r'ä¸ºæˆ‘æ–¹.*?æˆæƒ.*?ä»£è¡¨',             # "ä¸ºæˆ‘æ–¹æˆæƒä»£è¡¨"
                r'ä¸ºæˆ‘æ–¹ä»£è¡¨.*?[èŒä½åŠ¡ç§°]',           # "ä¸ºæˆ‘æ–¹ä»£è¡¨èŒåŠ¡"
                r'å‚åŠ .*?ä»£è¡¨.*?[èŒä½åŠ¡ç§°]',          # "å‚åŠ æŠ•æ ‡ä»£è¡¨èŒåŠ¡"
                r'æˆæƒ.*?[ï¼ˆ(].*?[ï¼‰)].*?[èŒä½åŠ¡ç§°]',   # "æˆæƒï¼ˆå¼ ä¸‰ï¼‰èŒåŠ¡"
                r'è¢«æˆæƒ.*?[èŒä½åŠ¡ç§°]',              # "è¢«æˆæƒäººèŒåŠ¡"
                r'å•†åŠ¡ä»£è¡¨.*?[èŒä½åŠ¡ç§°]',             # "å•†åŠ¡ä»£è¡¨èŒåŠ¡"
                r'æˆæƒ.*?[ï¼ˆ(].*?å§“å.*?èŒ[ä½åŠ¡ç§°]',   # "æˆæƒï¼ˆå§“åã€èŒä½ï¼‰"
                r'ä¸ºæˆ‘æ–¹.*?æˆæƒ.*?[ï¼ˆ(].*?èŒ[ä½åŠ¡ç§°]', # "ä¸ºæˆ‘æ–¹æˆæƒï¼ˆèŒä½ã€èŒç§°ï¼‰"
            ]

            # æ³•å®šä»£è¡¨äººä¸Šä¸‹æ–‡å…³é”®å­—æ¨¡å¼
            legal_representative_patterns = [
                r'æ³•å®šä»£è¡¨äºº.*?èŒä½',           # "æ³•å®šä»£è¡¨äººèŒä½"
                r'æ³•äºº.*?èŒä½',                # "æ³•äººèŒä½"
                r'ç³».*?æ³•å®šä»£è¡¨äºº.*?èŒä½',      # "ç³»æˆ‘å…¬å¸æ³•å®šä»£è¡¨äººèŒä½"
                r'å…¬å¸.*?æ³•å®šä»£è¡¨äºº.*?èŒä½',    # "å…¬å¸æ³•å®šä»£è¡¨äººèŒä½"
            ]

            self.logger.debug(f"ğŸ” æ£€æµ‹èŒä½ä¸Šä¸‹æ–‡: '{text[:100]}{'...' if len(text) > 100 else ''}'")

            # æ£€æŸ¥è¢«æˆæƒäººä¸Šä¸‹æ–‡
            try:
                for pattern in authorized_person_patterns:
                    if re.search(pattern, text):
                        self.logger.info(f"âœ… è¯†åˆ«ä¸ºè¢«æˆæƒäººä¸Šä¸‹æ–‡: '{pattern}' åŒ¹é…")
                        return 'authorized_person'
            except re.error as e:
                self.logger.error(f"âŒ è¢«æˆæƒäººæ¨¡å¼åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")

            # æ£€æŸ¥æ³•å®šä»£è¡¨äººä¸Šä¸‹æ–‡
            try:
                for pattern in legal_representative_patterns:
                    if re.search(pattern, text):
                        self.logger.info(f"âœ… è¯†åˆ«ä¸ºæ³•å®šä»£è¡¨äººä¸Šä¸‹æ–‡: '{pattern}' åŒ¹é…")
                        return 'legal_representative'
            except re.error as e:
                self.logger.error(f"âŒ æ³•å®šä»£è¡¨äººæ¨¡å¼åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")

            # é»˜è®¤æƒ…å†µï¼šå¦‚æœæ²¡æœ‰æ˜ç¡®ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨æ³•å®šä»£è¡¨äºº
            return 'legal_representative'

        except Exception as e:
            self.logger.error(f"âŒ èŒä½ä¸Šä¸‹æ–‡æ£€æµ‹å‘ç”Ÿå¼‚å¸¸: {e}")
            return 'legal_representative'

    def _try_combination_rule(self, paragraph: Paragraph, info: Dict[str, Any]) -> bool:
        """å°è¯•åº”ç”¨ç»„åˆæ›¿æ¢è§„åˆ™ - å‚è€ƒå¤‡ä»½ç‰ˆæœ¬çš„ç‹¬ç«‹æ¨¡å¼æ£€æŸ¥"""
        text = paragraph.text
        processed_any = False

        # ç»„åˆæ¨¡å¼1ï¼šä¾›åº”å•†åç§°ã€åœ°å€
        pattern1 = r'[ï¼ˆ(]\s*(?:ä¾›åº”å•†åç§°|å…¬å¸åç§°|å•ä½åç§°)\s*[ã€ï¼Œ]\s*(?:åœ°å€|è”ç³»åœ°å€)\s*[ï¼‰)]'
        if re.search(pattern1, text):
            self.logger.debug(f"ğŸ¯ æ£€æµ‹åˆ°ä¾›åº”å•†åç§°åœ°å€ç»„åˆæ¨¡å¼: '{text[:50]}...'")
            company_name = info.get('å…¬å¸åç§°', '')
            address = info.get('åœ°å€', '')
            self.logger.debug(f"ğŸ“Š å­—æ®µæ•°æ®: å…¬å¸åç§°='{company_name}', åœ°å€='{address}'")

            if company_name and address:
                replacement = f"ï¼ˆ{company_name}ã€{address}ï¼‰"
                success = WordDocumentUtils.precise_replace(paragraph, pattern1, replacement, self.logger)
                if success:
                    self.logger.info(f"ğŸ”„ ç»„åˆè§„åˆ™æ›¿æ¢æˆåŠŸ: ä¾›åº”å•†åç§°ã€åœ°å€ -> {replacement}")
                    processed_any = True
            else:
                missing_fields = []
                if not company_name:
                    missing_fields.append('å…¬å¸åç§°')
                if not address:
                    missing_fields.append('åœ°å€')
                self.logger.warning(f"âš ï¸ ä¾›åº”å•†åç§°åœ°å€ç»„åˆç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")

        # ç»„åˆæ¨¡å¼2ï¼šé¡¹ç›®åç§°ã€é¡¹ç›®ç¼–å·
        pattern2 = r'[ï¼ˆ(]\s*(?:é¡¹ç›®åç§°|å·¥ç¨‹åç§°)\s*[ã€ï¼Œ]\s*(?:é¡¹ç›®ç¼–å·|æ‹›æ ‡ç¼–å·|é‡‡è´­ç¼–å·)\s*[ï¼‰)]'
        if re.search(pattern2, text):
            self.logger.debug(f"ğŸ¯ æ£€æµ‹åˆ°é¡¹ç›®åç§°ç¼–å·ç»„åˆæ¨¡å¼: '{text[:50]}...'")
            project_name = info.get('é¡¹ç›®åç§°', '')
            project_number = info.get('é¡¹ç›®ç¼–å·', '')
            self.logger.debug(f"ğŸ“Š å­—æ®µæ•°æ®: é¡¹ç›®åç§°='{project_name}', é¡¹ç›®ç¼–å·='{project_number}'")

            if project_name and project_number:
                replacement = f"ï¼ˆ{project_name}ã€{project_number}ï¼‰"
                success = WordDocumentUtils.precise_replace(paragraph, pattern2, replacement, self.logger)
                if success:
                    self.logger.info(f"ğŸ”„ ç»„åˆè§„åˆ™æ›¿æ¢æˆåŠŸ: é¡¹ç›®åç§°ã€é¡¹ç›®ç¼–å· -> {replacement}")
                    processed_any = True
            else:
                missing_fields = []
                if not project_name:
                    missing_fields.append('é¡¹ç›®åç§°')
                if not project_number:
                    missing_fields.append('é¡¹ç›®ç¼–å·')
                self.logger.warning(f"âš ï¸ é¡¹ç›®åç§°ç¼–å·ç»„åˆç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")

        # ç»„åˆæ¨¡å¼3ï¼šè”ç³»ç”µè¯ã€é‚®ç®±
        pattern3 = r'[ï¼ˆ(]\s*(?:è”ç³»ç”µè¯|ç”µè¯)\s*[ã€ï¼Œ]\s*(?:é‚®ç®±|ç”µå­é‚®ä»¶)\s*[ï¼‰)]'
        if re.search(pattern3, text):
            self.logger.debug(f"ğŸ¯ æ£€æµ‹åˆ°ç”µè¯é‚®ç®±ç»„åˆæ¨¡å¼: '{text[:50]}...'")
            phone = info.get('ç”µè¯', '')
            email = info.get('é‚®ç®±', '')
            self.logger.debug(f"ğŸ“Š å­—æ®µæ•°æ®: ç”µè¯='{phone}', é‚®ç®±='{email}'")

            if phone and email:
                replacement = f"ï¼ˆ{phone}ã€{email}ï¼‰"
                success = WordDocumentUtils.precise_replace(paragraph, pattern3, replacement, self.logger)
                if success:
                    self.logger.info(f"ğŸ”„ ç»„åˆè§„åˆ™æ›¿æ¢æˆåŠŸ: è”ç³»ç”µè¯ã€é‚®ç®± -> {replacement}")
                    processed_any = True
            else:
                missing_fields = []
                if not phone:
                    missing_fields.append('ç”µè¯')
                if not email:
                    missing_fields.append('é‚®ç®±')
                self.logger.warning(f"âš ï¸ ç”µè¯é‚®ç®±ç»„åˆç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")

        # ç»„åˆæ¨¡å¼4ï¼šèŒä½ã€èŒç§° - æ™ºèƒ½ä¸Šä¸‹æ–‡è¯†åˆ«
        position_pattern = r'[ï¼ˆ(]\s*èŒ[ä½åŠ¡ç§°]\s*[ã€ï¼Œ]\s*èŒ[ä½åŠ¡ç§°]\s*[ï¼‰)]'
        if re.search(position_pattern, text):
            self.logger.debug(f"ğŸ¯ æ£€æµ‹åˆ°èŒä½ç»„åˆæ¨¡å¼: '{text[:50]}...'")

            try:
                # æ™ºèƒ½è¯†åˆ«ä¸Šä¸‹æ–‡
                context = self._detect_position_context(text)
                self.logger.debug(f"ğŸ§  ä¸Šä¸‹æ–‡è¯†åˆ«ç»“æœ: {context}")

                # æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ•°æ®æº
                if context == 'authorized_person':
                    position = info.get('è¢«æˆæƒäººèŒåŠ¡', '') or info.get('authorizedPersonPosition', '')
                    if position:
                        self.logger.info(f"ğŸ“ ä½¿ç”¨è¢«æˆæƒäººèŒåŠ¡: '{position}'")
                    else:
                        self.logger.warning(f"âš ï¸ è¢«æˆæƒäººèŒåŠ¡ä¸ºç©ºï¼Œå°è¯•æ³•å®šä»£è¡¨äººèŒä½")
                        position = info.get('æ³•å®šä»£è¡¨äººèŒä½', '') or info.get('legalRepresentativePosition', '')
                        if position:
                            self.logger.info(f"ğŸ“ å›é€€ä½¿ç”¨æ³•å®šä»£è¡¨äººèŒä½: '{position}'")
                else:  # legal_representative
                    position = info.get('æ³•å®šä»£è¡¨äººèŒä½', '') or info.get('legalRepresentativePosition', '')
                    if position:
                        self.logger.info(f"ğŸ“ ä½¿ç”¨æ³•å®šä»£è¡¨äººèŒä½: '{position}'")
                    else:
                        self.logger.warning(f"âš ï¸ æ³•å®šä»£è¡¨äººèŒä½ä¸ºç©ºï¼Œå°è¯•è¢«æˆæƒäººèŒåŠ¡")
                        position = info.get('è¢«æˆæƒäººèŒåŠ¡', '') or info.get('authorizedPersonPosition', '')
                        if position:
                            self.logger.info(f"ğŸ“ å›é€€ä½¿ç”¨è¢«æˆæƒäººèŒåŠ¡: '{position}'")

                if position:
                    replacement = f"ï¼ˆ{position}ã€{position}ï¼‰"
                    success = WordDocumentUtils.precise_replace(paragraph, position_pattern, replacement, self.logger)
                    if success:
                        self.logger.info(f"æ™ºèƒ½èŒä½ç»„åˆæ›¿æ¢: ï¼ˆèŒä½ã€èŒç§°ï¼‰ â†’ ï¼ˆ{position}ã€{position}ï¼‰")
                        processed_any = True
                else:
                    self.logger.warning(f"âš ï¸ æ‰€æœ‰èŒä½æ•°æ®æºéƒ½ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")

            except Exception as e:
                self.logger.error(f"âŒ èŒä½ç»„åˆæ›¿æ¢å‘ç”Ÿå¼‚å¸¸: {e}")

        # ç»„åˆæ¨¡å¼5ï¼šå§“åã€èŒä½ - æ™ºèƒ½ä¸Šä¸‹æ–‡è¯†åˆ«
        name_position_pattern = r'[ï¼ˆ(]\s*å§“å\s*[ã€ï¼Œ]\s*èŒ[ä½åŠ¡ç§°]\s*[ï¼‰)]'
        if re.search(name_position_pattern, text):
            self.logger.debug(f"ğŸ¯ æ£€æµ‹åˆ°å§“åèŒä½ç»„åˆæ¨¡å¼: '{text[:50]}...'")

            try:
                # æ™ºèƒ½è¯†åˆ«ä¸Šä¸‹æ–‡
                context = self._detect_position_context(text)
                self.logger.debug(f"ğŸ§  ä¸Šä¸‹æ–‡è¯†åˆ«ç»“æœ: {context}")

                # æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ•°æ®æº
                if context == 'authorized_person':
                    name = info.get('è¢«æˆæƒäººå§“å', '') or info.get('authorizedPersonName', '')
                    position = info.get('è¢«æˆæƒäººèŒåŠ¡', '') or info.get('authorizedPersonPosition', '')
                    if name and position:
                        self.logger.info(f"ğŸ“ ä½¿ç”¨è¢«æˆæƒäººä¿¡æ¯: '{name}', '{position}'")
                    elif not name:
                        name = info.get('æ³•å®šä»£è¡¨äºº', '') or info.get('legalRepresentativeName', '')
                        if name:
                            self.logger.warning(f"âš ï¸ è¢«æˆæƒäººå§“åä¸ºç©ºï¼Œä½¿ç”¨æ³•å®šä»£è¡¨äºº: '{name}'")
                    elif not position:
                        position = info.get('æ³•å®šä»£è¡¨äººèŒä½', '') or info.get('legalRepresentativePosition', '')
                        if position:
                            self.logger.warning(f"âš ï¸ è¢«æˆæƒäººèŒåŠ¡ä¸ºç©ºï¼Œä½¿ç”¨æ³•å®šä»£è¡¨äººèŒä½: '{position}'")
                else:  # legal_representative
                    name = info.get('æ³•å®šä»£è¡¨äºº', '') or info.get('legalRepresentativeName', '')
                    position = info.get('æ³•å®šä»£è¡¨äººèŒä½', '') or info.get('legalRepresentativePosition', '')
                    if name and position:
                        self.logger.info(f"ğŸ“ ä½¿ç”¨æ³•å®šä»£è¡¨äººä¿¡æ¯: '{name}', '{position}'")
                    elif not name:
                        name = info.get('è¢«æˆæƒäººå§“å', '') or info.get('authorizedPersonName', '')
                        if name:
                            self.logger.warning(f"âš ï¸ æ³•å®šä»£è¡¨äººå§“åä¸ºç©ºï¼Œä½¿ç”¨è¢«æˆæƒäºº: '{name}'")
                    elif not position:
                        position = info.get('è¢«æˆæƒäººèŒåŠ¡', '') or info.get('authorizedPersonPosition', '')
                        if position:
                            self.logger.warning(f"âš ï¸ æ³•å®šä»£è¡¨äººèŒä½ä¸ºç©ºï¼Œä½¿ç”¨è¢«æˆæƒäººèŒåŠ¡: '{position}'")

                if name and position:
                    replacement = f"ï¼ˆ{name}ã€{position}ï¼‰"
                    success = WordDocumentUtils.precise_replace(paragraph, name_position_pattern, replacement, self.logger)
                    if success:
                        self.logger.info(f"æ™ºèƒ½å§“åèŒä½ç»„åˆæ›¿æ¢: ï¼ˆå§“åã€èŒä½ï¼‰ â†’ ï¼ˆ{name}ã€{position}ï¼‰")
                        processed_any = True
                else:
                    self.logger.warning(f"âš ï¸ å§“åæˆ–èŒä½æ•°æ®ä¸ºç©º: å§“å={name}, èŒä½={position}")

            except Exception as e:
                self.logger.error(f"âŒ å§“åèŒä½ç»„åˆæ›¿æ¢å‘ç”Ÿå¼‚å¸¸: {e}")

        return processed_any
    
    def _try_replacement_rule(self, paragraph: Paragraph, info: Dict[str, Any]) -> bool:
        """å°è¯•åº”ç”¨æ‹¬å·æ›¿æ¢è§„åˆ™ - ç´¯ç§¯å¤„ç†æ¨¡å¼"""
        text = paragraph.text
        replacement_count = 0

        # æ‹¬å·æ›¿æ¢è§„åˆ™
        for field_name, value in info.items():
            if not value:
                continue

            # è·å–å­—æ®µå˜ä½“ - ç›´æ¥ä½¿ç”¨å­—æ®µåè¿›è¡Œæ˜ å°„
            field_mapping = {
                'å…¬å¸åç§°': self.field_variants['companyName'],
                'é‚®ç®±': self.field_variants['email'],
                'ç”µè¯': self.field_variants['phone'],
                'ä¼ çœŸ': self.field_variants['fax'],
                'åœ°å€': self.field_variants['address'],
                'é‚®æ”¿ç¼–ç ': self.field_variants['postalCode'],
                'æ—¥æœŸ': self.field_variants['date'],
                'é‡‡è´­äººåç§°': self.field_variants['purchaserName'],
                'é¡¹ç›®åç§°': self.field_variants['projectName'],
                'é¡¹ç›®ç¼–å·': self.field_variants['projectNumber']
            }
            field_variants = field_mapping.get(field_name, [])

            if not field_variants:
                continue

            # æ„å»ºæ‹¬å·åŒ¹é…æ¨¡å¼
            variants_pattern = '|'.join(re.escape(variant) for variant in field_variants)
            bracket_pattern = f'[ï¼ˆ(]\\s*(?:{variants_pattern})\\s*[ï¼‰)]'

            if re.search(bracket_pattern, text):
                replacement_text = f'ï¼ˆ{value}ï¼‰'
                success = WordDocumentUtils.precise_replace(paragraph, bracket_pattern, replacement_text, self.logger)
                if success:
                    self.logger.info(f"ğŸ”„ æ‹¬å·æ›¿æ¢æˆåŠŸ: {field_name} -> {value}")
                    replacement_count += 1

        return replacement_count > 0
    
    def _try_fill_rule(self, paragraph: Paragraph, info: Dict[str, Any]) -> bool:
        """å°è¯•åº”ç”¨å¡«ç©ºè§„åˆ™ - ç´¯ç§¯å¤„ç†æ¨¡å¼"""
        text = paragraph.text
        fill_count = 0

        # å¡«ç©ºè§„åˆ™å¤„ç†
        for field_name, value in info.items():
            if not value:
                self.logger.info(f"ğŸ” [è°ƒè¯•] è·³è¿‡ç©ºå­—æ®µ: {field_name}")
                continue

            self.logger.info(f"ğŸ” [è°ƒè¯•] å°è¯•å¡«ç©ºå­—æ®µ: {field_name} = {value}")

            # è·å–å­—æ®µå˜ä½“ - ç›´æ¥ä½¿ç”¨å­—æ®µåè¿›è¡Œæ˜ å°„
            field_mapping = {
                'å…¬å¸åç§°': self.field_variants['companyName'],
                'é‚®ç®±': self.field_variants['email'],
                'ç”µè¯': self.field_variants['phone'],
                'ä¼ çœŸ': self.field_variants['fax'],
                'åœ°å€': self.field_variants['address'],
                'é‚®æ”¿ç¼–ç ': self.field_variants['postalCode'],
                'æ—¥æœŸ': self.field_variants['date'],
                'é‡‡è´­äººåç§°': self.field_variants['purchaserName'],
                'é¡¹ç›®åç§°': self.field_variants['projectName'],
                'é¡¹ç›®ç¼–å·': self.field_variants['projectNumber']
            }
            field_variants = field_mapping.get(field_name, [])

            if not field_variants:
                continue

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœ¨æ­¤æ®µè½ä¸­å°è¯•è¯¥å­—æ®µ
            if not SmartFieldDetector.should_try_field_in_paragraph(text, field_variants):
                self.logger.info(f"ğŸ” [è°ƒè¯•] è·³è¿‡å­—æ®µ {field_name} åœ¨æ®µè½: {text[:50]}...")
                continue

            # å°è¯•å„ç§å¡«ç©ºç­–ç•¥
            field_processed = False
            for variant in field_variants:
                if field_processed:
                    break  # è¯¥å­—æ®µå·²å¤„ç†æˆåŠŸï¼Œå°è¯•ä¸‹ä¸€ä¸ªå­—æ®µ

                self.logger.info(f"ğŸ” [è°ƒè¯•] å°è¯•å­—æ®µå˜ä½“: {variant} åœ¨æ®µè½: {paragraph.text[:50]}...")

                # ç­–ç•¥1ï¼šæ’å…¥å¼æ›¿æ¢ï¼ˆæŒ‰å¤‡ä»½æ–‡ä»¶é¡ºåºï¼‰
                if self._try_insert_strategy(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ æ’å…¥å¼æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

                # ç­–ç•¥2ï¼šå…¬ç« æ ¼å¼æ›¿æ¢
                if self._try_stamp_strategy(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ å…¬ç« æ ¼å¼æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

                # ç­–ç•¥3ï¼šçº¯ç©ºæ ¼æ›¿æ¢
                if self._try_space_only_strategy(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ çº¯ç©ºæ ¼æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

                # ç­–ç•¥4ï¼šæ‹¬å·æ ¼å¼æ›¿æ¢
                if self._try_bracket_strategy(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ æ‹¬å·æ ¼å¼æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

                # ç­–ç•¥5ï¼šç²¾ç¡®æ¨¡å¼æ›¿æ¢ï¼ˆæ–°å¢ï¼‰
                if self._try_precise_strategies(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ ç²¾ç¡®æ¨¡å¼æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

                # ç­–ç•¥6ï¼šä¼ ç»Ÿå¡«ç©ºæ¨¡å¼ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
                if self._try_fill_patterns(paragraph, variant, value):
                    self.logger.info(f"ğŸ”„ å¡«ç©ºè§„åˆ™æˆåŠŸ: {field_name} -> {value}")
                    fill_count += 1
                    field_processed = True
                    continue

        return fill_count > 0
    
    def _try_fill_patterns(self, paragraph: Paragraph, field_variant: str, value: str) -> bool:
        """å°è¯•å„ç§å¡«ç©ºæ¨¡å¼"""
        patterns = [
            # æ¨¡å¼1: å­—æ®µåï¼š___
            f'{re.escape(field_variant)}\\s*[ï¼š:]\\s*_+',
            # æ¨¡å¼2: å­—æ®µåï¼š
            f'{re.escape(field_variant)}\\s*[ï¼š:]\\s*$',
            # æ¨¡å¼3: å­—æ®µåï¼š___ (æ··åˆ)
            f'{re.escape(field_variant)}\\s*[ï¼š:]\\s*[_\\s]*$',
            # æ¨¡å¼4: å­—æ®µå (æ’å…¥å¼)
            f'{re.escape(field_variant)}(?=\\s+)(?![ï¼š:])',
            # æ¨¡å¼5: è‡´ï¼šå­—æ®µå æ ¼å¼
            f'è‡´\\s*[ï¼š:]\\s*{re.escape(field_variant)}\\s*$'
        ]
        
        for pattern in patterns:
            if re.search(pattern, paragraph.text):
                # æ„å»ºæ›¿æ¢æ–‡æœ¬
                if 'è‡´' in pattern:
                    # ç‰¹æ®Šå¤„ç†"è‡´ï¼š"æ ¼å¼
                    replacement = f'è‡´ï¼š{value}'
                elif 'ï¼š' in paragraph.text or ':' in paragraph.text:
                    replacement = f'{field_variant}ï¼š{value}'
                else:
                    replacement = f'{field_variant} {value}'

                success = WordDocumentUtils.precise_replace(paragraph, pattern, replacement, self.logger)
                if success:
                    return True
        
        return False

    def _try_bracket_strategy(self, paragraph: Paragraph, variant: str, value: str) -> bool:
        """ç­–ç•¥1ï¼šæ‹¬å·æ ¼å¼æ›¿æ¢ - å¤„ç†ï¼ˆå­—æ®µåï¼‰â†’ï¼ˆæ›¿æ¢å€¼ï¼‰æ ¼å¼"""
        # å¿«é€Ÿæ£€æŸ¥ï¼šå¦‚æœæ®µè½ä¸­æ ¹æœ¬æ²¡æœ‰æ‹¬å·ï¼Œç›´æ¥è¿”å›
        if 'ï¼ˆ' not in paragraph.text and '(' not in paragraph.text:
            return False

        bracket_pattern = rf'[ï¼ˆ(]\s*{re.escape(variant)}\s*[ï¼‰)]'
        match = re.search(bracket_pattern, paragraph.text)
        if not match:
            return False

        self.logger.info(f"ğŸ¯ ç­–ç•¥1(æ‹¬å·æ ¼å¼)åŒ¹é…æˆåŠŸ - å­—æ®µ: {variant}")
        self.logger.info(f"ğŸ“ åŒ¹é…æ¨¡å¼: {bracket_pattern}")
        self.logger.info(f"âœ… åŒ¹é…å†…å®¹: '{match.group()}'")

        replacement = f"ï¼ˆ{value}ï¼‰"
        return WordDocumentUtils.precise_replace(paragraph, bracket_pattern, replacement, self.logger)

    def _try_insert_strategy(self, paragraph: Paragraph, variant: str, value: str) -> bool:
        """ç­–ç•¥2ï¼šæ’å…¥å¼æ›¿æ¢ - ç›´æ¥åœ¨å­—æ®µååæ’å…¥å†…å®¹"""
        # å¿«é€Ÿæ£€æŸ¥ï¼šåªæœ‰å­—æ®µååç›´æ¥è·Ÿå†’å·æ‰æ‹’ç»
        if re.search(rf'{re.escape(variant)}\s*[:ï¼š]', paragraph.text):
            # å¦‚æœå­—æ®µååç›´æ¥è·Ÿå†’å·ï¼Œä¸æ˜¯æ’å…¥å¼æ ¼å¼
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æ’å…¥å¼æ¨¡å¼ï¼šå­—æ®µååé¢è·Ÿç©ºæ ¼ä½†ä¸è·Ÿå†’å·
        # æ”¹è¿›ï¼šåŒ¹é…å­—æ®µååŠå…¶åé¢çš„æ‰€æœ‰ç©ºæ ¼ï¼Œç¡®ä¿å®Œå…¨æ›¿æ¢
        insert_pattern = rf'{re.escape(variant)}\s+'

        # å…ˆæ£€æŸ¥åŸºæœ¬åŒ¹é…æ¡ä»¶
        if not re.search(rf'{re.escape(variant)}(?=\s+)(?![:ï¼š])', paragraph.text):
            return False

        self.logger.info(f"ğŸ¯ ç­–ç•¥2(æ’å…¥å¼)åŒ¹é…æˆåŠŸ - å­—æ®µ: {variant}")
        self.logger.info(f"ğŸ“ åŒ¹é…æ¨¡å¼(æ”¹è¿›ç‰ˆ): {insert_pattern}")

        replacement = f'{variant} {value}'
        success = WordDocumentUtils.precise_replace(paragraph, insert_pattern, replacement, self.logger)

        if success:
            # æ ‡è®°æ­¤æ®µè½éœ€è¦åç»­æ ¼å¼æ¸…ç†
            self._mark_paragraph_for_format_cleanup(paragraph, variant, value)
            self.logger.info(f"ğŸ·ï¸ æ ‡è®°æ®µè½éœ€è¦æ ¼å¼æ¸…ç†: {variant}")

        return success

    def _try_space_only_strategy(self, paragraph: Paragraph, variant: str, value: str) -> bool:
        """ç­–ç•¥3ï¼šçº¯ç©ºæ ¼æ›¿æ¢ - å¤„ç†åªæœ‰ç©ºæ ¼æ— ä¸‹åˆ’çº¿çš„æƒ…å†µ"""
        # å¿«é€Ÿæ£€æŸ¥ï¼šå¿…é¡»åŒ…å«å†’å·å¹¶ä¸”ä»¥ç©ºæ ¼ç»“å°¾
        if not re.search(r'[:ï¼š]\s+$', paragraph.text):
            return False

        space_pattern = rf'({re.escape(variant)}\s*[:ï¼š])\s+$'
        match = re.search(space_pattern, paragraph.text)
        if not match:
            return False

        self.logger.info(f"ğŸ¯ ç­–ç•¥3(çº¯ç©ºæ ¼)åŒ¹é…æˆåŠŸ - å­—æ®µ: {variant}")
        replacement = rf'\1{value}'
        return WordDocumentUtils.precise_replace(paragraph, space_pattern, replacement, self.logger)

    def _try_stamp_strategy(self, paragraph: Paragraph, variant: str, value: str) -> bool:
        """ç­–ç•¥4ï¼šå…¬ç« æ ¼å¼æ›¿æ¢ - ä¿ç•™å…¬ç« æ‹¬å·"""
        # å¿«é€Ÿæ£€æŸ¥ï¼šå¦‚æœæ®µè½ä¸­æ²¡æœ‰"ç« "å­—ï¼Œä¸å¯èƒ½æ˜¯å…¬ç« æ ¼å¼
        if 'ç« ' not in paragraph.text:
            return False

        stamp_pattern = rf'(?P<prefix>{re.escape(variant)}\s*[:ï¼š]\s*)(?P<spaces>[_\s]+)(?P<stamp>[ï¼ˆ(][^ï¼‰)]*ç« [^ï¼‰)]*[ï¼‰)])'
        match = re.search(stamp_pattern, paragraph.text)
        if not match:
            return False

        self.logger.info(f"ğŸ¯ ç­–ç•¥4(å…¬ç« æ ¼å¼)åŒ¹é…æˆåŠŸ - å­—æ®µ: {variant}")
        replacement = rf'\g<prefix>{value}\g<stamp>'
        return WordDocumentUtils.precise_replace(paragraph, stamp_pattern, replacement, self.logger)

    def _try_precise_strategies(self, paragraph: Paragraph, variant: str, replacement_text: str) -> bool:
        """ç­–ç•¥5ï¼šç²¾ç¡®æ¨¡å¼æ›¿æ¢ - 4ä¸ªå­ç­–ç•¥"""
        self.logger.debug(f"ğŸ”„ ä½¿ç”¨ç²¾ç¡®æ¨¡å¼æ›¿æ¢ç­–ç•¥")

        # ç²¾ç¡®æ¨¡å¼å­ç­–ç•¥åˆ—è¡¨
        precise_patterns = [
            # å­ç­–ç•¥1ï¼šå¤šå­—æ®µæ ¼å¼å¤„ç† - åœ°å€ï¼š___ é‚®ç¼–ï¼š___ï¼ˆä¿ç•™åç»­å­—æ®µï¼‰
            (rf'(?P<prefix>{re.escape(variant)}\s*[:ï¼š]\s*)(?P<underscores>_+)(?P<suffix>\s+[^\s_]+[:ï¼š])',
             rf'\g<prefix>{replacement_text}\g<suffix>'),

            # å­ç­–ç•¥2ï¼šå•å­—æ®µæœ«å°¾æ ¼å¼ - ç”µè¯ï¼š___________ï¼ˆæ¸…ç†æ‰€æœ‰ä¸‹åˆ’çº¿ï¼‰
            (rf'({re.escape(variant)}\s*[:ï¼š]\s*)_+\s*$',
             rf'\g<1>{replacement_text}'),

            # å­ç­–ç•¥3ï¼šæ— ä¸‹åˆ’çº¿æ ¼å¼ - ç”µå­é‚®ç®±ï¼šï¼ˆç›´æ¥æ·»åŠ å†…å®¹ï¼‰
            (rf'({re.escape(variant)}\s*[:ï¼š])\s*$',
             rf'\g<1>{replacement_text}'),

            # å­ç­–ç•¥4ï¼šé€šç”¨ä¸‹åˆ’çº¿æ ¼å¼ - ä¾›åº”å•†åç§°ï¼š___ï¼ˆæ¸…ç†ä¸‹åˆ’çº¿å’Œç©ºæ ¼ï¼‰
            (rf'({re.escape(variant)}\s*[:ï¼š]\s*)[_\s]+',
             rf'\g<1>{replacement_text}')
        ]

        # ä¾æ¬¡å°è¯•æ¯ä¸ªç²¾ç¡®å­ç­–ç•¥
        for i, (pattern, replacement) in enumerate(precise_patterns, 1):
            if re.search(pattern, paragraph.text):
                # æå‡åˆ°INFOçº§åˆ«ï¼Œå¹¶å¢åŠ è¯¦ç»†ä¿¡æ¯
                self.logger.info(f"ğŸ¯ ç²¾ç¡®å­ç­–ç•¥{i}åŒ¹é…æˆåŠŸ - æ¨¡å¼: {pattern}")
                self.logger.info(f"ğŸ“ æ›¿æ¢æ¨¡å¼: {replacement}")
                match_obj = re.search(pattern, paragraph.text)
                if match_obj:
                    self.logger.info(f"âœ… åŒ¹é…å†…å®¹: '{match_obj.group()}'")
                if WordDocumentUtils.precise_replace(paragraph, pattern, replacement, self.logger):
                    return True

        return False

    def _process_table(self, table: Table, info: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¡¨æ ¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        stats = {'total_replacements': 0}
        
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    if paragraph.text.strip():
                        cell_stats = self._process_paragraph(paragraph, info)
                        for key, value in cell_stats.items():
                            stats[key] = stats.get(key, 0) + value
        
        return stats
    
    def _post_process(self, doc: Document):
        """
        åå¤„ç†ï¼šæ¸…ç†å¤šä½™çš„å ä½ç¬¦å’Œè£…é¥°æ€§æ ¼å¼ï¼ˆä¿æŠ¤å·²å¡«å……å†…å®¹ï¼‰
        æ–°å¢ï¼šä¸“é—¨å¤„ç†æ’å…¥å¼ç­–ç•¥çš„æ ¼å¼æ¸…ç†éœ€æ±‚
        """
        # ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ ‡è®°çš„æ ¼å¼æ¸…ç†
        self.logger.info("ğŸ§¹ å¼€å§‹åå¤„ç†ï¼šæ ¼å¼æ¸…ç†å’Œç¾åŒ–")

        for paragraph in doc.paragraphs:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼æ¸…ç†æ ‡è®°
            if hasattr(paragraph, '_format_cleanup_needed'):
                self.logger.info(f"ğŸ·ï¸ å‘ç°éœ€è¦æ ¼å¼æ¸…ç†çš„æ®µè½: '{paragraph.text[:30]}...'")
                self._clean_decorative_formats_only(paragraph)

        # ç¬¬äºŒæ­¥ï¼šå¤„ç†å¹´æœˆæ—¥æ ¼å¼å¡«å……
        self._process_date_format_filling(doc)

        # ç¬¬ä¸‰æ­¥ï¼šåŸæœ‰çš„æ–‡æœ¬æ¸…ç†é€»è¾‘
        for paragraph in doc.paragraphs:
            text = paragraph.text
            original_text = text

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å·²å¡«å……çš„å†…å®¹ï¼ˆåŒ…å«ä¸­æ–‡å…¬å¸åç§°ç­‰ï¼‰
            contains_filled_content = False
            for company_pattern in self.company_name_extended_patterns:
                base_pattern = company_pattern.split('(?:')[0]  # è·å–åŸºç¡€æ¨¡å¼ï¼ˆå»æ‰å…¬ç« éƒ¨åˆ†ï¼‰
                if base_pattern in text and len(text) > len(base_pattern) + 5:
                    # å¦‚æœæ–‡æœ¬æ¯”åŸºç¡€å­—æ®µåé•¿å¾ˆå¤šï¼Œå¯èƒ½åŒ…å«å¡«å……å†…å®¹
                    contains_filled_content = True
                    break

            # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡‡è´­äººåç§°ç­‰å¡«å……å†…å®¹
            if 'åŒ—äº¬å¸‚' in text or 'æœ‰é™å…¬å¸' in text or 'é›†å›¢' in text:
                contains_filled_content = True

            # æ£€æŸ¥æ˜¯å¦åŒ…å«è”ç³»ä¿¡æ¯ç­‰å¡«å……å†…å®¹
            if (re.search(r'\d{3,4}-\d{7,8}', text) or  # ç”µè¯å·ç æ ¼å¼
                re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text) or  # é‚®ç®±æ ¼å¼
                re.search(r'\d{6}', text) or  # é‚®ç¼–æ ¼å¼
                'å¹´' in text and 'æœˆ' in text and 'æ—¥' in text):  # æ—¥æœŸæ ¼å¼
                contains_filled_content = True

            # å¦‚æœåŒ…å«å¡«å……å†…å®¹ï¼Œè·³è¿‡ç©ºæ ¼æ¸…ç†ä»¥ä¿æŠ¤å†…å®¹
            if not contains_filled_content:
                # æ¸…ç†å¤šä½™çš„ä¸‹åˆ’çº¿
                text = re.sub(r'_{3,}', '', text)

                # æ¸…ç†å¤šä½™çš„ç©ºæ ¼ï¼ˆä¿ç•™è¡¨æ ¼å¯¹é½æ‰€éœ€çš„ç©ºæ ¼ï¼‰
                if not re.search(r'\s{8,}', text):  # ä¸æ˜¯è¡¨æ ¼å¼å¸ƒå±€
                    text = re.sub(r'\s{3,}', '  ', text)

            # æ¸…ç†å¤šä½™çš„å†’å·
            text = re.sub(r'[:ï¼š]{2,}', 'ï¼š', text)

            # æ ‡å‡†åŒ–å†’å·
            text = re.sub(r':', 'ï¼š', text)

            # å»é™¤å¤šä½™çš„å¹´æœˆæ—¥æ ‡è¯†å’Œé‡å¤å†…å®¹
            text = self._clean_date_redundancy_and_placeholders(text)

            if text != original_text:
                # ä½¿ç”¨ç²¾ç¡®æ ¼å¼å¤„ç†è¿›è¡Œåå¤„ç†æ¸…ç†
                escaped_original = re.escape(original_text.strip())
                if not WordDocumentUtils.precise_replace(paragraph, escaped_original, text.strip(), self.logger):
                    # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨æ ¼å¼ä¿æŠ¤æ–¹æ³•
                    self._update_paragraph_text_preserving_format(paragraph, text.strip())
    
    def _mark_paragraph_for_format_cleanup(self, paragraph, field_name: str, content: str):
        """æ ‡è®°æ®µè½éœ€è¦åç»­æ ¼å¼æ¸…ç†"""
        try:
            # åœ¨æ®µè½å¯¹è±¡ä¸Šæ·»åŠ æ¸…ç†æ ‡è®°ï¼ˆä¸´æ—¶å±æ€§ï¼‰
            if not hasattr(paragraph, '_format_cleanup_needed'):
                paragraph._format_cleanup_needed = []

            paragraph._format_cleanup_needed.append({
                'field_name': field_name,
                'content': content
            })

            self.logger.info(f"ğŸ·ï¸ æ®µè½æ ¼å¼æ¸…ç†æ ‡è®°å·²æ·»åŠ : {field_name} -> {content[:20]}...")

        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ æ ¼å¼æ¸…ç†æ ‡è®°å¤±è´¥: {e}")

    def _is_filled_content_run(self, run) -> bool:
        """åˆ¤æ–­runæ˜¯å¦åŒ…å«å·²å¡«å……çš„å†…å®¹"""
        try:
            run_text = run.text
            if not run_text:
                return False

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¸å‹çš„å¡«å……å†…å®¹æ¨¡å¼
            filled_patterns = [
                r'\d{3,4}-\d{7,8}',  # ç”µè¯å·ç 
                r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',  # é‚®ç®±
                r'\d{6}',  # é‚®ç¼–
                r'www\.',  # ç½‘ç«™
                r'æœ‰é™å…¬å¸|è‚¡ä»½|é›†å›¢|ç§‘æŠ€',  # å…¬å¸åç§°ç‰¹å¾
            ]

            for pattern in filled_patterns:
                if re.search(pattern, run_text):
                    return True

            return False

        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥å¡«å……å†…å®¹å¤±è´¥: {e}")
            return False

    def _clean_decorative_formats_only(self, paragraph):
        """åªæ¸…ç†è£…é¥°æ€§æ ¼å¼ï¼Œå®Œå…¨ä¿ç•™æ–‡æœ¬ç»“æ„"""
        try:
            cleanup_info = getattr(paragraph, '_format_cleanup_needed', [])

            for run in paragraph.runs:
                should_clean = False

                # æ–¹æ³•1ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æˆ‘ä»¬æ ‡è®°çš„å¡«å……å†…å®¹
                for info in cleanup_info:
                    if info['content'] in run.text:
                        should_clean = True
                        self.logger.info(f"ğŸ·ï¸ å‘ç°æ ‡è®°çš„å¡«å……å†…å®¹: '{info['content']}'")
                        break

                # æ–¹æ³•2ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«å…¸å‹å¡«å……å†…å®¹æ¨¡å¼
                if not should_clean:
                    should_clean = self._is_filled_content_run(run)

                # æ–¹æ³•3ï¼šå¯¹äºæ’å…¥å¼ç­–ç•¥ï¼Œæ¸…ç†æ‰€æœ‰åç»­ç©ºæ ¼çš„è£…é¥°æ ¼å¼
                if not should_clean and len(run.text.strip()) == 0:
                    # å¦‚æœæ˜¯çº¯ç©ºæ ¼runï¼Œä¸”æ®µè½åŒ…å«å¡«å……å†…å®¹ï¼Œåˆ™æ¸…ç†è£…é¥°æ ¼å¼
                    paragraph_text = paragraph.text
                    if any(pattern in paragraph_text for pattern in ['010-', '@', 'www.', 'æœ‰é™å…¬å¸']):
                        should_clean = True
                        self.logger.info(f"ğŸ§¹ æ¸…ç†å¡«å……å†…å®¹åçš„ç©ºæ ¼è£…é¥°æ ¼å¼")

                if should_clean:
                    # æ¸…ç†è£…é¥°æ ¼å¼
                    if hasattr(run.font, 'underline') and run.font.underline:
                        run.font.underline = False
                        self.logger.info(f"ğŸ”§ æ¸…é™¤ä¸‹åˆ’çº¿æ ¼å¼: '{run.text[:15]}...'")

                    if hasattr(run.font, 'strike') and run.font.strike:
                        run.font.strike = False
                        self.logger.info(f"ğŸ”§ æ¸…é™¤åˆ é™¤çº¿æ ¼å¼: '{run.text[:15]}...'")

            # æ¸…ç†ä¸´æ—¶æ ‡è®°
            if hasattr(paragraph, '_format_cleanup_needed'):
                delattr(paragraph, '_format_cleanup_needed')

        except Exception as e:
            self.logger.error(f"âŒ è£…é¥°æ€§æ ¼å¼æ¸…ç†å¤±è´¥: {e}")

    def _process_date_format_filling(self, doc: Document):
        """
        å¤„ç†å¹´æœˆæ—¥æ ¼å¼å¡«å……
        è¯†åˆ«å’Œå¡«å……"    å¹´    æœˆ    æ—¥"ç­‰å„ç§ç©ºæ ¼åˆ†éš”çš„å¹´æœˆæ—¥æ ¼å¼
        """
        self.logger.info("ğŸ“… å¼€å§‹å¤„ç†å¹´æœˆæ—¥æ ¼å¼å¡«å……")

        # è·å–æ—¥æœŸå€¼
        date_value = self.info.get('date', '')
        if not date_value:
            self.logger.info("âš ï¸ æ—¥æœŸå€¼ä¸ºç©ºï¼Œè·³è¿‡å¹´æœˆæ—¥æ ¼å¼å¡«å……")
            return

        # æ ¼å¼åŒ–æ—¥æœŸ
        formatted_date = self._format_date(date_value)
        if not formatted_date:
            self.logger.warning("âš ï¸ æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥ï¼Œè·³è¿‡å¹´æœˆæ—¥æ ¼å¼å¡«å……")
            return

        self.logger.info(f"ğŸ“… å‡†å¤‡å¡«å……çš„æ—¥æœŸå€¼: '{formatted_date}'")

        # å®šä¹‰å¹´æœˆæ—¥æ ¼å¼åŒ¹é…æ¨¡å¼
        date_end_patterns = [
            r'^\s{2,}å¹´\s{2,}æœˆ\s{2,}æ—¥$',      # ç©ºæ ¼åˆ†éš”çš„å¹´æœˆæ—¥æ ¼å¼ï¼ˆç‹¬ç«‹è¡Œï¼‰
            r'(\s+)å¹´(\s+)æœˆ(\s+)æ—¥(\s*)$',      # æœ«å°¾æ ¼å¼ï¼šç©ºæ ¼+å¹´+ç©ºæ ¼+æœˆ+ç©ºæ ¼+æ—¥
            r'(\n\s*)å¹´(\s+)æœˆ(\s+)æ—¥(\s*)$',    # æ¢è¡Œ+ç©ºæ ¼+å¹´æœˆæ—¥æ ¼å¼
            r'(\s+)å¹´(\s+)æœˆ(\s+)æ—¥',           # é€šç”¨æ ¼å¼ï¼šç©ºæ ¼+å¹´+ç©ºæ ¼+æœˆ+ç©ºæ ¼+æ—¥
        ]

        processed_count = 0

        for paragraph in doc.paragraphs:
            text = paragraph.text
            if not text or not text.strip():
                continue

            # æ£€æŸ¥æ˜¯å¦åŒ¹é…å¹´æœˆæ—¥æ ¼å¼
            for i, pattern in enumerate(date_end_patterns, 1):
                match = re.search(pattern, text)
                if match:
                    self.logger.info(f"âœ… å¹´æœˆæ—¥æ¨¡å¼{i}åŒ¹é…æˆåŠŸ: '{match.group()}' åœ¨æ®µè½: '{text[:50]}...'")

                    # æ„å»ºæ–°æ–‡æœ¬
                    if i == 1:  # ç‹¬ç«‹çš„ç©ºæ ¼å¹´æœˆæ—¥æ ¼å¼
                        # ç›´æ¥æ›¿æ¢æ•´ä¸ªåŒ¹é…å†…å®¹
                        new_text = re.sub(pattern, formatted_date, text)
                    elif i == 3:  # æ¢è¡Œ+ç©ºæ ¼+å¹´æœˆæ—¥æ ¼å¼
                        # ä¿ç•™æ¢è¡Œç¬¦ï¼Œåªæ›¿æ¢å¹´æœˆæ—¥éƒ¨åˆ†
                        new_text = re.sub(pattern, rf'\1{formatted_date}', text)
                    else:
                        # æ ‡å‡†æ›¿æ¢ï¼šæ•´ä¸ªåŒ¹é…çš„å¹´æœˆæ—¥æ¨¡å¼ä¸ºå®Œæ•´æ—¥æœŸ
                        new_text = re.sub(pattern, formatted_date, text)

                    if new_text != text:
                        # ä½¿ç”¨ç²¾ç¡®æ ¼å¼å¤„ç†è¿›è¡Œæ›¿æ¢
                        escaped_original = re.escape(text.strip())
                        if WordDocumentUtils.precise_replace(paragraph, escaped_original, new_text.strip(), self.logger):
                            self.logger.info(f"ğŸ”„ å¹´æœˆæ—¥æ ¼å¼å¡«å……æˆåŠŸ: '{text}' -> '{new_text}'")
                            processed_count += 1
                        else:
                            # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨æ ¼å¼ä¿æŠ¤æ–¹æ³•
                            self._update_paragraph_text_preserving_format(paragraph, new_text.strip())
                            self.logger.info(f"ğŸ”„ å¹´æœˆæ—¥æ ¼å¼å¡«å……æˆåŠŸ(åå¤‡): '{text}' -> '{new_text}'")
                            processed_count += 1

                        # æ‰¾åˆ°ä¸€ä¸ªåŒ¹é…åï¼Œè·³å‡ºæ¨¡å¼å¾ªç¯
                        break

        if processed_count > 0:
            self.logger.info(f"ğŸ“Š å¹´æœˆæ—¥æ ¼å¼å¡«å……å®Œæˆï¼Œå…±å¤„ç† {processed_count} ä¸ªæ®µè½")
        else:
            self.logger.info("ğŸ“Š æœªå‘ç°éœ€è¦å¡«å……çš„å¹´æœˆæ—¥æ ¼å¼")

    def _clean_date_redundancy_and_placeholders(self, text: str) -> str:
        """
        æ¸…ç†æ—¥æœŸç›¸å…³çš„é‡å¤å†…å®¹å’Œå ä½ç¬¦æ®‹ç•™
        å¤„ç†å„ç§"å¹´æœˆæ—¥"é‡å¤æ¨¡å¼å’Œå ä½ç¬¦
        """
        original_text = text

        # ç¬¬ä¸€ç»„ï¼šå¤„ç†ç›´æ¥é‡å¤çš„å¹´æœˆæ—¥å­—ç¬¦
        redundant_patterns = [
            r'(\d+å¹´\d+æœˆ\d+æ—¥)å¹´',              # 2015å¹´12æœˆ18æ—¥å¹´
            r'(\d+å¹´\d+æœˆ\d+æ—¥)æœˆ',              # 2015å¹´12æœˆ18æ—¥æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)æ—¥',              # 2015å¹´12æœˆ18æ—¥æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)å¹´\s*æœˆ',         # 2015å¹´12æœˆ18æ—¥å¹´æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)å¹´\s*æœˆ\s*æ—¥',    # 2015å¹´12æœˆ18æ—¥å¹´æœˆæ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)æœˆ\s*æ—¥',         # 2015å¹´12æœˆ18æ—¥æœˆæ—¥
        ]

        for pattern in redundant_patterns:
            if re.search(pattern, text):
                old_text = text
                text = re.sub(pattern, r'\1', text)
                self.logger.debug(f"æ¸…ç†é‡å¤å­—ç¬¦: '{old_text}' -> '{text}'")

        # ç¬¬äºŒç»„ï¼šå¤„ç†å¸¦ç©ºæ ¼çš„é‡å¤æ¨¡å¼
        spaced_redundant_patterns = [
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+å¹´',           # 2015å¹´12æœˆ18æ—¥ å¹´
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+æœˆ',           # 2015å¹´12æœˆ18æ—¥ æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+æ—¥',           # 2015å¹´12æœˆ18æ—¥ æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+å¹´\s*æœˆ',      # 2015å¹´12æœˆ18æ—¥ å¹´æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+å¹´\s*æœˆ\s*æ—¥', # 2015å¹´12æœˆ18æ—¥ å¹´æœˆæ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+æœˆ\s*æ—¥',      # 2015å¹´12æœˆ18æ—¥ æœˆæ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s*å¹´\s*æœˆ\s*æ—¥', # 2015å¹´12æœˆ18æ—¥å¹´æœˆæ—¥ï¼ˆä»»æ„ç©ºæ ¼ï¼‰
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+æœˆ\s+æ—¥',      # 2015å¹´12æœˆ18æ—¥  æœˆ  æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)\s+å¹´\s+æœˆ',      # 2015å¹´12æœˆ18æ—¥  å¹´  æœˆ
        ]

        for pattern in spaced_redundant_patterns:
            if re.search(pattern, text):
                old_text = text
                text = re.sub(pattern, r'\1', text)
                self.logger.debug(f"æ¸…ç†ç©ºæ ¼é‡å¤: '{old_text}' -> '{text}'")

        # ç¬¬ä¸‰ç»„ï¼šå¤„ç†å ä½ç¬¦æ®‹ç•™
        placeholder_cleanup_patterns = [
            # æ¸…ç†æ—¥æœŸåçš„ä¸‹åˆ’çº¿å ä½ç¬¦
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+æœˆ_+æ—¥',        # 2025å¹´09æœˆ07æ—¥_____æœˆ_____æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+æœˆ',            # 2025å¹´09æœˆ07æ—¥_____æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+æ—¥',            # 2025å¹´09æœˆ07æ—¥_____æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+å¹´_+æœˆ_+æ—¥',    # 2025å¹´09æœˆ07æ—¥_____å¹´_____æœˆ_____æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+å¹´_+æœˆ',        # 2025å¹´09æœˆ07æ—¥_____å¹´_____æœˆ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+å¹´',            # 2025å¹´09æœˆ07æ—¥_____å¹´

            # æ¸…ç†ç©ºæ ¼å’Œä¸‹åˆ’çº¿æ··åˆçš„æƒ…å†µ
            r'(\d+å¹´\d+æœˆ\d+æ—¥)[\s_]+æœˆ[\s_]*æ—¥', # 2025å¹´09æœˆ07æ—¥ ___æœˆ___æ—¥
            r'(\d+å¹´\d+æœˆ\d+æ—¥)[\s_]+å¹´[\s_]*æœˆ[\s_]*æ—¥', # å¸¦ç©ºæ ¼çš„æ··åˆæƒ…å†µ

            # æ¸…ç†æ¨ªçº¿å½¢å¼çš„å ä½ç¬¦
            r'(\d+å¹´\d+æœˆ\d+æ—¥)-+',              # 2025å¹´09æœˆ07æ—¥--------
            r'(\d+å¹´\d+æœˆ\d+æ—¥)[\s-]+$',         # 2025å¹´09æœˆ07æ—¥ ---- (è¡Œæœ«)
            r'(\d+å¹´\d+æœˆ\d+æ—¥)_+$',             # 2025å¹´09æœˆ07æ—¥_____ (è¡Œæœ«)

            # æ¸…ç†æ—¥æœŸåçš„ä»»æ„ç»„åˆå ä½ç¬¦ï¼ˆæ›´é€šç”¨çš„æ¨¡å¼ï¼‰
            r'(\d+å¹´\d+æœˆ\d+æ—¥)[\s_-]+.*?$',     # æ—¥æœŸåä»»æ„å ä½ç¬¦åˆ°è¡Œæœ«
        ]

        for pattern in placeholder_cleanup_patterns:
            if re.search(pattern, text):
                old_text = text
                text = re.sub(pattern, r'\1', text)
                self.logger.debug(f"æ¸…ç†å ä½ç¬¦æ®‹ç•™: '{old_text}' -> '{text}'")

        # ç¬¬å››ç»„ï¼šå¤„ç†é‡å¤æ—¥æœŸ
        duplicate_date_patterns = [
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)\s+(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',  # 2025å¹´9æœˆ12æ—¥ 2025å¹´9æœˆ12æ—¥
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)å¹´[_\s]*æœˆ[_\s]*æ—¥',              # 2025å¹´9æœˆ12æ—¥å¹´_____æœˆ_____æ—¥
        ]

        for pattern in duplicate_date_patterns:
            if re.search(pattern, text):
                old_text = text
                text = re.sub(pattern, r'\1', text)
                self.logger.debug(f"æ¸…ç†é‡å¤æ—¥æœŸ: '{old_text}' -> '{text}'")

        # å¦‚æœæœ‰æ¸…ç†æ“ä½œï¼Œè®°å½•æ—¥å¿—
        if text != original_text:
            self.logger.info(f"ğŸ“… æ—¥æœŸæ¸…ç†å®Œæˆ: '{original_text}' -> '{text}'")

        return text

    def _format_date(self, date_str: str) -> str:
        """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²"""
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        date_str = re.sub(r'\s+', '', date_str)

        # å°è¯•åŒ¹é…å¸¸è§æ—¥æœŸæ ¼å¼
        patterns = [
            (r'(\d{4})-(\d{1,2})-(\d{1,2})', r'\1å¹´\2æœˆ\3æ—¥'),
            (r'(\d{4})/(\d{1,2})/(\d{1,2})', r'\1å¹´\2æœˆ\3æ—¥'),
            (r'(\d{4})\.(\d{1,2})\.(\d{1,2})', r'\1å¹´\2æœˆ\3æ—¥'),
        ]

        for pattern, replacement in patterns:
            if re.match(pattern, date_str):
                return re.sub(pattern, replacement, date_str)

        # å¦‚æœå·²ç»æ˜¯å¹´æœˆæ—¥æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if re.match(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', date_str):
            return date_str

        return None

    def _update_paragraph_text_preserving_format(self, paragraph: Paragraph, new_text: str):
        """
        æ ¼å¼ä¿æŠ¤çš„æ®µè½æ–‡æœ¬æ›´æ–°æ–¹æ³• - åå¤‡æ–¹æ¡ˆ

        æ³¨æ„ï¼šä¼˜å…ˆä½¿ç”¨ precise_replace() ç²¾ç¡®æ ¼å¼å¤„ç†å¼•æ“
        æ­¤æ–¹æ³•ä¸»è¦ä½œä¸ºå¤æ‚æƒ…å†µä¸‹çš„åå¤‡æ–¹æ¡ˆ
        """
        if not paragraph.runs:
            return

        # å°†æ–°æ–‡æœ¬åˆ†é…ç»™ç¬¬ä¸€ä¸ªrunï¼Œæ¸…ç©ºå…¶ä»–runs
        first_run = paragraph.runs[0]
        first_run.text = new_text

        # æ¸…ç©ºå…¶ä»–runsçš„æ–‡æœ¬ä½†ä¿æŒå®ƒä»¬çš„å­˜åœ¨ï¼ˆä¿æŒæ ¼å¼ç»“æ„ï¼‰
        for run in paragraph.runs[1:]:
            run.text = ''

        self.logger.info(f"âœ… æ ¼å¼ä¿æŠ¤æ›´æ–°å®Œæˆ: '{new_text}'")

# å‘åå…¼å®¹
class BusinessInfoFiller(InfoFiller):
    """å‘åå…¼å®¹çš„ç±»ååˆ«å"""
    pass