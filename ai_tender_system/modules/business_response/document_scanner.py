#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£æ‰«æå™¨ - æ‰«æWordæ–‡æ¡£æŸ¥æ‰¾å›¾ç‰‡æ’å…¥ä½ç½®
"""

import sys
from pathlib import Path
from typing import Dict, Any
from docx import Document

sys.path.append(str(Path(__file__).parent.parent.parent))
from common import get_module_logger


class DocumentScanner:
    """æ–‡æ¡£æ‰«æå™¨ - è´Ÿè´£æ‰«æWordæ–‡æ¡£æŸ¥æ‰¾å›¾ç‰‡æ’å…¥ä½ç½®"""

    def __init__(self):
        self.logger = get_module_logger("document_scanner")

        # å›¾ç‰‡ç±»å‹å…³é”®è¯æ˜ å°„
        self.image_keywords = {
            'license': ['è¥ä¸šæ‰§ç…§', 'è¥ä¸šæ‰§ç…§å‰¯æœ¬', 'æ‰§ç…§'],
            'qualification': [],  # æ¸…ç©ºé€šç”¨å…³é”®è¯ï¼Œåªä½¿ç”¨å…·ä½“èµ„è´¨ç±»å‹åŒ¹é…ï¼ˆé¿å…è¯¯åŒ¹é…"ç›¸å…³èµ„è´¨è¯ä¹¦"ç­‰æ³›æŒ‡æ–‡å­—ï¼‰
            'authorization': ['æˆæƒä¹¦', 'æˆæƒå§”æ‰˜ä¹¦', 'æ³•äººæˆæƒ'],
            'certificate': ['è¯ä¹¦', 'è®¤è¯', 'èµ„æ ¼è¯'],
            'legal_id': [
                'æ³•å®šä»£è¡¨äººèº«ä»½è¯å¤å°ä»¶', 'æ³•å®šä»£è¡¨äººèº«ä»½è¯', 'æ³•äººèº«ä»½è¯', 'æ³•å®šä»£è¡¨äººèº«ä»½è¯æ˜',
                'æ³•äººä»£è¡¨èº«ä»½è¯', 'æ³•äººä»£è¡¨èº«ä»½è¯å¤å°ä»¶',
                'æ³•å®šä»£è¡¨äººå±…æ°‘èº«ä»½è¯',  # æ–°å¢ï¼šæ­£å¼è¡¨è¿°
                'æ³•äººå±…æ°‘èº«ä»½è¯'  # æ–°å¢ï¼šç®€åŒ–è¡¨è¿°
            ],
            'auth_id': [
                'æˆæƒä»£è¡¨èº«ä»½è¯', 'æˆæƒäººèº«ä»½è¯', 'è¢«æˆæƒäººèº«ä»½è¯',
                'æˆæƒä»£è¡¨èº«ä»½è¯å¤å°ä»¶', 'è¢«æˆæƒäººèº«ä»½è¯å¤å°ä»¶',
                'å§”æ‰˜ä»£ç†äººèº«ä»½è¯', 'ä»£ç†äººèº«ä»½è¯å¤å°ä»¶',
                'è¢«æˆæƒä»£è¡¨èº«ä»½è¯', 'è¢«æˆæƒä»£è¡¨èº«ä»½è¯å¤å°ä»¶',  # æ–°å¢ï¼šè¢«æˆæƒä»£è¡¨å˜ä½“
                'æˆæƒä»£è¡¨äººèº«ä»½è¯', 'æˆæƒä»£è¡¨äººèº«ä»½è¯å¤å°ä»¶',  # æ–°å¢ï¼šæˆæƒä»£è¡¨äººå˜ä½“
                'æˆæƒä»£è¡¨å±…æ°‘èº«ä»½è¯', 'è¢«æˆæƒäººå±…æ°‘èº«ä»½è¯',  # æ–°å¢ï¼šæ­£å¼è¡¨è¿°
                'èº«ä»½è¯å¤å°ä»¶',  # æ–°å¢ï¼šé€šç”¨è¡¨è¿°ï¼ˆä¼˜å…ˆçº§ä½ï¼Œä¼šåœ¨æ³•äººèº«ä»½è¯ååŒ¹é…ï¼‰
                'èº«ä»½è¯',  # æ–°å¢ï¼šæœ€ç®€åŒ–è¡¨è¿°ï¼ˆä¼˜å…ˆçº§æœ€ä½ï¼‰
                'å±…æ°‘èº«ä»½è¯'  # æ–°å¢ï¼šæ­£å¼ç®€åŒ–è¡¨è¿°
            ],
            'dishonest_executor': ['å¤±ä¿¡è¢«æ‰§è¡Œäºº', 'å¤±ä¿¡è¢«æ‰§è¡Œäººåå•'],
            'tax_violation_check': ['é‡å¤§ç¨æ”¶è¿æ³•', 'ç¨æ”¶è¿æ³•æ¡ˆä»¶å½“äº‹äººåå•'],
            # æ³¨æ„ï¼šgov_procurement_creditchina å’Œ gov_procurement_ccgp ä½¿ç”¨ç‰¹æ®ŠANDé€»è¾‘å¤„ç†ï¼Œè§ä¸‹æ–¹æ‰«æä»£ç 
            'audit_report': ['å®¡è®¡æŠ¥å‘Š', 'è´¢åŠ¡å®¡è®¡æŠ¥å‘Š', 'å¹´åº¦å®¡è®¡æŠ¥å‘Š', 'ä¼šè®¡å¸ˆäº‹åŠ¡æ‰€å‡ºå…·']
        }

    def scan_insert_points(self, doc: Document, image_config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰«ææ–‡æ¡£ï¼ŒæŸ¥æ‰¾å›¾ç‰‡æ’å…¥ç‚¹ï¼ˆä¸¤é˜¶æ®µè¯†åˆ«æ³•ï¼šæ ¸å¿ƒè¯+ä¸Šä¸‹æ–‡åˆ†ç±»ï¼‰

        Args:
            doc: Wordæ–‡æ¡£å¯¹è±¡
            image_config: å›¾ç‰‡é…ç½®ï¼ˆå¯é€‰ï¼‰ï¼ŒåŒ…å«qualification_detailsç”¨äºç²¾ç¡®åŒ¹é…

        Returns:
            æ’å…¥ç‚¹å­—å…¸ï¼Œé”®å¯ä»¥æ˜¯é€šç”¨ç±»å‹(license/qualification)æˆ–å…·ä½“èµ„è´¨(iso9001/cmmiç­‰)
        """
        import re

        # å€™é€‰ä½ç½®å­—å…¸ï¼š{img_type: [candidate_dict, ...]}
        candidates = {}

        # ä»qualification_matcherå¯¼å…¥æ˜ å°„è¡¨
        from .qualification_matcher import QUALIFICATION_MAPPING

        # è·å–æ–‡æ¡£æ€»æ®µè½æ•°
        total_paragraphs = len(doc.paragraphs)

        # ===== é˜¶æ®µ1ï¼šæ‰«ææ®µè½ï¼ŒåŸºäºæ ¸å¿ƒè¯è¯†åˆ« =====
        self.logger.info(f"ğŸ“„ å¼€å§‹æ‰«ææ–‡æ¡£ï¼ˆå…±{total_paragraphs}ä¸ªæ®µè½ï¼‰")

        for para_idx, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if not text:
                continue

            # è·å–æ®µè½æ ·å¼å
            style_name = paragraph.style.name if paragraph.style else ''

            # ===== 1. è¥ä¸šæ‰§ç…§è¯†åˆ« =====
            if "è¥ä¸šæ‰§ç…§" in text:
                category = self._classify_paragraph(text, para_idx, total_paragraphs, style_name)
                if category != 'exclude':
                    candidates.setdefault('license', []).append({
                        'type': 'paragraph',
                        'index': para_idx,
                        'paragraph': paragraph,
                        'category': category,
                        'text': text[:60]
                    })
                    self.logger.info(f"ğŸ” è¥ä¸šæ‰§ç…§å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

            # ===== 2. èº«ä»½è¯è¯†åˆ«ï¼ˆæ”¯æŒç»„åˆåˆ¤æ–­ï¼‰=====
            if "èº«ä»½è¯" in text:
                category = self._classify_paragraph(text, para_idx, total_paragraphs, style_name)
                if category != 'exclude':
                    # åˆ¤æ–­æ˜¯å“ªç§èº«ä»½è¯
                    has_legal = any(kw in text for kw in ["æ³•å®šä»£è¡¨äºº", "æ³•äºº", "æ³•äººä»£è¡¨"])
                    has_auth = any(kw in text for kw in ["æˆæƒ", "è¢«æˆæƒ", "ä»£ç†äºº", "å§”æ‰˜"])

                    # æ³•äººèº«ä»½è¯
                    if has_legal:
                        candidates.setdefault('legal_id', []).append({
                            'type': 'paragraph',
                            'index': para_idx,
                            'paragraph': paragraph,
                            'category': category,
                            'text': text[:60]
                        })
                        self.logger.info(f"ğŸ” æ³•äººèº«ä»½è¯å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

                    # è¢«æˆæƒäººèº«ä»½è¯
                    if has_auth:
                        candidates.setdefault('auth_id', []).append({
                            'type': 'paragraph',
                            'index': para_idx,
                            'paragraph': paragraph,
                            'category': category,
                            'text': text[:60]
                        })
                        self.logger.info(f"ğŸ” è¢«æˆæƒäººèº«ä»½è¯å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

                    # å¦‚æœä¸¤è€…éƒ½æ²¡æœ‰ï¼Œå¯èƒ½æ˜¯é€šç”¨èº«ä»½è¯è¦æ±‚ï¼ˆä¸¤è€…éƒ½éœ€è¦ï¼‰
                    if not has_legal and not has_auth:
                        # åŒæ—¶ä¸ºä¸¤ç§èº«ä»½è¯æ·»åŠ å€™é€‰
                        for id_type in ['legal_id', 'auth_id']:
                            candidates.setdefault(id_type, []).append({
                                'type': 'paragraph',
                                'index': para_idx,
                                'paragraph': paragraph,
                                'category': category,
                                'text': text[:60]
                            })
                        self.logger.info(f"ğŸ” é€šç”¨èº«ä»½è¯å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

            # ===== 4. æˆæƒä¹¦è¯†åˆ« =====
            if "æˆæƒ" in text and ("æˆæƒä¹¦" in text or "æˆæƒå§”æ‰˜ä¹¦" in text):
                category = self._classify_paragraph(text, para_idx, total_paragraphs, style_name)
                if category != 'exclude':
                    candidates.setdefault('authorization', []).append({
                        'type': 'paragraph',
                        'index': para_idx,
                        'paragraph': paragraph,
                        'category': category,
                        'text': text[:60]
                    })
                    self.logger.info(f"ğŸ” æˆæƒä¹¦å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

            # ===== 5. ç‰¹æ®Šå¤„ç†ï¼šæ”¿åºœé‡‡è´­èµ„è´¨ï¼ˆä½¿ç”¨ä¼˜å…ˆçº§åˆ¤æ–­ï¼‰=====
            #
            # ã€é‡è¦ã€‘ä¸¤ç§ä¸åŒçš„èµ„è´¨ç±»å‹ï¼ˆå¿…é¡»æ­£ç¡®åŒºåˆ†ï¼‰ï¼š
            # 1. gov_procurement_creditchina: åœ¨"ä¿¡ç”¨ä¸­å›½"ç½‘ç«™æŸ¥è¯¢æ”¿åºœé‡‡è´­è¿æ³•è®°å½•
            # 2. gov_procurement_ccgp: åœ¨"ä¸­å›½æ”¿åºœé‡‡è´­ç½‘"æŸ¥è¯¢æ”¿åºœé‡‡è´­è¿æ³•è®°å½•
            #
            # ã€æµ‹è¯•æ¡ˆä¾‹A - åŒæ—¶æåˆ°ä¸¤ä¸ªç½‘ç«™ã€‘ï¼š
            # æ–‡æœ¬ï¼š"å“åº”æ–¹åœ¨'ä¿¡ç”¨ä¸­å›½'ç½‘ç«™...çš„ä¿¡ç”¨æŠ¥å‘ŠåŠ'ä¸­å›½æ”¿åºœé‡‡è´­ç½‘'...çš„æ”¿åºœé‡‡è´­ä¸¥é‡è¿æ³•å¤±ä¿¡è¡Œä¸ºä¿¡æ¯è®°å½•"
            # é¢„æœŸç»“æœï¼š
            #   - creditchina_credit_reportï¼ˆä¿¡ç”¨æŠ¥å‘Šï¼‰ â† å¯¹åº”"ä¿¡ç”¨ä¸­å›½"
            #   - gov_procurement_ccgpï¼ˆæ”¿åºœé‡‡è´­ç½‘æŸ¥è¯¢ï¼‰ â† å¯¹åº”"æ”¿åºœé‡‡è´­ç½‘"
            #   - ä¸åº”è¯¥è¯†åˆ«ä¸º gov_procurement_creditchina âŒ
            #
            # ã€æµ‹è¯•æ¡ˆä¾‹B - åªæä¿¡ç”¨ä¸­å›½ã€‘ï¼š
            # æ–‡æœ¬ï¼š"æœªè¢«åˆ—å…¥'ä¿¡ç”¨ä¸­å›½'ç½‘ç«™å¤±ä¿¡è¢«æ‰§è¡Œäººã€é‡å¤§ç¨æ”¶è¿æ³•ã€æ”¿åºœé‡‡è´­ä¸¥é‡è¿æ³•å¤±ä¿¡è®°å½•åå•"
            # é¢„æœŸç»“æœï¼š
            #   - dishonest_executorï¼ˆå¤±ä¿¡è¢«æ‰§è¡Œäººï¼‰
            #   - tax_violation_checkï¼ˆç¨æ”¶è¿æ³•ï¼‰
            #   - gov_procurement_creditchinaï¼ˆä¿¡ç”¨ä¸­å›½çš„æ”¿åºœé‡‡è´­æŸ¥è¯¢ï¼‰ âœ…
            #
            # ã€è¯†åˆ«é€»è¾‘ã€‘ï¼š
            # ä¼˜å…ˆçº§1ï¼šæ˜ç¡®æåˆ°"æ”¿åºœé‡‡è´­ç½‘"æˆ–"ccgp" â†’ gov_procurement_ccgp
            # ä¼˜å…ˆçº§2ï¼šåªæåˆ°"ä¿¡ç”¨ä¸­å›½"ï¼ˆä¸”æ²¡æœ‰æ”¿åºœé‡‡è´­ç½‘ï¼‰ â†’ gov_procurement_creditchina
            #
            if "æ”¿åºœé‡‡è´­ä¸¥é‡è¿æ³•å¤±ä¿¡" in text:
                category = self._classify_paragraph(text, para_idx, total_paragraphs, style_name)
                if category != 'exclude':
                    # ä¼˜å…ˆçº§1ï¼šæ˜ç¡®æåˆ°"æ”¿åºœé‡‡è´­ç½‘" â†’ è¯†åˆ«ä¸ºæ”¿åºœé‡‡è´­ç½‘æŸ¥è¯¢
                    if "æ”¿åºœé‡‡è´­ç½‘" in text or "ccgp" in text.lower():
                        candidates.setdefault('gov_procurement_ccgp', []).append({
                            'type': 'paragraph',
                            'index': para_idx,
                            'paragraph': paragraph,
                            'category': category,
                            'text': text[:60]
                        })
                        self.logger.info(f"ğŸ” æ”¿åºœé‡‡è´­-æ”¿é‡‡ç½‘å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

                    # ä¼˜å…ˆçº§2ï¼šåªæåˆ°"ä¿¡ç”¨ä¸­å›½"ï¼ˆæ²¡æœ‰æ”¿åºœé‡‡è´­ç½‘ï¼‰â†’ è¯†åˆ«ä¸ºä¿¡ç”¨ä¸­å›½æŸ¥è¯¢
                    elif "ä¿¡ç”¨ä¸­å›½" in text or "creditchina" in text.lower():
                        candidates.setdefault('gov_procurement_creditchina', []).append({
                            'type': 'paragraph',
                            'index': para_idx,
                            'paragraph': paragraph,
                            'category': category,
                            'text': text[:60]
                        })
                        self.logger.info(f"ğŸ” æ”¿åºœé‡‡è´­-ä¿¡ç”¨ä¸­å›½å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, æ–‡æœ¬='{text[:60]}'")

            # ===== 6. æŸ¥æ‰¾å…·ä½“èµ„è´¨ç±»å‹ï¼ˆISO9001, CMMIç­‰ï¼‰=====
            for qual_key, qual_info in QUALIFICATION_MAPPING.items():
                # è·³è¿‡å·²ç‰¹æ®Šå¤„ç†çš„æ”¿åºœé‡‡è´­èµ„è´¨
                if qual_key in ['gov_procurement_creditchina', 'gov_procurement_ccgp']:
                    continue

                keywords = qual_info.get('keywords', [])
                if any(keyword in text for keyword in keywords):
                    category = self._classify_paragraph(text, para_idx, total_paragraphs, style_name)
                    if category != 'exclude':
                        candidates.setdefault(qual_key, []).append({
                            'type': 'paragraph',
                            'index': para_idx,
                            'paragraph': paragraph,
                            'category': category,
                            'text': text[:60]
                        })
                        matched_kw = next((kw for kw in keywords if kw in text), keywords[0])
                        self.logger.info(f"ğŸ” {qual_key}å€™é€‰: æ®µè½#{para_idx}, ç±»åˆ«={category}, å…³é”®è¯='{matched_kw}'")
                    # ä¿®å¤ï¼šåˆ é™¤breakï¼Œå…è®¸ä¸€ä¸ªæ ‡é¢˜åŒ¹é…å¤šä¸ªèµ„è´¨ï¼ˆå¦‚"åŸºç¡€ç”µä¿¡ä¸šåŠ¡ç»è¥è®¸å¯è¯åŠå¢å€¼ç”µä¿¡ä¸šåŠ¡ç»è¥è®¸å¯è¯"ï¼‰

        # ===== æ‰«æè¡¨æ ¼ä¸­çš„èº«ä»½è¯æ’å…¥ç‚¹ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰=====
        self.logger.info(f"ğŸ“‹ å¼€å§‹æ‰«æè¡¨æ ¼ï¼ˆå…±{len(doc.tables)}ä¸ªè¡¨æ ¼ï¼‰")

        for table_idx, table in enumerate(doc.tables):
            for row in table.rows:
                for cell in row.cells:
                    cell_text = cell.text.strip()
                    if not cell_text:
                        continue

                    # èº«ä»½è¯è¡¨æ ¼ç‰¹æ®Šå¤„ç†ï¼ˆæ£€æµ‹è¡¨æ ¼ç‰¹å¾ï¼‰
                    if "èº«ä»½è¯" in cell_text:
                        # æ£€æµ‹æ˜¯å¦ä¸ºèº«ä»½è¯è¡¨æ ¼ï¼ˆåŒ…å«"æ­£åé¢"ã€"å¤´åƒé¢"ç­‰ç‰¹å¾ï¼‰
                        id_table_features = ['æ­£ã€åé¢', 'æ­£åé¢', 'å¤´åƒé¢', 'å›½å¾½é¢', 'äººåƒé¢']
                        is_id_table = any(feature in cell_text for feature in id_table_features)

                        if is_id_table:
                            # åˆ¤æ–­æ˜¯å“ªç§èº«ä»½è¯
                            has_legal = any(kw in cell_text for kw in ["æ³•å®šä»£è¡¨äºº", "æ³•äºº"])
                            has_auth = any(kw in cell_text for kw in ["æˆæƒ", "è¢«æˆæƒ", "ä»£ç†"])

                            # æ³•äººèº«ä»½è¯è¡¨æ ¼ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
                            if has_legal:
                                candidates.setdefault('legal_id', []).append({
                                    'type': 'table_cell',
                                    'table_index': table_idx,
                                    'cell': cell,
                                    'category': 'strong_attach',  # è¡¨æ ¼ç‰¹å¾æ˜ç¡®ï¼Œè®¾ä¸ºå¼ºé™„ä»¶
                                    'text': cell_text[:60]
                                })
                                self.logger.info(f"ğŸ” æ³•äººèº«ä»½è¯è¡¨æ ¼: è¡¨æ ¼#{table_idx}, æ–‡æœ¬='{cell_text[:60]}'")

                            # è¢«æˆæƒäººèº«ä»½è¯è¡¨æ ¼
                            if has_auth:
                                candidates.setdefault('auth_id', []).append({
                                    'type': 'table_cell',
                                    'table_index': table_idx,
                                    'cell': cell,
                                    'category': 'strong_attach',
                                    'text': cell_text[:60]
                                })
                                self.logger.info(f"ğŸ” è¢«æˆæƒäººèº«ä»½è¯è¡¨æ ¼: è¡¨æ ¼#{table_idx}, æ–‡æœ¬='{cell_text[:60]}'")

                            # é€šç”¨èº«ä»½è¯è¡¨æ ¼
                            if not has_legal and not has_auth:
                                for id_type in ['legal_id', 'auth_id']:
                                    candidates.setdefault(id_type, []).append({
                                        'type': 'table_cell',
                                        'table_index': table_idx,
                                        'cell': cell,
                                        'category': 'strong_attach',
                                        'text': cell_text[:60]
                                    })
                                self.logger.info(f"ğŸ” é€šç”¨èº«ä»½è¯è¡¨æ ¼: è¡¨æ ¼#{table_idx}, æ–‡æœ¬='{cell_text[:60]}'")

        # ===== é˜¶æ®µ2ï¼šé€‰æ‹©æœ€ä½³ä½ç½®ï¼ˆåŸºäºåˆ†ç±»ä¼˜å…ˆçº§ï¼‰=====
        self.logger.info(f"ğŸ“Š å¼€å§‹é€‰æ‹©æœ€ä½³æ’å…¥ä½ç½®...")

        # å®šä¹‰åˆ†ç±»ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆï¼‰
        category_priority = {
            'strong_attach': 100,        # å¼ºé™„ä»¶æ ‡è®°ï¼ˆæœ€ä¼˜ï¼‰
            'weak_attach': 80,           # å¼±é™„ä»¶æ ‡è®°
            'neutral': 50,               # ä¸­æ€§ä½ç½®
            'chapter': 30,               # ç« èŠ‚æ ‡é¢˜
            'toc': 10,                   # ç›®å½•
            'reference': 5,              # æ­£æ–‡å¼•ç”¨
            'requirement_clause': -10,   # æ‹›æ ‡è¦æ±‚æ¡æ¬¾ï¼ˆå¯ç”¨ä½†ä¸æ¨èï¼‰
            'header_noise': -50,         # æ–‡æ¡£æ ‡é¢˜å™ªéŸ³ï¼ˆåŸºæœ¬ä¸ç”¨ï¼‰
            'exclude': -999,             # ç»å¯¹æ’é™¤ï¼ˆé¡µçœ‰é¡µè„šã€é™„ä»¶æ¸…å•æ ‡é¢˜ï¼‰
        }

        insert_points = {}

        for img_type, candidate_list in candidates.items():
            if not candidate_list:
                self.logger.warning(f"âš ï¸ {img_type}æœªæ‰¾åˆ°ä»»ä½•å€™é€‰ä½ç½®ï¼Œå°†ä½¿ç”¨é™çº§ç­–ç•¥ï¼ˆæ–‡æ¡£æœ«å°¾ï¼‰")
                continue

            # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³å€™é€‰
            # æ’åºè§„åˆ™ï¼š1. ç±»åˆ«ä¼˜å…ˆçº§ï¼ˆé«˜ä¼˜å…ˆï¼‰ 2. æ–‡æœ¬ç®€çŸ­ï¼ˆç®€çŸ­ä¼˜å…ˆï¼‰ 3. ä½ç½®é åï¼ˆé åä¼˜å…ˆï¼‰
            best_candidate = max(candidate_list, key=lambda x: (
                category_priority.get(x['category'], 0),  # å…ˆæŒ‰ç±»åˆ«ä¼˜å…ˆçº§
                -len(x['text']),                          # æ–‡æœ¬è¶ŠçŸ­è¶Šå¥½ï¼ˆè´Ÿå·å®ç°ï¼‰
                x.get('index', 0)                         # ä½ç½®è¶Šé åè¶Šå¥½
            ))

            best_category = best_candidate['category']
            best_priority = category_priority.get(best_category, 0)

            # æ„å»ºæ’å…¥ç‚¹ä¿¡æ¯
            insert_point = {
                'type': best_candidate['type'],
                'category': best_category,
                'matched_keyword': best_candidate.get('text', '')[:30]
            }

            if best_candidate['type'] == 'paragraph':
                insert_point['index'] = best_candidate['index']
                insert_point['paragraph'] = best_candidate['paragraph']
            elif best_candidate['type'] == 'table_cell':
                insert_point['table_index'] = best_candidate['table_index']
                insert_point['cell'] = best_candidate['cell']

            insert_points[img_type] = insert_point

            # å‹å¥½çš„æ—¥å¿—è¾“å‡ºï¼ˆæ ¹æ®è´¨é‡çº§åˆ«ï¼‰
            if best_priority >= 80:
                self.logger.info(
                    f"âœ… {img_type}: æ‰¾åˆ°ä¼˜è´¨ä½ç½® [{best_category}] "
                    f"'{best_candidate['text']}' (å…±{len(candidate_list)}ä¸ªå€™é€‰)"
                )
            elif best_priority >= 30:
                self.logger.info(
                    f"â˜‘ï¸ {img_type}: æ‰¾åˆ°å¯ç”¨ä½ç½® [{best_category}] "
                    f"'{best_candidate['text']}' (å…±{len(candidate_list)}ä¸ªå€™é€‰)"
                )
            elif best_priority >= 0:
                self.logger.warning(
                    f"âš ï¸ {img_type}: æ‰¾åˆ°æ¬¡ä¼˜ä½ç½® [{best_category}] "
                    f"'{best_candidate['text']}' (å…±{len(candidate_list)}ä¸ªå€™é€‰)"
                )
            else:
                self.logger.warning(
                    f"ğŸ”» {img_type}: ä»…æ‰¾åˆ°ä½è´¨é‡ä½ç½® [{best_category}] (è¯„åˆ†:{best_priority}) "
                    f"'{best_candidate['text']}' (å…±{len(candidate_list)}ä¸ªå€™é€‰)"
                )

        # è¾“å‡ºæ‰«ææ€»ç»“
        self.logger.info(f"ğŸ“Š æ‰«æå®Œæˆ: æ‰¾åˆ° {len(insert_points)} ä¸ªæ’å…¥ç‚¹ - {list(insert_points.keys())}")
        return insert_points

    def _classify_paragraph(self, text: str, para_idx: int, total_paras: int,
                           style_name: str = '') -> str:
        """
        æ®µè½åˆ†ç±»ï¼ˆç¬¦åˆäººçš„åˆ¤æ–­é€»è¾‘ï¼‰

        åˆ†ç±»ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
        1. strong_attach      - å¼ºé™„ä»¶æ ‡è®°ï¼ˆç¼–å·é™„ä»¶ã€é™„ä»¶æ ‡é¢˜ï¼‰ 100åˆ†
        2. weak_attach        - å¼±é™„ä»¶æ ‡è®°ï¼ˆè¯´æ˜æ€§æ–‡å­—ã€"åé™„"ï¼‰ 80åˆ†
        3. neutral            - ä¸­æ€§ä½ç½®ï¼ˆæ™®é€šæ®µè½ï¼‰ 50åˆ†
        4. chapter            - ç« èŠ‚æ ‡é¢˜ï¼ˆä¸ç†æƒ³ä½†å¯æ¥å—ï¼‰ 30åˆ†
        5. toc                - ç›®å½•ï¼ˆå¾ˆä¸ç†æƒ³ï¼‰ 10åˆ†
        6. reference          - æ­£æ–‡å¼•ç”¨ï¼ˆæœ€ä¸ç†æƒ³ï¼‰ 5åˆ†
        7. requirement_clause - æ‹›æ ‡è¦æ±‚æ¡æ¬¾ï¼ˆå¯ç”¨ä½†ä¸æ¨èï¼‰ -10åˆ†
        8. header_noise       - æ–‡æ¡£æ ‡é¢˜å™ªéŸ³ï¼ˆåŸºæœ¬ä¸ç”¨ï¼‰ -50åˆ†
        9. exclude            - ç»å¯¹æ’é™¤ï¼ˆé¡µçœ‰é¡µè„šã€é™„ä»¶æ¸…å•æ ‡é¢˜ï¼‰ -999åˆ†

        Args:
            text: æ®µè½æ–‡æœ¬
            para_idx: æ®µè½ç´¢å¼•
            total_paras: æ–‡æ¡£æ€»æ®µè½æ•°
            style_name: Wordæ ·å¼åï¼ˆå¯é€‰ï¼‰

        Returns:
            åˆ†ç±»å­—ç¬¦ä¸²
        """
        import re

        # ========== 1. excludeï¼ˆç»å¯¹æ’é™¤ - ä»…ä¿ç•™æŠ€æœ¯æ€§ç¦åŒºï¼‰==========

        # é¡µçœ‰é¡µè„šï¼ˆæŠ€æœ¯ç¦åŒºï¼‰
        if style_name and ('Header' in style_name or 'Footer' in style_name):
            return 'exclude'

        # é™„ä»¶æ¸…å•æ ‡é¢˜ï¼ˆè¯­ä¹‰ç¦åŒºï¼‰
        if "é™„ä»¶æ¸…å•" in text or "é™„ä»¶ç›®å½•" in text:
            return 'exclude'

        # ========== 2. strong_attachï¼ˆå¼ºé™„ä»¶æ ‡è®°ï¼‰==========

        # ç¼–å·é™„ä»¶ï¼ˆæœ€å¼ºä¿¡å·ï¼‰- "5-1 è¥ä¸šæ‰§ç…§"
        if re.match(r'^\d+[-.]?\d*\s+', text):
            return 'strong_attach'

        # é™„ä»¶æ ‡é¢˜ - "é™„ä»¶ï¼šè¥ä¸šæ‰§ç…§"ã€"é™„ï¼šè¥ä¸šæ‰§ç…§"
        if (text.startswith("é™„ä»¶") or text.startswith("é™„ï¼š")) and len(text) < 50:
            return 'strong_attach'

        # ========== 3. weak_attachï¼ˆå¼±é™„ä»¶æ ‡è®°ï¼‰==========

        # è¯´æ˜æ€§æŒ‡ç¤º
        if any(pattern in text for pattern in [
            "åé™„", "å¦‚ä¸‹", "è§ä¸‹", "ä»¥ä¸‹ä¸º", "å¦‚ä¸‹æ‰€ç¤º", "è§å"
        ]) and len(text) < 50:
            return 'weak_attach'

        # åŒ…å«"é™„ä»¶"ä½†è¾ƒé•¿ï¼ˆå¯èƒ½æ˜¯é™„ä»¶è¯´æ˜ï¼‰
        if "é™„ä»¶" in text and 20 < len(text) < 80:
            return 'weak_attach'

        # ========== 4. chapterï¼ˆç« èŠ‚æ ‡é¢˜ï¼‰==========

        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
        is_chapter = any([
            text.startswith("ç¬¬") and ("ç« " in text or "èŠ‚" in text or "éƒ¨åˆ†" in text),
            re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€ï¼.]', text),
            'Heading' in style_name,  # Wordæ ·å¼ä¸ºæ ‡é¢˜
        ])

        if is_chapter:
            # ç‰¹æ®Šæƒ…å†µï¼šå°èŠ‚æ ‡é¢˜ä¸”ç®€çŸ­ï¼Œå¯èƒ½æ˜¯æ’å…¥ç‚¹
            # å¦‚ "5.1 è¥ä¸šæ‰§ç…§å‰¯æœ¬"
            if re.match(r'^\d+\.\d+', text) and len(text) < 30:
                return 'weak_attach'  # å‡çº§ä¸ºå¼±é™„ä»¶
            return 'chapter'

        # ========== 5. tocï¼ˆç›®å½•ï¼‰==========

        if any([
            "ç›®å½•" in text,
            "......" in text or "â€¦â€¦â€¦â€¦" in text,  # ç›®å½•ç‰¹å¾
            para_idx < total_paras * 0.05,  # æ–‡æ¡£å‰5%
            "TOC" in style_name,  # Wordç›®å½•æ ·å¼
        ]):
            return 'toc'

        # ========== 6. referenceï¼ˆæ­£æ–‡å¼•ç”¨ï¼‰==========

        # æ­£æ–‡ä¸­çš„å¼•ç”¨/æè¿°
        if any(keyword in text for keyword in [
            "æ ¹æ®", "ä¾æ®", "æŒ‰ç…§", "å‚ç…§",
            "è®°è½½", "æ‰€ç¤º", "æ˜¾ç¤º", "é¢å‘çš„",
        ]) and len(text) > 30:  # è¾ƒé•¿çš„å¥å­
            return 'reference'

        # ========== 7. requirement_clauseï¼ˆæ‹›æ ‡è¦æ±‚æ¡æ¬¾ -10åˆ†ï¼‰==========
        # ğŸ“Œ ä»excludeé™çº§ä¸ºè´Ÿåˆ†è¯„åˆ†é¡¹

        # æ‹›æ ‡æ–‡ä»¶çš„è¦æ±‚æ¡æ¬¾
        if any(pattern in text for pattern in [
            "é¡»åœ¨å“åº”æ–‡ä»¶ä¸­æä¾›",
            "åº”åœ¨æŠ•æ ‡æ–‡ä»¶ä¸­æä¾›",
            "æŠ•æ ‡äººé¡»æä¾›", "å“åº”æ–¹é¡»æä¾›",
            "æŠ•æ ‡äººéœ€æä¾›", "å“åº”æ–¹éœ€æä¾›",
        ]):
            return 'requirement_clause'

        if ("å¦‚å“åº”æ–¹" in text or "å¦‚æŠ•æ ‡äºº" in text) and "é¡»" in text:
            return 'requirement_clause'

        # ========== 8. header_noiseï¼ˆæ–‡æ¡£æ ‡é¢˜å™ªéŸ³ -50åˆ†ï¼‰==========

        # æ–‡æ¡£å¼€å¤´çš„æçŸ­æ–‡æœ¬
        if len(text) < 10 and para_idx < 3:
            # å¦‚æœæ˜¯å…³é”®è¯æ ‡é¢˜ï¼Œæ­£å¸¸è¯„åˆ†
            if any(kw in text for kw in ['è¥ä¸šæ‰§ç…§', 'èº«ä»½è¯', 'æˆæƒä¹¦', 'èµ„è´¨', 'è¯ä¹¦']):
                return 'neutral'
            else:
                return 'header_noise'

        # ========== 9. neutralï¼ˆä¸­æ€§ä½ç½® - é»˜è®¤ï¼‰==========

        return 'neutral'

    # ==================== ğŸ†• æ¡ˆä¾‹è¡¨æ ¼å¤„ç†ç›¸å…³æ–¹æ³• ====================

    def scan_case_requirements(self, doc: Document) -> list:
        """
        æ‰«ææ–‡æ¡£ä¸­"æ ¼å¼è‡ªæ‹Ÿ"çš„ä¸šç»©æ¡ˆä¾‹è¦æ±‚

        åŠŸèƒ½ï¼š
        1. è¯†åˆ«åŒ…å«"æ¡ˆä¾‹"+"æ ¼å¼è‡ªæ‹Ÿ"å…³é”®è¯çš„æ®µè½
        2. æ™ºèƒ½å»é‡ï¼šæ£€æŸ¥é™„è¿‘æ˜¯å¦å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼
        3. è¿”å›éœ€è¦ç”Ÿæˆè¡¨æ ¼çš„ä½ç½®åˆ—è¡¨

        è¯†åˆ«è§„åˆ™ï¼š
        - æ¡ˆä¾‹å…³é”®è¯ï¼šä¸šç»©æ¡ˆä¾‹ã€èµ„æ ¼æ¡ˆä¾‹ã€é¡¹ç›®æ¡ˆä¾‹ã€é¡¹ç›®ç»éªŒç­‰
        - æ ¼å¼è‡ªæ‹Ÿå…³é”®è¯ï¼šæ ¼å¼è‡ªæ‹Ÿã€è‡ªæ‹Ÿæ ¼å¼ã€è‡ªè¡Œç¼–åˆ¶ã€æ ¼å¼ä¸é™ç­‰

        æ™ºèƒ½å»é‡ï¼š
        - æ£€æŸ¥æ®µè½å10ä¸ªæ®µè½èŒƒå›´å†…æ˜¯å¦å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼
        - å¦‚æœæœ‰è¡¨æ ¼ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
        - å¦‚æœæ— è¡¨æ ¼ï¼Œæ ‡è®°ä¸ºéœ€è¦ç”Ÿæˆ

        Args:
            doc: Wordæ–‡æ¡£å¯¹è±¡

        Returns:
            æ¡ˆä¾‹è¦æ±‚ä½ç½®åˆ—è¡¨
            [
                {
                    'type': 'paragraph',
                    'paragraph': paragraphå¯¹è±¡,
                    'index': æ®µè½ç´¢å¼•,
                    'text': 'å…«ã€èµ„æ ¼æ¡ˆä¾‹ï¼ˆåŠ ç›–å…¬ç« ï¼‰',
                    'requirement_text': 'æ ¼å¼è‡ªæ‹Ÿ',
                    'insert_position': 'after'
                },
                ...
            ]
        """
        case_requirements = []

        # æ¡ˆä¾‹ç›¸å…³å…³é”®è¯
        case_keywords = [
            'ä¸šç»©æ¡ˆä¾‹', 'èµ„æ ¼æ¡ˆä¾‹', 'é¡¹ç›®æ¡ˆä¾‹', 'ç±»ä¼¼æ¡ˆä¾‹',
            'ä¸šç»©', 'é¡¹ç›®ç»éªŒ', 'åŒç±»é¡¹ç›®', 'ä»¥å¾€é¡¹ç›®',
            'é¡¹ç›®å®æ–½ç»éªŒ', 'å®Œæˆçš„é¡¹ç›®', 'é¡¹ç›®ä¸šç»©'
        ]

        # "æ ¼å¼è‡ªæ‹Ÿ"æŒ‡ç¤ºè¯
        format_free_keywords = [
            'æ ¼å¼è‡ªæ‹Ÿ', 'è‡ªæ‹Ÿæ ¼å¼', 'è‡ªè¡Œç¼–åˆ¶',
            'è‡ªè¡Œè®¾è®¡', 'æ ¼å¼ä¸é™', 'è‡ªå®šä¹‰æ ¼å¼',
            'æ ¼å¼ç”±æŠ•æ ‡äººè‡ªå®š', 'æŒ‰æŠ•æ ‡äººæ ¼å¼', 'è‡ªè¡Œæä¾›æ ¼å¼'
        ]

        self.logger.info(f"ğŸ“‹ å¼€å§‹æ‰«ææ ¼å¼è‡ªæ‹Ÿçš„æ¡ˆä¾‹è¦æ±‚...")

        for para_idx, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if not text:
                continue

            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¡ˆä¾‹å…³é”®è¯
            has_case_keyword = any(kw in text for kw in case_keywords)

            # æ£€æŸ¥æ˜¯å¦åŒ…å«"æ ¼å¼è‡ªæ‹Ÿ"æŒ‡ç¤º
            has_format_free = any(kw in text for kw in format_free_keywords)

            if has_case_keyword:
                # æƒ…å†µ1ï¼šå½“å‰æ®µè½åŒæ—¶åŒ…å«æ¡ˆä¾‹+æ ¼å¼è‡ªæ‹Ÿ
                if has_format_free:
                    # æ™ºèƒ½å»é‡ï¼šæ£€æŸ¥é™„è¿‘æ˜¯å¦å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼
                    nearby_has_case_table = self._check_nearby_case_table(
                        doc, para_idx, search_range=10
                    )

                    if nearby_has_case_table:
                        self.logger.info(
                            f"â­ï¸  æ®µè½#{para_idx}é™„è¿‘å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼ï¼Œè·³è¿‡ç”Ÿæˆ: '{text[:60]}'"
                        )
                        continue

                    # éœ€è¦ç”Ÿæˆè¡¨æ ¼
                    case_requirements.append({
                        'type': 'paragraph',
                        'paragraph': paragraph,
                        'index': para_idx,
                        'text': text,
                        'requirement_text': 'æ ¼å¼è‡ªæ‹Ÿ',
                        'insert_position': 'after',
                        'reason': 'å½“å‰æ®µè½åŒ…å«æ¡ˆä¾‹+æ ¼å¼è‡ªæ‹Ÿ'
                    })
                    self.logger.info(
                        f"ğŸ” è¯†åˆ«åˆ°éœ€è¦ç”Ÿæˆæ¡ˆä¾‹è¡¨æ ¼: æ®µè½#{para_idx}, '{text[:60]}'"
                    )

                # æƒ…å†µ2ï¼šä¸‹ä¸€æ®µè½åŒ…å«"æ ¼å¼è‡ªæ‹Ÿ"ï¼ˆæ ‡é¢˜å’Œå†…å®¹åˆ†æ®µçš„æƒ…å†µï¼‰
                elif para_idx + 1 < len(doc.paragraphs):
                    next_para = doc.paragraphs[para_idx + 1]
                    next_text = next_para.text.strip()
                    if any(kw in next_text for kw in format_free_keywords):
                        # æ™ºèƒ½å»é‡
                        nearby_has_case_table = self._check_nearby_case_table(
                            doc, para_idx + 1, search_range=10
                        )

                        if nearby_has_case_table:
                            self.logger.info(
                                f"â­ï¸  æ®µè½#{para_idx}é™„è¿‘å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼ï¼Œè·³è¿‡ç”Ÿæˆ: '{text[:60]}'"
                            )
                            continue

                        # ä½¿ç”¨ä¸‹ä¸€æ®µè½ä½œä¸ºæ’å…¥ç‚¹
                        case_requirements.append({
                            'type': 'paragraph',
                            'paragraph': next_para,
                            'index': para_idx + 1,
                            'text': text,
                            'requirement_text': next_text,
                            'insert_position': 'after',
                            'reason': 'æ¡ˆä¾‹æ ‡é¢˜åœ¨å½“å‰æ®µï¼Œæ ¼å¼è¯´æ˜åœ¨ä¸‹ä¸€æ®µ'
                        })
                        self.logger.info(
                            f"ğŸ” è¯†åˆ«åˆ°éœ€è¦ç”Ÿæˆæ¡ˆä¾‹è¡¨æ ¼: æ®µè½#{para_idx}, '{text[:60]}' "
                            f"(æ ¼å¼è¯´æ˜åœ¨ä¸‹ä¸€æ®µ)"
                        )

        self.logger.info(f"ğŸ“Š æ‰«æå®Œæˆ: è¯†åˆ«åˆ° {len(case_requirements)} å¤„éœ€è¦ç”Ÿæˆæ¡ˆä¾‹è¡¨æ ¼çš„ä½ç½®")
        return case_requirements

    def _check_nearby_case_table(self, doc: Document, para_idx: int,
                                 search_range: int = 10) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šæ®µè½é™„è¿‘æ˜¯å¦å·²æœ‰æ¡ˆä¾‹è¡¨æ ¼

        æ£€æµ‹èŒƒå›´ï¼š
        - å‘åæœç´¢Nä¸ªæ®µè½ï¼ˆé»˜è®¤10ä¸ªï¼‰
        - å¦‚æœé‡åˆ°æ–°çš„ç« èŠ‚æ ‡é¢˜ï¼Œåœæ­¢æœç´¢

        æ£€æµ‹æ–¹æ³•ï¼š
        - éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰è¡¨æ ¼
        - æ£€æŸ¥è¡¨æ ¼ä½ç½®æ˜¯å¦åœ¨æœç´¢èŒƒå›´å†…
        - ä½¿ç”¨CaseTableFillerçš„è¯†åˆ«é€»è¾‘åˆ¤æ–­æ˜¯å¦ä¸ºæ¡ˆä¾‹è¡¨æ ¼

        Args:
            doc: Wordæ–‡æ¡£å¯¹è±¡
            para_idx: èµ·å§‹æ®µè½ç´¢å¼•
            search_range: å‘åæœç´¢çš„æ®µè½æ•°é‡

        Returns:
            True: é™„è¿‘æœ‰æ¡ˆä¾‹è¡¨æ ¼
            False: é™„è¿‘æ— æ¡ˆä¾‹è¡¨æ ¼
        """
        # è®¡ç®—æœç´¢èŒƒå›´çš„ç»“æŸæ®µè½ç´¢å¼•
        end_idx = min(para_idx + search_range, len(doc.paragraphs))

        # è·å–æœç´¢èŒƒå›´å†…çš„æ®µè½å…ƒç´ 
        search_paragraphs = []
        for i in range(para_idx, end_idx):
            if i >= len(doc.paragraphs):
                break

            para = doc.paragraphs[i]

            # å¦‚æœé‡åˆ°æ–°çš„ç« èŠ‚æ ‡é¢˜ï¼Œåœæ­¢æœç´¢
            if self._is_chapter_title(para.text):
                self.logger.debug(f"  é‡åˆ°æ–°ç« èŠ‚ï¼Œåœæ­¢æœç´¢: {para.text[:30]}")
                break

            search_paragraphs.append(para._element)

        if not search_paragraphs:
            return False

        # éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰è¡¨æ ¼
        for table in doc.tables:
            table_element = table._element

            # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åœ¨æœç´¢èŒƒå›´å†…
            if self._is_table_in_range(table_element, search_paragraphs):
                # ä½¿ç”¨CaseTableFillerçš„è¯†åˆ«é€»è¾‘
                # ä¸´æ—¶å¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
                try:
                    from .case_table_filler import CaseTableFiller
                    temp_filler = CaseTableFiller(None)  # ä¸´æ—¶åˆ›å»ºï¼Œåªç”¨äºè¯†åˆ«

                    if temp_filler._is_case_table(table):
                        self.logger.debug(f"  âœ… åœ¨æœç´¢èŒƒå›´å†…æ‰¾åˆ°æ¡ˆä¾‹è¡¨æ ¼")
                        return True
                except ImportError:
                    self.logger.warning("  âš ï¸ æ— æ³•å¯¼å…¥CaseTableFillerï¼Œè·³è¿‡è¡¨æ ¼æ£€æµ‹")
                    return False

        self.logger.debug(f"  âŒ æœç´¢èŒƒå›´å†…æœªæ‰¾åˆ°æ¡ˆä¾‹è¡¨æ ¼")
        return False

    def _is_table_in_range(self, table_element, paragraph_elements: list) -> bool:
        """
        æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åœ¨æ®µè½èŒƒå›´å†…

        é€šè¿‡éå†çˆ¶å…ƒç´ çš„å­å…ƒç´ ï¼Œæ£€æŸ¥è¡¨æ ¼æ˜¯å¦å‡ºç°åœ¨æ®µè½ä¹‹å

        Args:
            table_element: è¡¨æ ¼å…ƒç´ 
            paragraph_elements: æ®µè½å…ƒç´ åˆ—è¡¨

        Returns:
            True: è¡¨æ ¼åœ¨èŒƒå›´å†…
            False: è¡¨æ ¼ä¸åœ¨èŒƒå›´å†…
        """
        if not paragraph_elements:
            return False

        # è·å–ç¬¬ä¸€ä¸ªæ®µè½çš„çˆ¶å…ƒç´ ï¼ˆé€šå¸¸æ˜¯bodyæˆ–sectionï¼‰
        parent = paragraph_elements[0].getparent()
        if parent is None:
            return False

        # æ ‡è®°æ˜¯å¦è¿›å…¥æœç´¢èŒƒå›´
        in_range = False

        for child in parent:
            # å¦‚æœé‡åˆ°èµ·å§‹æ®µè½ï¼Œå¼€å§‹æœç´¢
            if child == paragraph_elements[0]:
                in_range = True
                continue

            # å¦‚æœåœ¨èŒƒå›´å†…ä¸”é‡åˆ°è¡¨æ ¼ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡è¡¨æ ¼
            if in_range and child.tag.endswith('}tbl'):
                if child == table_element:
                    return True

            # å¦‚æœé‡åˆ°æœ€åä¸€ä¸ªæœç´¢æ®µè½ä¹‹åçš„æ®µè½ï¼Œåœæ­¢
            if in_range and child in paragraph_elements:
                # è¿˜åœ¨èŒƒå›´å†…ï¼Œç»§ç»­
                continue
            elif in_range and child not in paragraph_elements:
                # æ£€æŸ¥æ˜¯å¦å·²ç»è¶…å‡ºèŒƒå›´
                # ï¼ˆè¶…å‡ºæœ€åä¸€ä¸ªæ®µè½ï¼‰
                found_last = False
                for para_elem in paragraph_elements:
                    if child.getprevious() == para_elem:
                        found_last = True
                        break
                if found_last:
                    # å·²ç»è¶…å‡ºèŒƒå›´
                    break

        return False

    def _is_chapter_title(self, text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºç« èŠ‚æ ‡é¢˜

        å¸¸è§ç« èŠ‚æ ‡é¢˜ç‰¹å¾ï¼š
        - ä¸€ã€äºŒã€ä¸‰ã€...
        - ç¬¬ä¸€ç« ã€ç¬¬äºŒç« ã€...
        - 1.ã€2.ã€3.ã€...

        Args:
            text: æ®µè½æ–‡æœ¬

        Returns:
            True: æ˜¯ç« èŠ‚æ ‡é¢˜
            False: ä¸æ˜¯ç« èŠ‚æ ‡é¢˜
        """
        import re

        text = text.strip()
        if not text:
            return False

        patterns = [
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€ï¼.]',  # ä¸€ã€ äºŒã€
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« ',      # ç¬¬ä¸€ç« 
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+èŠ‚',      # ç¬¬ä¸€èŠ‚
            r'^\d+[ã€ï¼.]',                        # 1ã€ 2ã€
            r'^\d+\.\d+',                          # 1.1 2.3
        ]

        for pattern in patterns:
            if re.match(pattern, text):
                return True

        return False
