#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•†åŠ¡åº”ç­”å…±äº«å·¥å…·æ¨¡å— - æ ¸å¿ƒå¤ç”¨ç»„ä»¶

æä¾›æ‰€æœ‰business_responseæ¨¡å—å…±äº«çš„å·¥å…·å‡½æ•°å’Œç®—æ³•ï¼š
- æ ¼å¼ä¿æŒç®—æ³• (Format Preservation)
- å ä½ç¬¦å¤„ç†å·¥å…· (Placeholder Tools)  
- æ­£åˆ™æ¨¡å¼åŒ¹é…å¼•æ“ (Pattern Engine)
- å­—æ®µæ˜ å°„ç®¡ç†å™¨ (Field Mapper)
- æ–‡æœ¬å¤„ç†å·¥å…·é›† (Text Utils)

è®¾è®¡ç†å¿µï¼šé€šè¿‡é›†ä¸­ç®¡ç†å…±äº«ç®—æ³•ï¼Œæå‡ä»£ç å¤ç”¨ç‡40-50%ï¼Œå‡å°‘é‡å¤å®ç°
"""

import re
from typing import Dict, List, Optional, Tuple, Any, Union
import logging

logger = logging.getLogger(__name__)

# =====================================
# 1. å­—æ®µæ˜ å°„ç®¡ç†å™¨ (Field Mapper)
# =====================================

class FieldMapper:
    """ç»Ÿä¸€çš„å­—æ®µæ˜ å°„å’Œè½¬æ¢è§„åˆ™ç®¡ç†"""
    
    # å…¬å¸ä¿¡æ¯å­—æ®µæ˜ å°„ (ç›´æ¥æ˜ å°„)
    COMPANY_FIELD_MAPPING = {
        'companyName': 'å…¬å¸åç§°',
        'email': 'é‚®ç®±', 
        'fax': 'ä¼ çœŸ',
        'postalCode': 'é‚®æ”¿ç¼–ç ',
        'establishDate': 'æˆç«‹æ—¶é—´',
        'businessScope': 'ç»è¥èŒƒå›´',
        'legalRepresentative': 'æ³•å®šä»£è¡¨äºº',
        'authorizedPersonName': 'è¢«æˆæƒäººå§“å'
    }
    
    # å¤šæºæ˜ å°„å­—æ®µ (æŒ‰ä¼˜å…ˆçº§é¡ºåº)
    MULTI_SOURCE_MAPPING = {
        'address': ['address', 'registeredAddress', 'officeAddress'],
        'phone': ['fixedPhone', 'phone']
    }
    
    # æ™ºèƒ½æ˜ å°„å­—æ®µ (éœ€ä¸Šä¸‹æ–‡è¯†åˆ«)
    SMART_MAPPING = {
        'authorizedPersonPosition': 'è¢«æˆæƒäººèŒåŠ¡',
        'legalRepresentativePosition': 'æ³•å®šä»£è¡¨äººèŒä½'
    }
    
    # é¡¹ç›®ä¿¡æ¯å­—æ®µæ˜ å°„
    PROJECT_FIELD_MAPPING = {
        'projectName': 'é¡¹ç›®åç§°',
        'projectNumber': 'é¡¹ç›®ç¼–å·', 
        'date': 'æ—¥æœŸ',
        'purchaserName': 'é‡‡è´­äººåç§°'
    }
    
    @classmethod
    def get_field_value(cls, data: Dict[str, Any], field_key: str) -> Optional[str]:
        """
        è·å–å­—æ®µå€¼ï¼Œæ”¯æŒå¤šæºæ˜ å°„å’Œå›é€€ç­–ç•¥
        
        Args:
            data: æ•°æ®å­—å…¸
            field_key: å­—æ®µé”®å
            
        Returns:
            å­—æ®µå€¼æˆ–None
        """
        # ç›´æ¥æ˜ å°„
        if field_key in data and data[field_key]:
            return str(data[field_key]).strip()
            
        # å¤šæºæ˜ å°„
        if field_key in cls.MULTI_SOURCE_MAPPING:
            for source_key in cls.MULTI_SOURCE_MAPPING[field_key]:
                if source_key in data and data[source_key]:
                    return str(data[source_key]).strip()
                    
        return None
    
    @classmethod
    def get_unified_field_mapping(cls) -> Dict[str, str]:
        """è·å–ç»Ÿä¸€çš„å­—æ®µæ˜ å°„å­—å…¸"""
        mapping = {}
        mapping.update(cls.COMPANY_FIELD_MAPPING)
        mapping.update(cls.SMART_MAPPING)
        mapping.update(cls.PROJECT_FIELD_MAPPING)
        return mapping

# =====================================
# 2. æ­£åˆ™æ¨¡å¼åŒ¹é…å¼•æ“ (Pattern Engine)  
# =====================================

class PatternMatcher:
    """ç»Ÿä¸€çš„æ¨¡å¼åŒ¹é…å¼•æ“"""
    
    # ä¾›åº”å•†åç§°å˜ä½“ (14ç§)
    SUPPLIER_NAME_VARIANTS = [
        'ä¾›åº”å•†åç§°', 'ä¾›åº”å•†å…¨ç§°', 'æŠ•æ ‡äººåç§°', 'å…¬å¸åç§°',
        'å•ä½åç§°', 'åº”ç­”äººåç§°', 'æŠ•æ ‡å•ä½', 'æ‰¿åŒ…å•†åç§°',
        'æœåŠ¡å•†åç§°', 'å‚å•†åç§°', 'ä¹™æ–¹åç§°', 'é¡¹ç›®å®æ–½æ–¹',
        'å“åº”äººåç§°', 'å“åº”äººå…¨ç§°'  # æ–°å¢ï¼šå“åº”äººåç§°å˜ä½“
    ]
    
    # æ‹¬å·æ›¿æ¢æ¨¡å¼
    BRACKET_PATTERNS = {
        'supplier': r'[ï¼ˆ(]\s*(?:' + '|'.join(SUPPLIER_NAME_VARIANTS) + r')\s*[ï¼‰)]',
        'purchaser': r'[ï¼ˆ(]\s*é‡‡è´­äºº\s*[ï¼‰)]',
        'project_name': r'[ï¼ˆ(]\s*é¡¹ç›®åç§°\s*[ï¼‰)]',  
        'project_number': r'[ï¼ˆ(]\s*(?:é¡¹ç›®ç¼–å·|æ‹›æ ‡ç¼–å·|é¡¹ç›®å·)\s*[ï¼‰)]',
        'combination': r'[ï¼ˆ(]\s*([^ï¼‰)]+)\s*[ï¼‰)]'
    }
    
    # å¡«ç©ºæ¨¡å¼ (6ç§)
    FILL_PATTERNS = {
        'underline': r'([^ï¼š:\s]+)\s*[ï¼š:]\s*_{2,}',  # å­—æ®µåï¼š___
        'colon': r'([^ï¼š:\s]+)\s*[ï¼š:]\s*$',          # å­—æ®µåï¼š
        'mixed': r'([^ï¼š:\s]+)\s*[ï¼š:]\s*[_\s]+',     # å­—æ®µåï¼š___ (æ··åˆ)
        'period': r'([^ï¼š:\s]+)\s*[ï¼š:]\s*_{2,}\s*[ã€‚.]', # å­—æ®µåï¼š___.
        'space': r'([^ï¼š:\s]+)(?=\s+)(?![ï¼š:])',      # å­—æ®µå (æ— å†’å·)
        'space_under': r'([^ï¼š:\s]+)\s+_{2,}'         # å­—æ®µå ___
    }
    
    @classmethod
    def find_bracket_matches(cls, text: str, pattern_type: str) -> List[Tuple[str, int, int]]:
        """
        æŸ¥æ‰¾æ‹¬å·æ¨¡å¼åŒ¹é…
        
        Args:
            text: è¦æœç´¢çš„æ–‡æœ¬
            pattern_type: æ¨¡å¼ç±»å‹ ('supplier', 'purchaser', etc.)
            
        Returns:
            åŒ¹é…ç»“æœåˆ—è¡¨ [(åŒ¹é…æ–‡æœ¬, å¼€å§‹ä½ç½®, ç»“æŸä½ç½®)]
        """
        if pattern_type not in cls.BRACKET_PATTERNS:
            return []
            
        pattern = cls.BRACKET_PATTERNS[pattern_type]
        matches = []
        
        for match in re.finditer(pattern, text):
            matches.append((match.group(0), match.start(), match.end()))
            
        return matches
    
    @classmethod
    def find_fill_matches(cls, text: str, field_name: str) -> List[Tuple[str, int, int, str]]:
        """
        æŸ¥æ‰¾å¡«ç©ºæ¨¡å¼åŒ¹é…
        
        Args:
            text: è¦æœç´¢çš„æ–‡æœ¬
            field_name: è¦åŒ¹é…çš„å­—æ®µå
            
        Returns:
            åŒ¹é…ç»“æœåˆ—è¡¨ [(åŒ¹é…æ–‡æœ¬, å¼€å§‹ä½ç½®, ç»“æŸä½ç½®, æ¨¡å¼ç±»å‹)]
        """
        matches = []
        
        for pattern_name, pattern in cls.FILL_PATTERNS.items():
            # ä¸ºç‰¹å®šå­—æ®µåè‡ªå®šä¹‰æ¨¡å¼
            field_pattern = pattern.replace(r'([^ï¼š:\s]+)', re.escape(field_name))
            
            for match in re.finditer(field_pattern, text):
                matches.append((match.group(0), match.start(), match.end(), pattern_name))
                
        return matches

# =====================================
# 3. æ ¼å¼ä¿æŒç®—æ³• (Format Preservation)
# =====================================

class FormatPreserver:
    """æ–‡æœ¬æ ¼å¼ä¿æŒç®—æ³•é›†åˆ"""
    
    @staticmethod
    def preserve_text_format(original: str, replacement: str, 
                           preserve_case: bool = True,
                           preserve_spacing: bool = True) -> str:
        """
        ä¿æŒåŸæ–‡æœ¬æ ¼å¼çš„æ™ºèƒ½æ›¿æ¢
        
        Args:
            original: åŸå§‹æ–‡æœ¬
            replacement: æ›¿æ¢å†…å®¹  
            preserve_case: æ˜¯å¦ä¿æŒå¤§å°å†™æ ¼å¼
            preserve_spacing: æ˜¯å¦ä¿æŒç©ºæ ¼æ ¼å¼
            
        Returns:
            æ ¼å¼åŒ–åçš„æ›¿æ¢æ–‡æœ¬
        """
        if not original or not replacement:
            return replacement
            
        result = replacement
        
        # ä¿æŒå¤§å°å†™æ ¼å¼
        if preserve_case and original.strip():
            if original.isupper():
                result = result.upper()
            elif original.islower():
                result = result.lower()
            elif original.istitle():
                result = result.title()
        
        # ä¿æŒå‰åç©ºæ ¼æ ¼å¼
        if preserve_spacing:
            leading_spaces = len(original) - len(original.lstrip())
            trailing_spaces = len(original) - len(original.rstrip())
            
            result = ' ' * leading_spaces + result.strip() + ' ' * trailing_spaces
            
        return result
    
    @staticmethod
    def extract_format_info(text: str) -> Dict[str, Any]:
        """
        æå–æ–‡æœ¬æ ¼å¼ä¿¡æ¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ ¼å¼ä¿¡æ¯å­—å…¸
        """
        return {
            'leading_spaces': len(text) - len(text.lstrip()),
            'trailing_spaces': len(text) - len(text.rstrip()),
            'is_upper': text.isupper(),
            'is_lower': text.islower(),
            'is_title': text.istitle(),
            'has_punctuation': bool(re.search(r'[ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', text)),
            'encoding': 'utf-8'
        }
    
    @staticmethod
    def apply_format_info(text: str, format_info: Dict[str, Any]) -> str:
        """
        åº”ç”¨æ ¼å¼ä¿¡æ¯åˆ°æ–‡æœ¬
        
        Args:
            text: è¦æ ¼å¼åŒ–çš„æ–‡æœ¬
            format_info: æ ¼å¼ä¿¡æ¯å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        result = text.strip()
        
        # åº”ç”¨å¤§å°å†™æ ¼å¼
        if format_info.get('is_upper', False):
            result = result.upper()
        elif format_info.get('is_lower', False):
            result = result.lower()
        elif format_info.get('is_title', False):
            result = result.title()
        
        # åº”ç”¨ç©ºæ ¼æ ¼å¼
        leading = ' ' * format_info.get('leading_spaces', 0)
        trailing = ' ' * format_info.get('trailing_spaces', 0)
        
        return leading + result + trailing

# =====================================
# 4. å ä½ç¬¦å¤„ç†å·¥å…· (Placeholder Tools)
# =====================================

class PlaceholderProcessor:
    """å ä½ç¬¦æ£€æµ‹å’Œå¤„ç†å·¥å…·"""
    
    # å ä½ç¬¦æ¨¡å¼
    PLACEHOLDER_PATTERNS = {
        'underscore': r'_{2,}',                    # ä¸‹åˆ’çº¿å ä½ç¬¦
        'space': r'\s{3,}',                       # ç©ºæ ¼å ä½ç¬¦
        'mixed': r'[_\s]{3,}',                    # æ··åˆå ä½ç¬¦
        'bracket': r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]',           # æ‹¬å·å ä½ç¬¦
        'punctuation': r'[ã€‚ï¼Œï¼šï¼›]{2,}'           # æ ‡ç‚¹ç¬¦å·å ä½ç¬¦
    }
    
    @classmethod
    def detect_placeholders(cls, text: str) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹æ–‡æœ¬ä¸­çš„å ä½ç¬¦
        
        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬
            
        Returns:
            å ä½ç¬¦ä¿¡æ¯åˆ—è¡¨
        """
        placeholders = []
        
        for placeholder_type, pattern in cls.PLACEHOLDER_PATTERNS.items():
            for match in re.finditer(pattern, text):
                placeholders.append({
                    'type': placeholder_type,
                    'text': match.group(0),
                    'start': match.start(),
                    'end': match.end(),
                    'length': len(match.group(0))
                })
        
        # æŒ‰ä½ç½®æ’åº        
        return sorted(placeholders, key=lambda x: x['start'])
    
    @classmethod
    def clean_placeholders(cls, text: str, replacement_map: Dict[str, str] = None) -> str:
        """
        æ¸…ç†æ–‡æœ¬ä¸­çš„å ä½ç¬¦
        
        Args:
            text: è¦æ¸…ç†çš„æ–‡æœ¬
            replacement_map: æ›¿æ¢æ˜ å°„ï¼Œå¦‚ {'___': 'å†…å®¹', '   ': ' '}
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        result = text
        default_replacements = {
            '___': '',
            '    ': '  ',  # å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºä¸¤ä¸ªç©ºæ ¼
            'ã€‚ã€‚': 'ã€‚',   # é‡å¤æ ‡ç‚¹ç¬¦å·
            'ï¼Œï¼Œ': 'ï¼Œ'
        }
        
        replacements = replacement_map or default_replacements
        
        for old, new in replacements.items():
            result = result.replace(old, new)
            
        return result

# =====================================
# 5. æ–‡æœ¬å¤„ç†å·¥å…·é›† (Text Utils)  
# =====================================

class TextUtils:
    """é€šç”¨æ–‡æœ¬å¤„ç†å·¥å…·é›†åˆ"""
    
    @staticmethod
    def normalize_whitespace(text: str, preserve_newlines: bool = True) -> str:
        """
        æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            preserve_newlines: æ˜¯å¦ä¿æŒæ¢è¡Œç¬¦
            
        Returns:
            æ ‡å‡†åŒ–åçš„æ–‡æœ¬
        """
        if preserve_newlines:
            # ä¿æŒæ¢è¡Œï¼Œä½†è§„èŒƒåŒ–å…¶ä»–ç©ºç™½å­—ç¬¦
            lines = text.split('\n')
            normalized_lines = []
            for line in lines:
                # å°†å¤šä¸ªè¿ç»­ç©ºæ ¼/åˆ¶è¡¨ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
                normalized = re.sub(r'[ \t]+', ' ', line.strip())
                normalized_lines.append(normalized)
            return '\n'.join(normalized_lines)
        else:
            # å…¨éƒ¨ç©ºç™½å­—ç¬¦æ ‡å‡†åŒ–ä¸ºå•ä¸ªç©ºæ ¼
            return re.sub(r'\s+', ' ', text.strip())
    
    @staticmethod
    def extract_field_value(pattern: str, text: str, group: int = 1) -> Optional[str]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å­—æ®µå€¼
        
        Args:
            pattern: æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            text: è¦æœç´¢çš„æ–‡æœ¬
            group: è¦æå–çš„ç»„å·
            
        Returns:
            æå–çš„å€¼æˆ–None
        """
        match = re.search(pattern, text)
        if match and len(match.groups()) >= group:
            return match.group(group).strip()
        return None
    
    @staticmethod
    def safe_replace(text: str, old: str, new: str, count: int = -1) -> Tuple[str, int]:
        """
        å®‰å…¨çš„æ–‡æœ¬æ›¿æ¢ï¼Œè¿”å›æ›¿æ¢æ¬¡æ•°
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            old: è¦æ›¿æ¢çš„æ–‡æœ¬
            new: æ–°æ–‡æœ¬
            count: æœ€å¤§æ›¿æ¢æ¬¡æ•°ï¼Œ-1è¡¨ç¤ºå…¨éƒ¨æ›¿æ¢
            
        Returns:
            (æ›¿æ¢åçš„æ–‡æœ¬, å®é™…æ›¿æ¢æ¬¡æ•°)
        """
        if count == -1:
            replaced_count = text.count(old)
            result = text.replace(old, new)
        else:
            replaced_count = 0
            result = text
            for _ in range(count):
                if old in result:
                    result = result.replace(old, new, 1)
                    replaced_count += 1
                else:
                    break
        
        return result, replaced_count
    
    @staticmethod
    def find_context_around(text: str, target: str, context_length: int = 50) -> Dict[str, str]:
        """
        æŸ¥æ‰¾ç›®æ ‡å­—ç¬¦ä¸²å‘¨å›´çš„ä¸Šä¸‹æ–‡
        
        Args:
            text: è¦æœç´¢çš„æ–‡æœ¬
            target: ç›®æ ‡å­—ç¬¦ä¸²  
            context_length: ä¸Šä¸‹æ–‡é•¿åº¦
            
        Returns:
            ä¸Šä¸‹æ–‡ä¿¡æ¯å­—å…¸
        """
        index = text.find(target)
        if index == -1:
            return {'before': '', 'target': target, 'after': '', 'found': False}
            
        start = max(0, index - context_length)
        end = min(len(text), index + len(target) + context_length)
        
        return {
            'before': text[start:index],
            'target': target,
            'after': text[index + len(target):end],
            'found': True,
            'position': index
        }

# =====================================
# 6. ç»Ÿä¸€é…ç½®å’Œå¸¸é‡
# =====================================

class BusinessResponseConstants:
    """å•†åŠ¡åº”ç­”æ¨¡å—å¸¸é‡å®šä¹‰"""
    
    # æ—¥å¿—é…ç½®
    LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # æ–‡æ¡£å¤„ç†å¸¸é‡
    MAX_FIELD_LENGTH = 1000
    DEFAULT_ENCODING = 'utf-8'
    
    # æ€§èƒ½ä¼˜åŒ–å¸¸é‡
    BATCH_SIZE = 100
    CACHE_SIZE = 500

# åˆå§‹åŒ–æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format=BusinessResponseConstants.LOG_FORMAT
    )

# æ¨¡å—åˆå§‹åŒ–æ—¶è®¾ç½®æ—¥å¿—
setup_logging()

# =====================================
# 6. Wordæ–‡æ¡£å¤„ç†å·¥å…·é›† (Word Document Utils)
# =====================================

class WordDocumentUtils:
    """Wordæ–‡æ¡£å¤„ç†çš„ä¸“ç”¨å·¥å…·é›†åˆ"""
    
    @staticmethod
    def build_paragraph_text_map(paragraph):
        """
        æ„å»ºæ®µè½çš„æ–‡æœ¬åˆ°Runæ˜ å°„
        
        Args:
            paragraph: Wordæ®µè½å¯¹è±¡
            
        Returns:
            tuple: (æ–‡æœ¬å†…å®¹, Runåˆ—è¡¨, å­—ç¬¦åˆ°Runçš„æ˜ å°„åˆ—è¡¨)
        """
        full_text = ""
        runs = []
        char_to_run_map = []

        for run_idx, run in enumerate(paragraph.runs):
            run_text = run.text
            runs.append(run)

            # è®°å½•æ¯ä¸ªå­—ç¬¦å±äºå“ªä¸ªrun
            for _ in range(len(run_text)):
                char_to_run_map.append(run_idx)

            full_text += run_text

        return full_text, runs, char_to_run_map
    
    @staticmethod
    def apply_replacement_to_runs(runs, char_to_run_map, match, replacement_text, logger=None, clean_format=True):
        """
        å°†æ›¿æ¢åº”ç”¨åˆ°æ¶‰åŠçš„Runä¸­ï¼Œä¿æŒæ ¼å¼

        Args:
            runs: Runå¯¹è±¡åˆ—è¡¨
            char_to_run_map: å­—ç¬¦åˆ°Runçš„æ˜ å°„
            match: åŒ¹é…å­—å…¸ï¼ŒåŒ…å«startã€endã€text
            replacement_text: æ›¿æ¢æ–‡æœ¬
            logger: æ—¥å¿—å¯¹è±¡
            clean_format: æ˜¯å¦æ¸…ç†æ ¼å¼ï¼ˆç§»é™¤ä¸‹åˆ’çº¿/åˆ é™¤çº¿/é«˜äº®/èƒŒæ™¯è‰²ï¼‰ï¼Œé»˜è®¤True

        Returns:
            bool: æ˜¯å¦æ›¿æ¢æˆåŠŸ
        """
        start_pos = match['start']
        end_pos = match['end']

        # æ‰¾å‡ºæ¶‰åŠçš„RunèŒƒå›´
        if start_pos >= len(char_to_run_map) or end_pos > len(char_to_run_map):
            if logger:
                logger.warning(f"è­¦å‘Šï¼šåŒ¹é…ä½ç½®è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡ {match['text']}")
            return False

        start_run_idx = char_to_run_map[start_pos]
        end_run_idx = char_to_run_map[end_pos - 1] if end_pos > 0 else start_run_idx

        if logger:
            logger.debug(f"åŒ¹é…èŒƒå›´ï¼šRun {start_run_idx} åˆ° Run {end_run_idx}")

        # æ„å»ºæ¯ä¸ªRunçš„å­—ç¬¦åç§»æ˜ å°„
        run_char_offsets = {}
        current_offset = 0
        for i, run in enumerate(runs):
            run_char_offsets[i] = current_offset
            current_offset += len(run.text)

        # è®¡ç®—éœ€è¦ä¿®æ”¹çš„RunåŠå…¶æ–°å†…å®¹
        for run_idx in range(start_run_idx, end_run_idx + 1):
            if run_idx >= len(runs):
                continue

            run = runs[run_idx]
            run_start_in_full = run_char_offsets[run_idx]

            # è®¡ç®—è¿™ä¸ªRunä¸­éœ€è¦æ›¿æ¢çš„éƒ¨åˆ†
            replace_start_in_run = max(0, start_pos - run_start_in_full)
            replace_end_in_run = min(len(run.text), end_pos - run_start_in_full)

            old_run_text = run.text

            if run_idx == start_run_idx and run_idx == end_run_idx:
                # æ›¿æ¢å®Œå…¨åœ¨ä¸€ä¸ªRunå†…
                new_run_text = (old_run_text[:replace_start_in_run] +
                              replacement_text +
                              old_run_text[replace_end_in_run:])
            elif run_idx == start_run_idx:
                # å¼€å§‹Runï¼šä¿ç•™å‰ç¼€ï¼ŒåŠ ä¸Šæ›¿æ¢æ–‡æœ¬
                new_run_text = old_run_text[:replace_start_in_run] + replacement_text
            elif run_idx == end_run_idx:
                # ç»“æŸRunï¼šåªä¿ç•™åç¼€
                new_run_text = old_run_text[replace_end_in_run:]
            else:
                # ä¸­é—´Runï¼šå®Œå…¨æ¸…ç©º
                new_run_text = ""

            run.text = new_run_text

            # ğŸ†• æ ¼å¼æ¸…ç†ï¼šç§»é™¤å ä½ç¬¦æ ¼å¼ï¼Œä¿ç•™åŸºæœ¬æ ·å¼
            if clean_format and new_run_text:  # åªæ¸…ç†æœ‰å†…å®¹çš„Run
                try:
                    # ç§»é™¤ä¸‹åˆ’çº¿ã€åˆ é™¤çº¿ã€é«˜äº®ã€èƒŒæ™¯è‰²
                    run.font.underline = None
                    run.font.strike = None
                    if hasattr(run.font, 'highlight_color'):
                        run.font.highlight_color = None
                    # ä¿ç•™ï¼šå­—ä½“åç§°ã€å¤§å°ã€ç²—ä½“ã€æ–œä½“ã€é¢œè‰²
                    if logger:
                        logger.debug(f"  æ¸…ç†Run {run_idx}æ ¼å¼ï¼šç§»é™¤ä¸‹åˆ’çº¿/åˆ é™¤çº¿/é«˜äº®")
                except Exception as e:
                    if logger:
                        logger.debug(f"  æ¸…ç†Run {run_idx}æ ¼å¼æ—¶å‡ºç°å¼‚å¸¸ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")

            if logger:
                logger.debug(f"Run {run_idx}: '{old_run_text}' -> '{new_run_text}'")

        return True
    
    @staticmethod
    def find_cross_run_matches(full_text: str, pattern: str):
        """
        åœ¨è·¨Runæ–‡æœ¬ä¸­æŸ¥æ‰¾æ¨¡å¼åŒ¹é…
        
        Args:
            full_text: å®Œæ•´çš„æ®µè½æ–‡æœ¬
            pattern: æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            
        Returns:
            list: åŒ¹é…ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«startã€endã€text
        """
        matches = []
        for match in re.finditer(pattern, full_text):
            matches.append({
                'start': match.start(),
                'end': match.end(),
                'text': match.group(),
                'groups': match.groups() if match.groups() else ()
            })
        return matches
    
    @staticmethod
    def copy_font_format(source_run, target_run):
        """
        å¤åˆ¶å­—ä½“æ ¼å¼ä»æºRunåˆ°ç›®æ ‡Run
        
        Args:
            source_run: æºRunå¯¹è±¡
            target_run: ç›®æ ‡Runå¯¹è±¡
        """
        try:
            # åŸºæœ¬å­—ä½“å±æ€§
            if source_run.font.name:
                target_run.font.name = source_run.font.name
            if source_run.font.size:
                target_run.font.size = source_run.font.size
                
            # å­—ä½“æ ·å¼
            target_run.font.bold = source_run.font.bold
            target_run.font.italic = source_run.font.italic
            target_run.font.underline = source_run.font.underline
            
            # å­—ä½“é¢œè‰²
            if source_run.font.color:
                target_run.font.color.rgb = source_run.font.color.rgb
                
        except Exception as e:
            logger.debug(f"å­—ä½“æ ¼å¼å¤åˆ¶æ—¶å‡ºç°å¼‚å¸¸: {e}")
    
    @staticmethod
    def analyze_paragraph_format(paragraph, pattern: str):
        """
        åˆ†ææ®µè½ä¸­ç›®æ ‡æ¨¡å¼çš„æ ¼å¼ä¿¡æ¯
        
        Args:
            paragraph: Wordæ®µè½å¯¹è±¡
            pattern: è¦åˆ†æçš„æ¨¡å¼
            
        Returns:
            dict: æ ¼å¼åˆ†æç»“æœ
        """
        full_text, runs, char_to_run_map = WordDocumentUtils.build_paragraph_text_map(paragraph)
        matches = WordDocumentUtils.find_cross_run_matches(full_text, pattern)
        
        if not matches:
            return None
            
        match = matches[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…
        start_pos = match['start']
        
        if start_pos < len(char_to_run_map):
            run_idx = char_to_run_map[start_pos]
            if run_idx < len(runs):
                template_run = runs[run_idx]
                return {
                    'font_name': template_run.font.name,
                    'font_size': template_run.font.size,
                    'bold': template_run.font.bold,
                    'italic': template_run.font.italic,
                    'underline': template_run.font.underline,
                    'run_index': run_idx
                }
        
        return None
    
    @staticmethod
    def precise_replace(paragraph, pattern: str, replacement: str, logger=None) -> bool:
        """
        åœ¨æ®µè½ä¸­ç²¾ç¡®æ›¿æ¢æ–‡æœ¬ï¼Œä¿æŒæ ¼å¼
        
        Args:
            paragraph: Wordæ®µè½å¯¹è±¡
            pattern: æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            replacement: æ›¿æ¢æ–‡æœ¬
            logger: æ—¥å¿—å¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦æ›¿æ¢æˆåŠŸ
        """
        try:
            full_text, runs, char_to_run_map = WordDocumentUtils.build_paragraph_text_map(paragraph)
            
            if not full_text:
                return False
                
            matches = WordDocumentUtils.find_cross_run_matches(full_text, pattern)
            
            if not matches:
                return False
            
            # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»é—®é¢˜
            for match in reversed(matches):
                success = WordDocumentUtils.apply_replacement_to_runs(
                    runs, char_to_run_map, match, replacement, logger
                )
                if not success:
                    return False
            
            if logger:
                logger.debug(f"ç²¾ç¡®æ›¿æ¢æˆåŠŸ: '{pattern}' -> '{replacement}'")
            
            return True
            
        except Exception as e:
            if logger:
                logger.error(f"ç²¾ç¡®æ›¿æ¢æ—¶å‡ºç°é”™è¯¯: {e}")
            return False

# =====================================
# 7. æ™ºèƒ½å­—æ®µæ£€æµ‹å™¨ (Smart Field Detector)
# =====================================

class SmartFieldDetector:
    """æ™ºèƒ½å­—æ®µæ£€æµ‹å’Œä¸Šä¸‹æ–‡åˆ†æ"""
    
    # èŒä½ä¸Šä¸‹æ–‡å…³é”®è¯
    POSITION_CONTEXT_KEYWORDS = {
        'authorized_person': ['è¢«æˆæƒäºº', 'æˆæƒä»£è¡¨', 'ä»£è¡¨äºº', 'é¡¹ç›®ç»ç†', 'è´Ÿè´£äºº'],
        'legal_representative': ['æ³•å®šä»£è¡¨äºº', 'æ³•äººä»£è¡¨', 'æ³•äºº', 'è‘£äº‹é•¿', 'æ€»ç»ç†'],
        'general': ['èŒåŠ¡', 'èŒä½', 'å²—ä½', 'èŒç§°']
    }
    
    @classmethod
    def detect_position_context(cls, paragraph_text: str) -> str:
        """
        æ£€æµ‹èŒä½å­—æ®µçš„ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­æ˜¯è¢«æˆæƒäººèŒåŠ¡è¿˜æ˜¯æ³•å®šä»£è¡¨äººèŒä½
        
        Args:
            paragraph_text: æ®µè½æ–‡æœ¬
            
        Returns:
            str: 'authorized_person', 'legal_representative', æˆ– 'general'
        """
        text_lower = paragraph_text.lower()
        
        # æ£€æŸ¥è¢«æˆæƒäººç›¸å…³å…³é”®è¯
        for keyword in cls.POSITION_CONTEXT_KEYWORDS['authorized_person']:
            if keyword in text_lower:
                return 'authorized_person'
        
        # æ£€æŸ¥æ³•å®šä»£è¡¨äººç›¸å…³å…³é”®è¯
        for keyword in cls.POSITION_CONTEXT_KEYWORDS['legal_representative']:
            if keyword in text_lower:
                return 'legal_representative'
                
        return 'general'
    
    @classmethod
    def should_try_field_in_paragraph(cls, paragraph_text: str, field_variants: list) -> bool:
        """
        é¢„æ£€æŸ¥æ®µè½æ˜¯å¦å¯èƒ½åŒ…å«ç›¸å…³å­—æ®µï¼ˆåŸå§‹ç‰ˆæœ¬é€»è¾‘ï¼‰

        Args:
            paragraph_text: æ®µè½æ–‡æœ¬
            field_variants: å­—æ®µå˜ä½“åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦å€¼å¾—å°è¯•å¤„ç†è¿™ä¸ªæ®µè½
        """
        import logging
        logger = logging.getLogger("ai_tender_system.business_response")

        # æ³¨æ„ï¼šä¸è¦strip()ï¼Œå› ä¸ºéœ€è¦ä¿ç•™ç©ºæ ¼æ¥æ£€æµ‹ç©ºæ ¼æ ¼å¼
        text = paragraph_text

        # ç¬¬1æ­¥ï¼šç©ºæ®µè½æ£€æŸ¥
        if not text or not text.strip():
            return False

        # ç¬¬2æ­¥ï¼šå­—æ®µç›¸å…³æ€§æ£€æŸ¥ - å¿…é¡»åŒ…å«å­—æ®µå˜ä½“
        contains_field = any(variant in text for variant in field_variants)
        if not contains_field:
            return False

        # ç¬¬3æ­¥ï¼šæ ¼å¼æ ‡è¯†ç¬¦æ£€æŸ¥ - æ”¾å®½æ£€æŸ¥æ¡ä»¶ä»¥æ”¯æŒæ›´å¤šæ ¼å¼
        field_indicators = [
            r'[:ï¼š]',           # å†’å·æ ¼å¼ï¼šåœ°å€ï¼šã€ç”µè¯ï¼š
            r'[ï¼ˆ(].*[ï¼‰)]',     # æ‹¬å·æ ¼å¼ï¼šï¼ˆåœ°å€ï¼‰ã€ï¼ˆå…¬ç« ï¼‰
            r'_+',              # ä¸‹åˆ’çº¿æ ¼å¼ï¼š___
            r'\s{3,}',          # å¤šç©ºæ ¼æ ¼å¼ï¼šä¼ çœŸ
            r'è‡´\s*[ï¼š:]',       # è‡´ï¼šæ ¼å¼
            r'[ã€‚ï¼Œ,\.]',        # æ ‡ç‚¹ç¬¦å·æ ¼å¼
            r'\d',              # åŒ…å«æ•°å­—
            r'[å¹´æœˆæ—¥]',         # æ—¥æœŸæ ¼å¼
        ]
        has_format = any(re.search(indicator, text) for indicator in field_indicators)

        # æ”¾å®½æ¡ä»¶ï¼šå¦‚æœæ®µè½è¾ƒçŸ­ä¸”åŒ…å«å­—æ®µåï¼Œä¹Ÿå…è®¸å¤„ç†
        is_short_with_field = len(text.strip()) < 100 and contains_field

        if not has_format and not is_short_with_field:
            logger.debug(f"âŒ [SmartFieldDetector] æ®µè½æ— æ ¼å¼æ ‡è¯†ç¬¦ä¸”éçŸ­æ®µè½: '{text[:50]}...'")
            return False

        # ç®€åŒ–çš„è°ƒè¯•ä¿¡æ¯
        logger.debug(f"âœ… [SmartFieldDetector] æ®µè½é€šè¿‡æ£€æŸ¥: åŒ…å«å­—æ®µå˜ä½“ä¸”æœ‰æ ¼å¼æ ‡è¯†ç¬¦ - '{text[:50]}...'")
        return True

# =====================================
# 8. æ•°æ®å­—æ®µè§„èŒƒåŒ–å·¥å…· (Data Normalization)
# =====================================

def normalize_data_keys(data: Dict[str, Any], logger=None) -> Dict[str, Any]:
    """
    è§„èŒƒåŒ–æ•°æ®å­—æ®µåï¼ˆç»Ÿä¸€å‘½åè§„åˆ™ï¼‰

    æ”¯æŒä¸¤ç§å‘½åé£æ ¼çš„è½¬æ¢ï¼š
    1. é©¼å³°å‘½å (fixedPhone, officeAddress) â†’ æ ‡å‡†å­—æ®µ (phone, address)
    2. ä¸‹åˆ’çº¿å‘½å (fixed_phone, office_address) â†’ æ ‡å‡†å­—æ®µ (phone, address)

    ç”¨é€”ï¼šç¡®ä¿ä»æ•°æ®åº“è¯»å–çš„æ•°æ®èƒ½è¢«smart_fillerå’Œtable_processoræ­£ç¡®è¯†åˆ«

    Args:
        data: åŸå§‹æ•°æ®å­—å…¸
        logger: æ—¥å¿—å¯¹è±¡ï¼ˆå¯é€‰ï¼‰

    Returns:
        è§„èŒƒåŒ–åçš„æ•°æ®å­—å…¸
    """
    normalized = data.copy()

    # å­—æ®µåæ˜ å°„è¡¨ï¼ˆæ—§å â†’ æ–°åï¼‰
    key_mappings = {
        # é©¼å³°å‘½åæ˜ å°„
        'fixedPhone': 'phone',
        'mobilePhone': 'mobile',
        'contactPhone': 'phone',
        'registeredAddress': 'address',
        'officeAddress': 'address',

        # ä¸‹åˆ’çº¿å‘½åæ˜ å°„ï¼ˆæ•°æ®åº“åŸå§‹å­—æ®µåï¼‰
        'fixed_phone': 'phone',
        'mobile_phone': 'mobile',
        'contact_phone': 'phone',
        'postal_code': 'postalCode',
        'registered_address': 'address',
        'office_address': 'address',
        'authorized_person_id': 'authorizedPersonId',  # è¢«æˆæƒäººèº«ä»½è¯å·
    }

    # åº”ç”¨å•é”®æ˜ å°„
    for old_key, new_key in key_mappings.items():
        if old_key in normalized and new_key not in normalized:
            normalized[new_key] = normalized[old_key]
            if logger:
                logger.debug(f"é”®åæ˜ å°„: {old_key} â†’ {new_key}")

    # å¤šæºæ˜ å°„ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    multi_source_mappings = {
        'address': ['address', 'officeAddress', 'registeredAddress',
                    'office_address', 'registered_address'],
        'phone': ['phone', 'fixedPhone', 'mobilePhone',
                  'fixed_phone', 'mobile_phone'],
    }

    for target_key, source_keys in multi_source_mappings.items():
        if target_key not in normalized or not normalized.get(target_key):
            for source_key in source_keys:
                if source_key in normalized and normalized.get(source_key):
                    normalized[target_key] = normalized[source_key]
                    if logger:
                        logger.debug(f"å¤šæºæ˜ å°„: {source_key} â†’ {target_key}")
                    break

    return normalized

# å¯¼å‡ºä¸»è¦ç±»å’Œå‡½æ•°
__all__ = [
    'FieldMapper',
    'PatternMatcher',
    'FormatPreserver',
    'PlaceholderProcessor',
    'TextUtils',
    'WordDocumentUtils',
    'SmartFieldDetector',
    'BusinessResponseConstants',
    'normalize_data_keys'  # æ–°å¢
]