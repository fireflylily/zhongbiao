#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é£é™©åˆ†ææ•°æ®ç»“æ„å®šä¹‰ - æ ‡ä¹¦å® 5.0 å‡çº§ç‰ˆ
æ–°å¢å­—æ®µï¼šoriginal_text, position_index, todo_action, deep_analysis, compliance_status ç­‰
"""

from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional
from datetime import datetime


@dataclass
class RiskItem:
    """
    é£é™©é¡¹æ•°æ®ç±» - 5.0 å‡çº§ç‰ˆ

    æ–°å¢å­—æ®µï¼š
    - original_text: æ‹›æ ‡æ–‡ä»¶åŸæ–‡
    - position_index: ä½ç½®ç´¢å¼•ï¼ˆå¦‚ P12, ç¬¬ä¸‰ç« 2.1ï¼‰
    - todo_action: å…·ä½“ Todo æ“ä½œ
    - deep_analysis: é—®é¢˜æ·±åº¦è§£æ
    - compliance_status: åˆè§„çŠ¶æ€ï¼ˆå¯¹è´¦åå¡«å……ï¼‰
    - compliance_note: åˆè§„å¤‡æ³¨
    - response_text: åº”ç­”æ–‡ä»¶å¯¹åº”å†…å®¹
    """
    # åŸºç¡€å­—æ®µï¼ˆåŸæœ‰ï¼‰
    location: str                   # æ¡æ¬¾ä½ç½®ï¼ˆå¦‚ï¼šç¬¬ä¸‰ç«  2.1èŠ‚ï¼‰
    requirement: str                # å…·ä½“è¦æ±‚å†…å®¹ï¼ˆç²¾ç‚¼æ€»ç»“ï¼‰
    suggestion: str                 # é¿å‘å»ºè®®
    risk_level: str = 'medium'      # high/medium/low
    risk_type: str = ''             # åºŸæ ‡æ¡æ¬¾/â˜…æ¡æ¬¾/èµ„è´¨è¦æ±‚/æŠ€æœ¯å‚æ•°/å•†åŠ¡æ¡æ¬¾/éšæ€§é£é™©
    source_chunk: int = 0           # æ¥æºåˆ†å—ç´¢å¼•
    confidence: float = 0.8         # ç½®ä¿¡åº¦

    # 5.0 æ–°å¢å­—æ®µ
    original_text: str = ''         # æ‹›æ ‡æ–‡ä»¶åŸæ–‡æ‘˜å½•
    position_index: str = ''        # ä½ç½®ç´¢å¼•ï¼ˆP12, ç¬¬ä¸‰ç« 2.1ï¼‰
    todo_action: str = ''           # å…·ä½“ Todo æ“ä½œ
    deep_analysis: str = ''         # é—®é¢˜æ·±åº¦è§£æ

    # åŒå‘å¯¹è´¦å­—æ®µ
    compliance_status: str = ''     # compliant/non_compliant/partial/unknown
    compliance_note: str = ''       # åˆè§„å¤‡æ³¨
    response_text: str = ''         # åº”ç­”æ–‡ä»¶å¯¹åº”å†…å®¹
    match_score: float = 0.0        # åŒ¹é…åº¦ 0-1

    def to_dict(self) -> Dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict) -> 'RiskItem':
        return cls(
            location=data.get('location', ''),
            requirement=data.get('requirement', ''),
            suggestion=data.get('suggestion', ''),
            risk_level=data.get('risk_level', 'medium'),
            risk_type=data.get('risk_type', ''),
            source_chunk=data.get('source_chunk', 0),
            confidence=data.get('confidence', 0.8),
            # 5.0 æ–°å¢å­—æ®µ
            original_text=data.get('original_text', ''),
            position_index=data.get('position_index', ''),
            todo_action=data.get('todo_action', ''),
            deep_analysis=data.get('deep_analysis', ''),
            # åŒå‘å¯¹è´¦å­—æ®µ
            compliance_status=data.get('compliance_status', ''),
            compliance_note=data.get('compliance_note', ''),
            response_text=data.get('response_text', ''),
            match_score=data.get('match_score', 0.0)
        )

    def get_risk_level_emoji(self) -> str:
        """è·å–é£é™©ç­‰çº§ emoji"""
        emoji_map = {
            'high': 'ğŸ”´',
            'medium': 'ğŸŸ¡',
            'low': 'ğŸ”µ'
        }
        return emoji_map.get(self.risk_level, 'ğŸŸ¡')

    def get_compliance_emoji(self) -> str:
        """è·å–åˆè§„çŠ¶æ€ emoji"""
        emoji_map = {
            'compliant': 'ğŸŸ¢',
            'non_compliant': 'ğŸ”´',
            'partial': 'ğŸŸ¡',
            'unknown': 'âšª'
        }
        return emoji_map.get(self.compliance_status, 'âšª')


@dataclass
class ReconcileResult:
    """
    åŒå‘å¯¹è´¦ç»“æœ - 5.0 æ–°å¢
    """
    risk_item_id: int = 0           # å…³è”çš„é£é™©é¡¹ç´¢å¼•
    bid_requirement: str = ''       # æ‹›æ ‡è¦æ±‚
    response_content: str = ''      # åº”ç­”å†…å®¹
    compliance_status: str = ''     # compliant/non_compliant/partial
    match_score: float = 0.0        # åŒ¹é…åº¦ 0-1
    issues: List[Dict] = field(default_factory=list)  # é—®é¢˜åˆ—è¡¨
    overall_assessment: str = ''    # æ€»ä½“è¯„ä¼°
    fix_suggestion: str = ''        # ä¿®å¤å»ºè®®
    fix_priority: str = 'normal'    # urgent/normal/optional

    def to_dict(self) -> Dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict) -> 'ReconcileResult':
        return cls(
            risk_item_id=data.get('risk_item_id', 0),
            bid_requirement=data.get('bid_requirement', ''),
            response_content=data.get('response_content', ''),
            compliance_status=data.get('compliance_status', ''),
            match_score=data.get('match_score', 0.0),
            issues=data.get('issues', []),
            overall_assessment=data.get('overall_assessment', ''),
            fix_suggestion=data.get('fix_suggestion', ''),
            fix_priority=data.get('fix_priority', 'normal')
        )


@dataclass
class RiskAnalysisResult:
    """åˆ†æç»“æœæ•°æ®ç±» - 5.0 å‡çº§ç‰ˆ"""
    risk_items: List[RiskItem] = field(default_factory=list)
    summary: str = ''
    risk_score: int = 0             # 0-100ï¼Œè¶Šé«˜é£é™©è¶Šå¤§
    total_chunks: int = 0
    analyzed_chunks: int = 0
    model_name: str = 'deepseek-v3'
    total_tokens: int = 0
    analysis_time: float = 0.0      # åˆ†æè€—æ—¶ï¼ˆç§’ï¼‰

    # 5.0 æ–°å¢
    has_toc: bool = False           # æ˜¯å¦æœ‰ç›®å½•
    exclude_chapters: List[str] = field(default_factory=list)  # æ’é™¤çš„ç« èŠ‚
    reconcile_results: List[ReconcileResult] = field(default_factory=list)  # å¯¹è´¦ç»“æœ

    def to_dict(self) -> Dict:
        return {
            'risk_items': [item.to_dict() for item in self.risk_items],
            'summary': self.summary,
            'risk_score': self.risk_score,
            'total_chunks': self.total_chunks,
            'analyzed_chunks': self.analyzed_chunks,
            'model_name': self.model_name,
            'total_tokens': self.total_tokens,
            'analysis_time': self.analysis_time,
            'statistics': self.get_statistics(),
            # 5.0 æ–°å¢
            'has_toc': self.has_toc,
            'exclude_chapters': self.exclude_chapters,
            'reconcile_results': [r.to_dict() for r in self.reconcile_results],
            'reconcile_summary': self.get_reconcile_summary()
        }

    def get_statistics(self) -> Dict:
        """è·å–é£é™©ç»Ÿè®¡"""
        high_count = sum(1 for item in self.risk_items if item.risk_level == 'high')
        medium_count = sum(1 for item in self.risk_items if item.risk_level == 'medium')
        low_count = sum(1 for item in self.risk_items if item.risk_level == 'low')

        return {
            'total_items': len(self.risk_items),
            'high_risk_count': high_count,
            'medium_risk_count': medium_count,
            'low_risk_count': low_count
        }

    def get_reconcile_summary(self) -> Dict:
        """è·å–å¯¹è´¦æ±‡æ€»"""
        if not self.reconcile_results:
            return {}

        compliant = sum(1 for r in self.reconcile_results if r.compliance_status == 'compliant')
        non_compliant = sum(1 for r in self.reconcile_results if r.compliance_status == 'non_compliant')
        partial = sum(1 for r in self.reconcile_results if r.compliance_status == 'partial')

        return {
            'total_checked': len(self.reconcile_results),
            'compliant': compliant,
            'non_compliant': non_compliant,
            'partial': partial,
            'compliance_rate': compliant / len(self.reconcile_results) if self.reconcile_results else 0
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'RiskAnalysisResult':
        risk_items = [RiskItem.from_dict(item) for item in data.get('risk_items', [])]
        reconcile_results = [ReconcileResult.from_dict(r) for r in data.get('reconcile_results', [])]
        return cls(
            risk_items=risk_items,
            summary=data.get('summary', ''),
            risk_score=data.get('risk_score', 0),
            total_chunks=data.get('total_chunks', 0),
            analyzed_chunks=data.get('analyzed_chunks', 0),
            model_name=data.get('model_name', 'deepseek-v3'),
            total_tokens=data.get('total_tokens', 0),
            analysis_time=data.get('analysis_time', 0.0),
            has_toc=data.get('has_toc', False),
            exclude_chapters=data.get('exclude_chapters', []),
            reconcile_results=reconcile_results
        )


@dataclass
class RiskTask:
    """é£é™©åˆ†æä»»åŠ¡ - 5.0 å‡çº§ç‰ˆ"""
    task_id: str
    openid: str = ''
    user_id: Optional[int] = None
    file_id: str = ''
    original_filename: str = ''
    file_size: int = 0

    # ä»»åŠ¡çŠ¶æ€
    status: str = 'pending'         # pending/parsing/analyzing/reconciling/completed/failed
    progress: int = 0               # 0-100
    current_step: str = ''
    error_message: str = ''

    # è§£æä¿¡æ¯
    total_text_length: int = 0
    chunk_count: int = 0

    # åˆ†æç»“æœ
    result: Optional[RiskAnalysisResult] = None

    # æ—¶é—´æˆ³
    created_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    # AI æ¨¡å‹ä¿¡æ¯
    model_name: str = 'deepseek-v3'

    # 5.0 æ–°å¢å­—æ®µ
    file_path: str = ''             # æ‹›æ ‡æ–‡ä»¶è·¯å¾„
    response_file_path: str = ''    # åº”ç­”æ–‡ä»¶è·¯å¾„
    response_file_name: str = ''    # åº”ç­”æ–‡ä»¶å
    has_toc: bool = False           # æ˜¯å¦æœ‰ç›®å½•
    analysis_mode: str = 'bid_only' # bid_only / bid_response_reconcile

    def to_dict(self) -> Dict:
        return {
            'task_id': self.task_id,
            'openid': self.openid,
            'user_id': self.user_id,
            'file_id': self.file_id,
            'original_filename': self.original_filename,
            'file_size': self.file_size,
            'status': self.status,
            'progress': self.progress,
            'current_step': self.current_step,
            'error_message': self.error_message,
            'total_text_length': self.total_text_length,
            'chunk_count': self.chunk_count,
            'result': self.result.to_dict() if self.result else None,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'started_at': self.started_at.isoformat() if self.started_at else None,
            'completed_at': self.completed_at.isoformat() if self.completed_at else None,
            'model_name': self.model_name,
            # 5.0 æ–°å¢
            'file_path': self.file_path,
            'response_file_path': self.response_file_path,
            'response_file_name': self.response_file_name,
            'has_toc': self.has_toc,
            'analysis_mode': self.analysis_mode
        }


@dataclass
class TodoItem:
    """Todo æ“ä½œé¡¹ - 5.0 æ–°å¢"""
    risk_item_index: int = 0        # å…³è”çš„é£é™©é¡¹ç´¢å¼•
    action: str = ''                # åŠ¨ä½œæè¿°
    assignee_type: str = ''         # å•†åŠ¡/æŠ€æœ¯/æ³•åŠ¡/è´¢åŠ¡/é¡¹ç›®ç»ç†
    priority: str = 'P1'            # P0/P1/P2
    checklist: List[str] = field(default_factory=list)  # å­æ­¥éª¤
    deadline_hint: str = ''         # æ—¶é—´èŠ‚ç‚¹æç¤º
    warning: str = ''               # ç‰¹åˆ«æ³¨æ„äº‹é¡¹

    def to_dict(self) -> Dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict) -> 'TodoItem':
        return cls(
            risk_item_index=data.get('risk_item_index', 0),
            action=data.get('action', ''),
            assignee_type=data.get('assignee_type', ''),
            priority=data.get('priority', 'P1'),
            checklist=data.get('checklist', []),
            deadline_hint=data.get('deadline_hint', ''),
            warning=data.get('warning', '')
        )

    def get_priority_emoji(self) -> str:
        """è·å–ä¼˜å…ˆçº§ emoji"""
        emoji_map = {
            'P0': 'ğŸ”´',
            'P1': 'ğŸŸ¡',
            'P2': 'ğŸ”µ'
        }
        return emoji_map.get(self.priority, 'ğŸŸ¡')
