#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ€æœ¯æ–¹æ¡ˆå¤§çº²ç”ŸæˆAPI
æä¾›æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆçš„Webæ¥å£
"""

import os
import json
import traceback
from datetime import datetime
from pathlib import Path
from flask import Blueprint, request, jsonify, send_file, Response, stream_with_context
from werkzeug.utils import secure_filename

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
import sys
sys.path.append(str(Path(__file__).parent.parent))
from common import get_module_logger, get_config, get_prompt_manager
from modules.outline_generator import (
    RequirementAnalyzer,
    OutlineGenerator,
    ProductMatcher,
    ProposalAssembler,
    WordExporter
)

# åˆ›å»ºè“å›¾
api_outline_bp = Blueprint('api_outline', __name__, url_prefix='/api')

# å…¨å±€å˜é‡
logger = get_module_logger("api_outline_generator")
config = get_config()

# å…è®¸çš„æ–‡ä»¶æ‰©å±•å
ALLOWED_EXTENSIONS = {'doc', 'docx', 'pdf', 'xlsx', 'xls'}


def allowed_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def get_hitl_technical_file_path(project_id: str) -> Path:
    """
    ä»æ•°æ®åº“æŸ¥è¯¢HITLé¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„

    Args:
        project_id: é¡¹ç›®ID

    Returns:
        æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    if not project_id or project_id == 'default':
        return None

    try:
        from ai_tender_system.common.database import get_knowledge_base_db
        db = get_knowledge_base_db()

        # æŸ¥è¯¢é¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„
        db_row = db.execute_query(
            "SELECT step1_data, technical_requirement_path FROM tender_projects WHERE project_id = ?",
            (project_id,),
            fetch_one=True
        )

        if db_row:
            tender_path = None
            # ä¼˜å…ˆä½¿ç”¨ technical_requirement_path
            if db_row[1] if isinstance(db_row, (list, tuple)) else db_row.get('technical_requirement_path'):
                path_value = db_row[1] if isinstance(db_row, (list, tuple)) else db_row.get('technical_requirement_path')
                tender_path = Path(path_value)
                logger.info(f"ä» technical_requirement_path è·å–æ–‡ä»¶è·¯å¾„: {tender_path}")
            # å¤‡é€‰ï¼šä» step1_data ä¸­è·å–
            else:
                step1_data_str = db_row[0] if isinstance(db_row, (list, tuple)) else db_row.get('step1_data')
                if step1_data_str:
                    try:
                        step1_data_json = json.loads(step1_data_str)
                        if step1_data_json.get('technical_file_path'):
                            tender_path = Path(step1_data_json['technical_file_path'])
                            logger.info(f"ä» step1_data.technical_file_path è·å–æ–‡ä»¶è·¯å¾„: {tender_path}")
                    except Exception as e:
                        logger.warning(f"è§£æ step1_data å¤±è´¥: {e}")

            if tender_path and tender_path.exists():
                logger.info(f"æ‰¾åˆ°HITLæŠ€æœ¯éœ€æ±‚æ–‡ä»¶: {tender_path}")
                return tender_path
            else:
                logger.warning(f"æŠ€æœ¯éœ€æ±‚æ–‡ä»¶ä¸å­˜åœ¨: {tender_path}")
        else:
            logger.warning(f"æœªæ‰¾åˆ°é¡¹ç›®è®°å½•: project_id={project_id}")
    except Exception as e:
        logger.warning(f"ä»æ•°æ®åº“æŸ¥è¯¢æŠ€æœ¯éœ€æ±‚æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)

    return None


def get_tech_proposal_output_dir(project_id=None) -> Path:
    """
    è·å–æŠ€æœ¯æ–¹æ¡ˆè¾“å‡ºç›®å½•

    å¦‚æœæœ‰ project_idï¼Œä¿å­˜åˆ° tech_proposal_files/{å¹´}/{æœˆ}/{é¡¹ç›®ID}/
    å¦åˆ™ä¿å­˜åˆ°é»˜è®¤çš„ outputs/ ç›®å½•

    Args:
        project_id: é¡¹ç›®IDï¼ˆå¯é€‰ï¼‰

    Returns:
        è¾“å‡ºç›®å½•è·¯å¾„
    """
    if project_id and project_id != 'default':
        now = datetime.now()
        output_dir = config.get_path('upload') / 'tech_proposal_files' / str(now.year) / str(now.month).zfill(2) / str(project_id)
    else:
        output_dir = config.get_path('output')

    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir


@api_outline_bp.route('/generate-proposal', methods=['POST'])
def generate_proposal():
    """
    ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆAPI

    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-dataï¼‰:
    - tender_file: æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶
    - product_file: äº§å“æ–‡æ¡£æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    - company_id: å…¬å¸IDï¼ˆå¯é€‰ï¼‰
    - output_prefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼Œé»˜è®¤"æŠ€æœ¯æ–¹æ¡ˆ"ï¼‰
    - include_analysis: æ˜¯å¦åŒ…å«éœ€æ±‚åˆ†ææŠ¥å‘Šï¼ˆå¯é€‰ï¼Œé»˜è®¤falseï¼‰
    - include_mapping: æ˜¯å¦ç”Ÿæˆéœ€æ±‚åŒ¹é…è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤falseï¼‰
    - include_summary: æ˜¯å¦ç”Ÿæˆç”ŸæˆæŠ¥å‘Šï¼ˆå¯é€‰ï¼Œé»˜è®¤falseï¼‰

    è¿”å›:
    {
        "success": true,
        "requirements_count": 50,
        "sections_count": 5,
        "matches_count": 45,
        "output_files": {
            "proposal": "/downloads/xxx.docx",
            "analysis": "/downloads/xxx.docx",
            "mapping": "/downloads/xxx.xlsx",
            "summary": "/downloads/xxx.txt"
        }
    }
    """
    try:
        logger.info("æ”¶åˆ°æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆè¯·æ±‚")

        # 1. éªŒè¯è¯·æ±‚ - æ”¯æŒä¸¤ç§æ–‡ä»¶æ¥æºï¼šç›´æ¥ä¸Šä¼ æˆ–ä»HITLä¼ é€’
        use_hitl_file = request.form.get('use_hitl_technical_file', 'false').lower() == 'true'
        project_id = request.form.get('hitl_task_id') or request.form.get('project_id')

        if use_hitl_file and project_id:
            # ä½¿ç”¨HITLä¼ é€’çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶ - ä»æ•°æ®åº“æŸ¥è¯¢è·¯å¾„
            logger.info(f"ä½¿ç”¨HITLé¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}")
            tender_path = get_hitl_technical_file_path(project_id)

            if not tender_path:
                return jsonify({
                    'success': False,
                    'error': f'æœªæ‰¾åˆ°é¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}'
                }), 400
        else:
            # ä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶
            if 'tender_file' not in request.files:
                return jsonify({
                    'success': False,
                    'error': 'ç¼ºå°‘æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶'
                }), 400

            tender_file = request.files['tender_file']

            if tender_file.filename == '':
                return jsonify({
                    'success': False,
                    'error': 'æœªé€‰æ‹©æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶'
                }), 400

            if not allowed_file(tender_file.filename):
                return jsonify({
                    'success': False,
                    'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  .doc, .docx, .pdf, .xlsx æˆ– .xls æ–‡ä»¶'
                }), 400

            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            upload_dir = config.get_path('uploads')
            upload_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            tender_filename = secure_filename(f"{timestamp}_{tender_file.filename}")
            tender_path = upload_dir / tender_filename

            tender_file.save(str(tender_path))
            logger.info(f"éœ€æ±‚æ–‡æ¡£å·²ä¿å­˜: {tender_path}")

        # 2. è·å–å‚æ•°
        company_id = request.form.get('companyId')
        project_name = request.form.get('projectName', '')  # è·å–é¡¹ç›®åç§°
        output_prefix = request.form.get('output_prefix', 'æŠ€æœ¯æ–¹æ¡ˆ')

        options = {
            'include_analysis': request.form.get('includeAnalysis', 'false').lower() == 'true',
            'include_mapping': request.form.get('includeMapping', 'false').lower() == 'true',
            'include_summary': request.form.get('includeSummary', 'false').lower() == 'true'
        }

        logger.info(f"ç”Ÿæˆé€‰é¡¹: {options}")

        # 4. é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æ
        logger.info("å¼€å§‹é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æ...")
        analyzer = RequirementAnalyzer()
        analysis_result = analyzer.analyze_document(str(tender_path))

        logger.info("éœ€æ±‚åˆ†æå®Œæˆ")

        # 5. é˜¶æ®µ2ï¼šå¤§çº²ç”Ÿæˆ
        logger.info("å¼€å§‹é˜¶æ®µ2ï¼šå¤§çº²ç”Ÿæˆ...")
        outline_gen = OutlineGenerator()
        outline_data = outline_gen.generate_outline(
            analysis_result,
            project_name=output_prefix
        )

        logger.info("å¤§çº²ç”Ÿæˆå®Œæˆ")

        # 6. é˜¶æ®µ3ï¼šäº§å“æ–‡æ¡£åŒ¹é…
        logger.info("å¼€å§‹é˜¶æ®µ3ï¼šäº§å“æ–‡æ¡£åŒ¹é…...")
        matcher = ProductMatcher()
        matched_docs = matcher.match_documents(
            analysis_result.get('requirement_categories', []),
            company_id=int(company_id) if company_id else None
        )

        logger.info(f"äº§å“æ–‡æ¡£åŒ¹é…å®Œæˆï¼Œå…±åŒ¹é… {sum(len(v) for v in matched_docs.values())} ä»½æ–‡æ¡£")

        # 7. é˜¶æ®µ4ï¼šæ–¹æ¡ˆç»„è£…
        logger.info("å¼€å§‹é˜¶æ®µ4ï¼šæ–¹æ¡ˆç»„è£…...")
        assembler = ProposalAssembler()
        proposal = assembler.assemble_proposal(
            outline_data,
            analysis_result,
            matched_docs,
            options
        )

        logger.info("æ–¹æ¡ˆç»„è£…å®Œæˆ")

        # 8. å¯¼å‡ºæ–‡ä»¶
        logger.info("å¼€å§‹å¯¼å‡ºæ–‡ä»¶...")
        exporter = WordExporter()

        output_dir = config.get_path('output')
        output_dir.mkdir(parents=True, exist_ok=True)

        output_files = {}

        # æ™ºèƒ½æ–‡ä»¶å‘½åï¼šæœ‰é¡¹ç›®åç§°æ—¶ä½¿ç”¨"é¡¹ç›®å_ç±»å‹_æ—¶é—´"ï¼Œæ— é¡¹ç›®åç§°æ—¶ä½¿ç”¨"å‰ç¼€_æ—¶é—´"
        if project_name:
            proposal_filename = f"{project_name}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
            analysis_filename = f"{project_name}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
            mapping_filename = f"{project_name}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
            summary_filename = f"{project_name}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"
        else:
            proposal_filename = f"{output_prefix}_{timestamp}.docx"
            analysis_filename = f"{output_prefix}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
            mapping_filename = f"{output_prefix}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
            summary_filename = f"{output_prefix}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"

        # å¯¼å‡ºä¸»æ–¹æ¡ˆï¼ˆç®€æ´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¤§çº²æŒ‡å¯¼ä¿¡æ¯ï¼‰
        proposal_path = output_dir / proposal_filename
        exporter.export_proposal(proposal, str(proposal_path), show_guidance=False)
        output_files['proposal'] = f"/api/downloads/{proposal_filename}"

        logger.info(f"ä¸»æ–¹æ¡ˆå·²å¯¼å‡º: {proposal_path}")

        # å¯¼å‡ºé™„ä»¶
        if options['include_analysis']:
            analysis_path = output_dir / analysis_filename
            exporter.export_analysis_report(analysis_result, str(analysis_path))
            output_files['analysis'] = f"/api/downloads/{analysis_filename}"

            logger.info(f"éœ€æ±‚åˆ†ææŠ¥å‘Šå·²å¯¼å‡º: {analysis_path}")

        if options['include_mapping']:
            mapping_path = output_dir / mapping_filename

            mapping_data = []
            for attachment in proposal.get('attachments', []):
                if attachment['type'] == 'mapping':
                    mapping_data = attachment['data']
                    break

            exporter.export_mapping_table(mapping_data, str(mapping_path))
            output_files['mapping'] = f"/api/downloads/{mapping_filename}"

            logger.info(f"éœ€æ±‚åŒ¹é…è¡¨å·²å¯¼å‡º: {mapping_path}")

        if options['include_summary']:
            summary_path = output_dir / summary_filename

            summary_data = {}
            for attachment in proposal.get('attachments', []):
                if attachment['type'] == 'summary':
                    summary_data = attachment['data']
                    break

            exporter.export_summary_report(summary_data, str(summary_path))
            output_files['summary'] = f"/api/downloads/{summary_filename}"

            logger.info(f"ç”ŸæˆæŠ¥å‘Šå·²å¯¼å‡º: {summary_path}")

        # 9. ç»Ÿè®¡ä¿¡æ¯
        requirements_count = analysis_result.get('document_summary', {}).get('total_requirements', 0)
        sections_count = len(outline_data.get('chapters', []))
        matches_count = sum(len(docs) for docs in matched_docs.values())

        # 10. è¿”å›ç»“æœ
        response = {
            'success': True,
            'requirements_count': requirements_count,
            'features_count': 0,  # æš‚æ—¶ä¸º0
            'sections_count': sections_count,
            'matches_count': matches_count,
            'output_files': output_files
        }

        logger.info("æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸ")
        return jsonify(response)

    except Exception as e:
        logger.error(f"æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        error_trace = traceback.format_exc()

        return jsonify({
            'success': False,
            'error': str(e),
            'trace': error_trace if config.get('debug', False) else None
        }), 500


@api_outline_bp.route('/generate-proposal-stream', methods=['POST'])
def generate_proposal_stream():
    """
    ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆAPIï¼ˆæµå¼SSEç‰ˆæœ¬ï¼‰
    å®æ—¶æ¨é€ç”Ÿæˆè¿›åº¦

    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-dataï¼‰:
    - tender_file: æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶
    - product_file: äº§å“æ–‡æ¡£æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    - outputPrefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
    - companyId: å…¬å¸ID
    - projectName: é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼Œä»HITLä¼ é€’ï¼‰
    - technicalFileTaskId: HITLä»»åŠ¡IDï¼ˆå¯é€‰ï¼‰
    - includeAnalysis: æ˜¯å¦åŒ…å«éœ€æ±‚åˆ†æ
    - includeMapping: æ˜¯å¦ç”ŸæˆåŒ¹é…è¡¨
    - includeSummary: æ˜¯å¦ç”Ÿæˆæ€»ç»“æŠ¥å‘Š

    è¿”å›: text/event-stream
    """

    def generate_events():
        """ç”ŸæˆSSEäº‹ä»¶æµ"""
        try:
            # å‘é€åˆå§‹è¿›åº¦
            yield f"data: {json.dumps({'stage': 'init', 'progress': 0, 'message': 'å‡†å¤‡ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ...'}, ensure_ascii=False)}\n\n"

            # 1. å‚æ•°è§£æï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰
            yield f"data: {json.dumps({'stage': 'init', 'progress': 5, 'message': 'è§£æè¯·æ±‚å‚æ•°...'}, ensure_ascii=False)}\n\n"

            tender_file = request.files.get('tender_file')
            product_file = request.files.get('product_file')
            output_prefix = request.form.get('outputPrefix', 'æŠ€æœ¯æ–¹æ¡ˆ')
            company_id = request.form.get('companyId')
            project_name = request.form.get('projectName', '')
            project_id = request.form.get('technicalFileTaskId', '') or request.form.get('projectId', '')

            # ç”Ÿæˆé€‰é¡¹
            options = {
                'include_analysis': request.form.get('includeAnalysis', 'false').lower() == 'true',
                'include_mapping': request.form.get('includeMapping', 'false').lower() == 'true',
                'include_summary': request.form.get('includeSummary', 'false').lower() == 'true'
            }

            # 2. è·å–æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„
            if project_id:
                # ä»HITLé¡¹ç›®åŠ è½½ - ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢
                yield f"data: {json.dumps({'stage': 'init', 'progress': 10, 'message': f'ä»æŠ•æ ‡é¡¹ç›®åŠ è½½æŠ€æœ¯éœ€æ±‚æ–‡ä»¶ (project_id={project_id})...'}, ensure_ascii=False)}\n\n"

                tender_path = get_hitl_technical_file_path(project_id)

                if not tender_path:
                    logger.error(f'æœªæ‰¾åˆ°é¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}')
                    raise ValueError(f'æœªæ‰¾åˆ°é¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}')
            elif tender_file:
                # ä¸Šä¼ æ–‡ä»¶
                yield f"data: {json.dumps({'stage': 'init', 'progress': 10, 'message': 'ä¿å­˜ä¸Šä¼ çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶...'}, ensure_ascii=False)}\n\n"
                if not allowed_file(tender_file.filename):
                    raise ValueError('æ–‡ä»¶ç±»å‹ä¸æ”¯æŒ')

                upload_dir = config.get_path('uploads') / 'tender_processing' / datetime.now().strftime('%Y/%m')
                upload_dir.mkdir(parents=True, exist_ok=True)

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = secure_filename(f"{timestamp}_{tender_file.filename}")
                tender_path = upload_dir / filename
                tender_file.save(str(tender_path))
            else:
                raise ValueError('æœªæä¾›æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶')

            # 3. é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æ
            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 15, 'message': 'ğŸ” æ­£åœ¨åˆ†ææŠ€æœ¯éœ€æ±‚æ–‡æ¡£...'}, ensure_ascii=False)}\n\n"

            analyzer = RequirementAnalyzer()
            analysis_result = analyzer.analyze_document(str(tender_path))

            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 30, 'message': 'âœ“ éœ€æ±‚åˆ†æå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæ•´çš„éœ€æ±‚åˆ†æç»“æœä¾›å‰ç«¯å±•ç¤º
            try:
                # ç¡®ä¿analysis_resultå¯ä»¥è¢«JSONåºåˆ—åŒ–
                analysis_result_serializable = json.loads(json.dumps(analysis_result, ensure_ascii=False, default=str))
                yield f"data: {json.dumps({'stage': 'analysis_completed', 'analysis_result': analysis_result_serializable}, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.warning(f"æ— æ³•åºåˆ—åŒ–éœ€æ±‚åˆ†æç»“æœ: {e}, è·³è¿‡å‰ç«¯å±•ç¤º")
                # ç»§ç»­æ‰§è¡Œ,ä¸å½±å“åç»­æµç¨‹

            # 4. é˜¶æ®µ2ï¼šå¤§çº²ç”Ÿæˆ
            yield f"data: {json.dumps({'stage': 'outline', 'progress': 35, 'message': 'ğŸ“ æ­£åœ¨ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆå¤§çº²...'}, ensure_ascii=False)}\n\n"

            outline_gen = OutlineGenerator()
            outline_data = outline_gen.generate_outline(
                analysis_result,
                project_name=output_prefix
            )

            yield f"data: {json.dumps({'stage': 'outline', 'progress': 55, 'message': 'âœ“ å¤§çº²ç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæ•´çš„å¤§çº²æ•°æ®ä¾›å‰ç«¯å±•ç¤º
            try:
                # ç¡®ä¿outline_dataå¯ä»¥è¢«JSONåºåˆ—åŒ–
                outline_data_serializable = json.loads(json.dumps(outline_data, ensure_ascii=False, default=str))
                yield f"data: {json.dumps({'stage': 'outline_completed', 'outline_data': outline_data_serializable}, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.warning(f"æ— æ³•åºåˆ—åŒ–å¤§çº²æ•°æ®: {e}, è·³è¿‡å‰ç«¯å±•ç¤º")
                # ç»§ç»­æ‰§è¡Œ,ä¸å½±å“åç»­æµç¨‹

            # 5. é˜¶æ®µ3ï¼šäº§å“æ–‡æ¡£åŒ¹é…
            yield f"data: {json.dumps({'stage': 'matching', 'progress': 60, 'message': 'ğŸ”— æ­£åœ¨åŒ¹é…äº§å“æ–‡æ¡£...'}, ensure_ascii=False)}\n\n"

            matcher = ProductMatcher()
            matched_docs = matcher.match_documents(
                analysis_result.get('requirement_categories', []),
                company_id=int(company_id) if company_id else None
            )

            matches_count = sum(len(v) for v in matched_docs.values())
            yield f"data: {json.dumps({'stage': 'matching', 'progress': 70, 'message': f'âœ“ æ–‡æ¡£åŒ¹é…å®Œæˆï¼ˆåŒ¹é…åˆ° {matches_count} ä»½æ–‡æ¡£ï¼‰'}, ensure_ascii=False)}\n\n"

            # 6. é˜¶æ®µ4ï¼šæ–¹æ¡ˆç»„è£…
            yield f"data: {json.dumps({'stage': 'assembly', 'progress': 75, 'message': 'âš™ï¸ æ­£åœ¨ç»„è£…æŠ€æœ¯æ–¹æ¡ˆ...'}, ensure_ascii=False)}\n\n"

            assembler = ProposalAssembler()
            proposal = assembler.assemble_proposal(
                outline_data,
                analysis_result,
                matched_docs,
                options
            )

            yield f"data: {json.dumps({'stage': 'assembly', 'progress': 85, 'message': 'âœ“ æ–¹æ¡ˆç»„è£…å®Œæˆ'}, ensure_ascii=False)}\n\n"

            # 7. å¯¼å‡ºæ–‡ä»¶
            yield f"data: {json.dumps({'stage': 'export', 'progress': 90, 'message': 'ğŸ’¾ æ­£åœ¨å¯¼å‡ºæ–‡ä»¶...'}, ensure_ascii=False)}\n\n"

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            # ä½¿ç”¨ç»Ÿä¸€çš„è¾“å‡ºç›®å½•å‡½æ•°ï¼Œç›´æ¥ä¿å­˜åˆ° tech_proposal_files/{å¹´}/{æœˆ}/{é¡¹ç›®ID}/
            output_dir = get_tech_proposal_output_dir(project_id)

            exporter = WordExporter()
            output_files = {}

            # æ–‡ä»¶å‘½åï¼šé¡¹ç›®ID_é¡¹ç›®åç§°_ç±»å‹_æ—¶é—´æˆ³ï¼ˆé¡¹ç›®IDç¡®ä¿å”¯ä¸€æ€§ï¼‰
            project_id_str = f"P{project_id}" if project_id and project_id != 'default' else ''
            name_part = project_name if project_name else output_prefix
            if project_id_str:
                proposal_filename = f"{project_id_str}_{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
                analysis_filename = f"{project_id_str}_{name_part}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
                mapping_filename = f"{project_id_str}_{name_part}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
                summary_filename = f"{project_id_str}_{name_part}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"
            else:
                proposal_filename = f"{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
                analysis_filename = f"{name_part}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
                mapping_filename = f"{name_part}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
                summary_filename = f"{name_part}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"

            # å¯¼å‡ºä¸»æ–¹æ¡ˆï¼ˆç®€æ´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¤§çº²æŒ‡å¯¼ä¿¡æ¯ï¼‰
            proposal_path = output_dir / proposal_filename
            exporter.export_proposal(proposal, str(proposal_path), show_guidance=False)
            output_files['proposal'] = f"/api/downloads/{proposal_filename}"

            # å¯¼å‡ºé™„ä»¶
            if options['include_analysis']:
                analysis_path = output_dir / analysis_filename
                exporter.export_analysis_report(analysis_result, str(analysis_path))
                output_files['analysis'] = f"/api/downloads/{analysis_filename}"

            if options['include_mapping']:
                mapping_path = output_dir / mapping_filename
                mapping_data = []
                for attachment in proposal.get('attachments', []):
                    if attachment['type'] == 'mapping':
                        mapping_data = attachment['data']
                        break
                exporter.export_mapping_table(mapping_data, str(mapping_path))
                output_files['mapping'] = f"/api/downloads/{mapping_filename}"

            if options['include_summary']:
                summary_path = output_dir / summary_filename
                summary_data = {}
                for attachment in proposal.get('attachments', []):
                    if attachment['type'] == 'summary':
                        summary_data = attachment['data']
                        break
                exporter.export_summary_report(summary_data, str(summary_path))
                output_files['summary'] = f"/api/downloads/{summary_filename}"

            # ç»Ÿè®¡ä¿¡æ¯
            requirements_count = analysis_result.get('document_summary', {}).get('total_requirements', 0)
            sections_count = len(outline_data.get('chapters', []))

            # 8. å®Œæˆ
            result = {
                'stage': 'completed',
                'progress': 100,
                'message': 'âœ… æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼',
                'success': True,
                'requirements_count': requirements_count,
                'features_count': 0,
                'sections_count': sections_count,
                'matches_count': matches_count,
                'output_file': str(proposal_path),  # âœ… æ·»åŠ æ–‡ä»¶ç³»ç»Ÿå®Œæ•´è·¯å¾„ï¼Œä¸å•†åŠ¡åº”ç­”/ç‚¹å¯¹ç‚¹åº”ç­”ä¿æŒä¸€è‡´
                'output_files': output_files  # ä¿ç•™ä¸‹è½½URLå­—å…¸
            }

            yield f"data: {json.dumps(result, ensure_ascii=False)}\n\n"
            logger.info("æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼ˆSSEæµå¼ï¼‰")

        except Exception as e:
            logger.error(f"æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼ˆSSEæµå¼ï¼‰: {e}", exc_info=True)
            error_data = {
                'stage': 'error',
                'progress': 0,
                'message': f'ç”Ÿæˆå¤±è´¥: {str(e)}',
                'success': False,
                'error': str(e)
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

    return Response(
        stream_with_context(generate_events()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@api_outline_bp.route('/downloads/<filename>', methods=['GET'])
def download_file(filename):
    """
    ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶

    Args:
        filename: æ–‡ä»¶å

    Returns:
        æ–‡ä»¶å†…å®¹
    """
    try:
        output_dir = config.get_path('output')
        file_path = output_dir / filename

        if not file_path.exists():
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404

        # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®MIMEç±»å‹
        ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else ''

        mime_types = {
            'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            'txt': 'text/plain',
            'pdf': 'application/pdf'
        }

        mimetype = mime_types.get(ext, 'application/octet-stream')

        return send_file(
            str(file_path),
            as_attachment=True,
            download_name=filename,
            mimetype=mimetype
        )

    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}", exc_info=True)

        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@api_outline_bp.route('/generate-proposal-stream-v2', methods=['POST'])
def generate_proposal_stream_v2():
    """
    ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆAPIï¼ˆæµå¼SSEç‰ˆæœ¬ V2 - æ”¯æŒå®æ—¶å†…å®¹æ¨é€ï¼‰
    å®æ—¶æ¨é€ç”Ÿæˆè¿›åº¦å’Œç« èŠ‚å†…å®¹

    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-dataï¼‰:
    - tender_file: æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶
    - outputPrefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
    - companyId: å…¬å¸ID
    - projectName: é¡¹ç›®åç§°
    - projectId: é¡¹ç›®IDï¼ˆä»HITLä¼ é€’ï¼‰
    - includeAnalysis: æ˜¯å¦åŒ…å«éœ€æ±‚åˆ†æ
    - includeMapping: æ˜¯å¦ç”ŸæˆåŒ¹é…è¡¨
    - includeSummary: æ˜¯å¦ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    - useStreamingContent: æ˜¯å¦ä½¿ç”¨æµå¼å†…å®¹ç”Ÿæˆï¼ˆé»˜è®¤trueï¼‰

    è¿”å›: text/event-stream
    """

    def generate_events():
        """ç”ŸæˆSSEäº‹ä»¶æµ"""
        try:
            # åˆå§‹åŒ–
            yield f"data: {json.dumps({'stage': 'init', 'progress': 0, 'message': 'å‡†å¤‡ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ...'}, ensure_ascii=False)}\n\n"

            # å‚æ•°è§£æ
            yield f"data: {json.dumps({'stage': 'init', 'progress': 5, 'message': 'è§£æè¯·æ±‚å‚æ•°...'}, ensure_ascii=False)}\n\n"

            tender_file = request.files.get('tender_file')
            output_prefix = request.form.get('outputPrefix', 'æŠ€æœ¯æ–¹æ¡ˆ')
            company_id = request.form.get('companyId')
            project_name = request.form.get('projectName', '')
            project_id = request.form.get('projectId', '')
            ai_model = request.form.get('aiModel', 'shihuang-gpt4o-mini')  # âœ… è·å–AIæ¨¡å‹å‚æ•°ï¼Œé»˜è®¤gpt4o-mini
            use_streaming_content = request.form.get('useStreamingContent', 'true').lower() == 'true'
            proposal_mode = request.form.get('proposalMode', 'basic')  # âœ… è·å–æ–¹æ¡ˆæ¨¡å¼å‚æ•°ï¼Œé»˜è®¤basic

            logger.info(f"ä½¿ç”¨AIæ¨¡å‹: {ai_model}, æ–¹æ¡ˆæ¨¡å¼: {proposal_mode}")

            # ç”Ÿæˆé€‰é¡¹
            options = {
                'include_analysis': request.form.get('includeAnalysis', 'false').lower() == 'true',
                'include_mapping': request.form.get('includeMapping', 'false').lower() == 'true',
                'include_summary': request.form.get('includeSummary', 'false').lower() == 'true'
            }

            # è·å–æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„
            if project_id:
                yield f"data: {json.dumps({'stage': 'init', 'progress': 10, 'message': f'ä»æŠ•æ ‡é¡¹ç›®åŠ è½½æŠ€æœ¯éœ€æ±‚æ–‡ä»¶...'}, ensure_ascii=False)}\n\n"

                tender_path = get_hitl_technical_file_path(project_id)

                if not tender_path:
                    raise ValueError(f'æœªæ‰¾åˆ°é¡¹ç›®çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}')
            elif tender_file:
                yield f"data: {json.dumps({'stage': 'init', 'progress': 10, 'message': 'ä¿å­˜ä¸Šä¼ çš„æŠ€æœ¯éœ€æ±‚æ–‡ä»¶...'}, ensure_ascii=False)}\n\n"

                if not allowed_file(tender_file.filename):
                    raise ValueError('æ–‡ä»¶ç±»å‹ä¸æ”¯æŒ')

                upload_dir = config.get_path('uploads') / 'tender_processing' / datetime.now().strftime('%Y/%m')
                upload_dir.mkdir(parents=True, exist_ok=True)

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = secure_filename(f"{timestamp}_{tender_file.filename}")
                tender_path = upload_dir / filename
                tender_file.save(str(tender_path))
            else:
                raise ValueError('æœªæä¾›æŠ€æœ¯éœ€æ±‚æ–‡æ¡£æ–‡ä»¶')

            # é˜¶æ®µ1ï¼šéœ€æ±‚åˆ†æ
            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 15, 'message': 'ğŸ” æ­£åœ¨åˆ†ææŠ€æœ¯éœ€æ±‚æ–‡æ¡£...'}, ensure_ascii=False)}\n\n"

            analyzer = RequirementAnalyzer(model_name=ai_model)  # âœ… ä¼ é€’AIæ¨¡å‹å‚æ•°
            analysis_result = analyzer.analyze_document(str(tender_path))

            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 30, 'message': 'âœ“ éœ€æ±‚åˆ†æå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # é˜¶æ®µ2ï¼šå¤§çº²ç”Ÿæˆ
            yield f"data: {json.dumps({'stage': 'outline', 'progress': 35, 'message': 'ğŸ“ æ­£åœ¨ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆå¤§çº²...'}, ensure_ascii=False)}\n\n"

            outline_gen = OutlineGenerator(model_name=ai_model)  # âœ… ä¼ é€’AIæ¨¡å‹å‚æ•°
            outline_data = outline_gen.generate_outline(analysis_result, project_name=output_prefix)

            yield f"data: {json.dumps({'stage': 'outline', 'progress': 55, 'message': 'âœ“ å¤§çº²ç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæ•´çš„å¤§çº²æ•°æ®ä¾›å‰ç«¯å±•ç¤ºï¼ˆä¸V1æ¥å£ä¿æŒä¸€è‡´ï¼‰
            try:
                outline_data_serializable = json.loads(json.dumps(outline_data, ensure_ascii=False, default=str))
                yield f"data: {json.dumps({'stage': 'outline_completed', 'outline_data': outline_data_serializable}, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.warning(f"æ— æ³•åºåˆ—åŒ–å¤§çº²æ•°æ®: {e}, è·³è¿‡å‰ç«¯å±•ç¤º")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸å½±å“åç»­æµç¨‹

            # é˜¶æ®µ3ï¼šäº§å“æ–‡æ¡£åŒ¹é…
            yield f"data: {json.dumps({'stage': 'matching', 'progress': 60, 'message': 'ğŸ”— æ­£åœ¨åŒ¹é…äº§å“æ–‡æ¡£...'}, ensure_ascii=False)}\n\n"

            matcher = ProductMatcher()
            matched_docs = matcher.match_documents(
                analysis_result.get('requirement_categories', []),
                company_id=int(company_id) if company_id else None
            )

            matches_count = sum(len(v) for v in matched_docs.values())
            yield f"data: {json.dumps({'stage': 'matching', 'progress': 70, 'message': f'âœ“ æ–‡æ¡£åŒ¹é…å®Œæˆï¼ˆåŒ¹é…åˆ° {matches_count} ä»½æ–‡æ¡£ï¼‰'}, ensure_ascii=False)}\n\n"

            # é˜¶æ®µ4ï¼šæ–¹æ¡ˆç»„è£…ï¼ˆæµå¼ï¼‰
            yield f"data: {json.dumps({'stage': 'assembly', 'progress': 75, 'message': 'âš™ï¸ æ­£åœ¨ç»„è£…æŠ€æœ¯æ–¹æ¡ˆ...'}, ensure_ascii=False)}\n\n"

            assembler = ProposalAssembler(model_name=ai_model)  # âœ… ä¼ é€’AIæ¨¡å‹å‚æ•°

            # é€‰æ‹©æµå¼æˆ–éæµå¼ç»„è£…
            if use_streaming_content:
                logger.info("ä½¿ç”¨æµå¼å†…å®¹ç”Ÿæˆæ¨¡å¼")
                proposal = None

                for event in assembler.assemble_proposal_stream(outline_data, analysis_result, matched_docs, options, proposal_mode):
                    event_type = event.get('type')

                    if event_type == 'chapter_start':
                        # æ¨é€ç« èŠ‚å¼€å§‹
                        chapter_start_data = {
                            'stage': 'content_generation',
                            'event': 'chapter_start',
                            'chapter_number': event.get('chapter_number', ''),
                            'chapter_title': event.get('chapter_title', ''),
                            'message': f"ğŸ“„ å¼€å§‹ç”Ÿæˆ {event.get('chapter_number', '')} {event.get('chapter_title', '')}..."
                        }
                        yield f"data: {json.dumps(chapter_start_data, ensure_ascii=False)}\n\n"

                    elif event_type == 'content_chunk':
                        # æ¨é€å†…å®¹ç‰‡æ®µ
                        content_chunk_data = {
                            'stage': 'content_generation',
                            'event': 'content_chunk',
                            'chapter_number': event.get('chapter_number', ''),
                            'content': event.get('chunk', '')
                        }
                        yield f"data: {json.dumps(content_chunk_data, ensure_ascii=False)}\n\n"

                    elif event_type == 'chapter_end':
                        # æ¨é€ç« èŠ‚å®Œæˆ
                        chapter_end_data = {
                            'stage': 'content_generation',
                            'event': 'chapter_end',
                            'chapter_number': event.get('chapter_number', ''),
                            'message': f"âœ“ {event.get('chapter_title', '')} ç”Ÿæˆå®Œæˆ"
                        }
                        yield f"data: {json.dumps(chapter_end_data, ensure_ascii=False)}\n\n"

                    elif event_type == 'completed':
                        # ä¿å­˜æ–¹æ¡ˆæ•°æ®
                        proposal = event['proposal']

                    elif event_type == 'error':
                        raise Exception(event['error'])

                if not proposal:
                    raise ValueError("æµå¼ç»„è£…æœªè¿”å›å®Œæ•´æ–¹æ¡ˆ")

                yield f"data: {json.dumps({'stage': 'assembly', 'progress': 85, 'message': 'âœ“ æ–¹æ¡ˆç»„è£…å®Œæˆï¼ˆæµå¼ï¼‰'}, ensure_ascii=False)}\n\n"
            else:
                # ä½¿ç”¨éæµå¼ç»„è£…ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                proposal = assembler.assemble_proposal(outline_data, analysis_result, matched_docs, options, proposal_mode)
                yield f"data: {json.dumps({'stage': 'assembly', 'progress': 85, 'message': 'âœ“ æ–¹æ¡ˆç»„è£…å®Œæˆ'}, ensure_ascii=False)}\n\n"

            # å¯¼å‡ºæ–‡ä»¶
            yield f"data: {json.dumps({'stage': 'export', 'progress': 90, 'message': 'ğŸ’¾ æ­£åœ¨å¯¼å‡ºæ–‡ä»¶...'}, ensure_ascii=False)}\n\n"

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            # ä½¿ç”¨ç»Ÿä¸€çš„è¾“å‡ºç›®å½•å‡½æ•°ï¼Œç›´æ¥ä¿å­˜åˆ° tech_proposal_files/{å¹´}/{æœˆ}/{é¡¹ç›®ID}/
            output_dir = get_tech_proposal_output_dir(project_id)

            exporter = WordExporter()
            output_files = {}

            # æ–‡ä»¶å‘½åï¼šé¡¹ç›®ID_é¡¹ç›®åç§°_ç±»å‹_æ—¶é—´æˆ³ï¼ˆé¡¹ç›®IDç¡®ä¿å”¯ä¸€æ€§ï¼‰
            project_id_str = f"P{project_id}" if project_id and project_id != 'default' else ''
            name_part = project_name if project_name else output_prefix
            if project_id_str:
                proposal_filename = f"{project_id_str}_{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
                analysis_filename = f"{project_id_str}_{name_part}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
                mapping_filename = f"{project_id_str}_{name_part}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
                summary_filename = f"{project_id_str}_{name_part}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"
            else:
                proposal_filename = f"{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
                analysis_filename = f"{name_part}_éœ€æ±‚åˆ†æ_{timestamp}.docx"
                mapping_filename = f"{name_part}_éœ€æ±‚åŒ¹é…è¡¨_{timestamp}.xlsx"
                summary_filename = f"{name_part}_ç”ŸæˆæŠ¥å‘Š_{timestamp}.txt"

            # å¯¼å‡ºä¸»æ–¹æ¡ˆï¼ˆç®€æ´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºå¤§çº²æŒ‡å¯¼ä¿¡æ¯ï¼‰
            proposal_path = output_dir / proposal_filename
            exporter.export_proposal(proposal, str(proposal_path), show_guidance=False)
            output_files['proposal'] = f"/api/downloads/{proposal_filename}"

            # å¯¼å‡ºé™„ä»¶
            if options['include_analysis']:
                analysis_path = output_dir / analysis_filename
                exporter.export_analysis_report(analysis_result, str(analysis_path))
                output_files['analysis'] = f"/api/downloads/{analysis_filename}"

            if options['include_mapping']:
                mapping_path = output_dir / mapping_filename
                mapping_data = []
                for attachment in proposal.get('attachments', []):
                    if attachment['type'] == 'mapping':
                        mapping_data = attachment['data']
                        break
                exporter.export_mapping_table(mapping_data, str(mapping_path))
                output_files['mapping'] = f"/api/downloads/{mapping_filename}"

            if options['include_summary']:
                summary_path = output_dir / summary_filename
                summary_data = {}
                for attachment in proposal.get('attachments', []):
                    if attachment['type'] == 'summary':
                        summary_data = attachment['data']
                        break
                exporter.export_summary_report(summary_data, str(summary_path))
                output_files['summary'] = f"/api/downloads/{summary_filename}"

            # ç»Ÿè®¡ä¿¡æ¯
            requirements_count = analysis_result.get('document_summary', {}).get('total_requirements', 0)
            sections_count = len(outline_data.get('chapters', []))

            # å®Œæˆ
            result = {
                'stage': 'completed',
                'progress': 100,
                'message': 'âœ… æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼',
                'success': True,
                'requirements_count': requirements_count,
                'features_count': 0,
                'sections_count': sections_count,
                'matches_count': matches_count,
                'output_file': str(proposal_path),
                'output_files': output_files,
                'streaming_mode': use_streaming_content
            }

            yield f"data: {json.dumps(result, ensure_ascii=False)}\n\n"
            logger.info("æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼ˆSSEæµå¼V2ï¼‰")

        except Exception as e:
            logger.error(f"æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼ˆSSEæµå¼V2ï¼‰: {e}", exc_info=True)
            error_data = {
                'stage': 'error',
                'progress': 0,
                'message': f'ç”Ÿæˆå¤±è´¥: {str(e)}',
                'success': False,
                'error': str(e)
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

    return Response(
        stream_with_context(generate_events()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@api_outline_bp.route('/prompts/outline-generation', methods=['GET'])
def get_outline_generation_prompts():
    """
    è·å–å¤§çº²ç”Ÿæˆæç¤ºè¯é…ç½®

    è¿”å›:
    {
        "success": true,
        "prompts": {
            "analyze_requirements": "...",
            "generate_outline": "...",
            "generate_response_suggestions": "...",
            "recommend_product_docs": "..."
        }
    }
    """
    try:
        logger.info("è·å–å¤§çº²ç”Ÿæˆæç¤ºè¯é…ç½®")

        # è·å– prompt manager
        prompt_manager = get_prompt_manager()

        # è·å–æ‰€æœ‰å¤§çº²ç”Ÿæˆç›¸å…³çš„æç¤ºè¯
        prompts = {
            'analyze_requirements': prompt_manager.get_prompt('outline_generation', 'analyze_requirements'),
            'generate_outline': prompt_manager.get_prompt('outline_generation', 'generate_outline'),
            'generate_response_suggestions': prompt_manager.get_prompt('outline_generation', 'generate_response_suggestions'),
            'recommend_product_docs': prompt_manager.get_prompt('outline_generation', 'recommend_product_docs')
        }

        return jsonify({
            'success': True,
            'prompts': prompts
        })

    except Exception as e:
        logger.error(f"è·å–æç¤ºè¯é…ç½®å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ==================== æ™ºèƒ½ä½“API ====================

@api_outline_bp.route('/agent/generate', methods=['POST'])
def generate_with_agent():
    """
    ä½¿ç”¨æ™ºèƒ½ä½“ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆAPIï¼ˆSSEæµå¼å“åº”ï¼‰

    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-data æˆ– JSONï¼‰:
    - generation_mode: ç”Ÿæˆæ¨¡å¼ ("æŒ‰è¯„åˆ†ç‚¹å†™" | "æŒ‰æ‹›æ ‡ä¹¦ç›®å½•å†™" | "ç¼–å†™ä¸“é¡¹ç« èŠ‚")
    - tender_file: æ‹›æ ‡æ–‡æ¡£æ–‡ä»¶ (FormData) æˆ– tender_doc: æ–‡æœ¬ (JSON)
    - page_count: ç›®æ ‡é¡µæ•°
    - content_style: å†…å®¹é£æ ¼é…ç½®(JSONå­—ç¬¦ä¸²æˆ–å¯¹è±¡)
    - template_name: æ¨¡æ¿åç§° (ç¼–å†™ä¸“é¡¹ç« èŠ‚æ¨¡å¼å¿…å¡«)
    - projectId: é¡¹ç›®ID (å¯é€‰ï¼Œä»HITLåŠ è½½)

    è¿”å›: SSEæµå¼äº‹ä»¶
    - stage: init/analysis/analysis_completed/outline_completed/export/completed/error
    - progress: 0-100
    - message: è¿›åº¦æ¶ˆæ¯
    - å„é˜¶æ®µç‰¹å®šæ•°æ®
    """
    # å…ˆè§£æè¯·æ±‚å‚æ•°ï¼ˆåœ¨generatorå¤–éƒ¨ï¼Œé¿å…ä¸Šä¸‹æ–‡é—®é¢˜ï¼‰
    try:
        from ai_tender_system.modules.outline_generator.agents import AgentRouter

        logger.info("ã€æ™ºèƒ½ä½“APIã€‘æ”¶åˆ°è¯·æ±‚")

        # æ”¯æŒä¸¤ç§æ ¼å¼: FormData å’Œ JSON
        is_json_request = request.is_json
        if is_json_request:
            # JSONæ ¼å¼
            req_data = request.json
            generation_mode = req_data.get('generation_mode')
            tender_doc = req_data.get('tender_doc', '')
            page_count = int(req_data.get('page_count', 200))
            content_style = req_data.get('content_style', {})
            template_name = req_data.get('template_name', 'æ”¿åºœé‡‡è´­æ ‡å‡†')
            scoring_points = req_data.get('scoring_points')
            project_id = req_data.get('projectId', 'default')
            project_name = req_data.get('projectName', '')
            output_prefix = req_data.get('outputPrefix', 'æŠ€æœ¯æ–¹æ¡ˆ')
        else:
            # FormDataæ ¼å¼
            generation_mode = request.form.get('generation_mode')
            tender_doc = ''
            page_count = int(request.form.get('page_count', 200))
            template_name = request.form.get('template_name', 'æ”¿åºœé‡‡è´­æ ‡å‡†')
            scoring_points = None
            project_id = request.form.get('projectId') or request.form.get('project_id') or 'default'
            project_name = request.form.get('projectName', '')
            output_prefix = request.form.get('outputPrefix', 'æŠ€æœ¯æ–¹æ¡ˆ')

            # content_styleå¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²
            content_style_str = request.form.get('content_style', '')
            if content_style_str:
                try:
                    content_style = json.loads(content_style_str)
                except:
                    content_style = {'tables': 'é€‚é‡', 'flowcharts': 'æµç¨‹å›¾', 'images': 'å°‘é‡'}
            else:
                content_style = {'tables': 'é€‚é‡', 'flowcharts': 'æµç¨‹å›¾', 'images': 'å°‘é‡'}

            # ä»HITLæˆ–ä¸Šä¼ æ–‡ä»¶è·å–æ‹›æ ‡æ–‡æ¡£
            use_hitl_file = request.form.get('use_hitl_technical_file', 'false').lower() == 'true'

            if use_hitl_file and project_id and project_id != 'default':
                # ä½¿ç”¨è¾…åŠ©å‡½æ•°ä»æ•°æ®åº“æŸ¥è¯¢æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„
                logger.info(f"[æ™ºèƒ½ä½“API] ä»HITLé¡¹ç›®åŠ è½½æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}")
                tender_path = get_hitl_technical_file_path(project_id)

                if tender_path:
                    logger.info(f"[æ™ºèƒ½ä½“API] æ‰¾åˆ°HITLæŠ€æœ¯éœ€æ±‚æ–‡ä»¶: {tender_path}")
                    from docx import Document
                    doc = Document(str(tender_path))
                    content_parts = []
                    for para in doc.paragraphs:
                        text = para.text.strip()
                        if text:
                            content_parts.append(text)
                    for table in doc.tables:
                        content_parts.append('\n[è¡¨æ ¼å†…å®¹]')
                        for tbl_row in table.rows:
                            row_text = ' | '.join([cell.text.strip() for cell in tbl_row.cells if cell.text.strip()])
                            if row_text:
                                content_parts.append(row_text)
                        content_parts.append('[è¡¨æ ¼ç»“æŸ]\n')
                    tender_doc = '\n'.join(content_parts)
                else:
                    logger.warning(f"[æ™ºèƒ½ä½“API] æœªæ‰¾åˆ°HITLæŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}")

            elif 'tender_file' in request.files:
                tender_file = request.files['tender_file']
                if allowed_file(tender_file.filename):
                    upload_dir = config.get_path('uploads')
                    upload_dir.mkdir(parents=True, exist_ok=True)
                    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
                    filename = secure_filename(f"{ts}_{tender_file.filename}")
                    tender_path = upload_dir / filename
                    tender_file.save(str(tender_path))

                    from docx import Document
                    doc = Document(str(tender_path))
                    content_parts = []
                    for para in doc.paragraphs:
                        text = para.text.strip()
                        if text:
                            content_parts.append(text)
                    for table in doc.tables:
                        content_parts.append('\n[è¡¨æ ¼å†…å®¹]')
                        for row in table.rows:
                            row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])
                            if row_text:
                                content_parts.append(row_text)
                        content_parts.append('[è¡¨æ ¼ç»“æŸ]\n')
                    tender_doc = '\n'.join(content_parts)
                    logger.info(f"å·²è§£æä¸Šä¼ æ–‡ä»¶: {tender_path}, æ–‡æœ¬é•¿åº¦: {len(tender_doc)}")

        # å‚æ•°éªŒè¯
        param_error = None
        if not generation_mode:
            param_error = 'ç¼ºå°‘å¿…å¡«å‚æ•°: generation_mode'
        elif not tender_doc:
            param_error = 'ç¼ºå°‘å¿…å¡«å‚æ•°: tender_doc æˆ– tender_file'

    except Exception as e:
        param_error = f'å‚æ•°è§£æå¤±è´¥: {str(e)}'
        generation_mode = None
        tender_doc = None
        page_count = 200
        content_style = {}
        template_name = 'æ”¿åºœé‡‡è´­æ ‡å‡†'
        scoring_points = None
        project_id = 'default'
        project_name = ''
        output_prefix = 'æŠ€æœ¯æ–¹æ¡ˆ'

    def generate_events():
        """ç”ŸæˆSSEäº‹ä»¶æµ"""
        nonlocal param_error, generation_mode, tender_doc, page_count, content_style
        nonlocal template_name, scoring_points, project_id, project_name, output_prefix

        try:
            # æ£€æŸ¥å‚æ•°é”™è¯¯
            if param_error:
                yield f"data: {json.dumps({'stage': 'error', 'error': param_error, 'message': f'âŒ {param_error}'}, ensure_ascii=False)}\n\n"
                return

            # 1. åˆå§‹åŒ–é˜¶æ®µ
            yield f"data: {json.dumps({'stage': 'init', 'progress': 5, 'message': 'ğŸš€ å¼€å§‹ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ...'}, ensure_ascii=False)}\n\n"

            # 2. è§£æå‚æ•°å®Œæˆ
            yield f"data: {json.dumps({'stage': 'init', 'progress': 10, 'message': 'ğŸ“„ å‚æ•°è§£æå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # 3. éœ€æ±‚åˆ†æé˜¶æ®µ
            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 20, 'message': 'ğŸ” æ­£åœ¨åˆ†ææŠ€æœ¯éœ€æ±‚...'}, ensure_ascii=False)}\n\n"

            # åˆ›å»ºè·¯ç”±å™¨å¹¶ç”Ÿæˆ
            from ai_tender_system.modules.outline_generator.agents import AgentRouter
            router = AgentRouter()

            logger.info(f"è°ƒç”¨æ™ºèƒ½ä½“è·¯ç”±: mode={generation_mode}, pages={page_count}, template={template_name}")

            result = router.route(
                generation_mode=generation_mode,
                tender_doc=tender_doc,
                page_count=page_count,
                content_style=content_style,
                scoring_points=scoring_points,
                template_name=template_name
            )

            logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘ç”ŸæˆæˆåŠŸï¼Œæ¨¡å¼: {generation_mode}")

            # 4. åˆ†æå®Œæˆ
            yield f"data: {json.dumps({'stage': 'analysis', 'progress': 35, 'message': 'âœ“ éœ€æ±‚åˆ†æå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # å‘é€åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            analysis_result = result.get('analysis', {})
            if analysis_result:
                yield f"data: {json.dumps({'stage': 'analysis_completed', 'progress': 40, 'analysis_result': analysis_result}, ensure_ascii=False)}\n\n"

            # 5. å¤§çº²ç”Ÿæˆå®Œæˆ
            outline_data = result.get('outline', {})
            chapters = result.get('chapters', [])
            yield f"data: {json.dumps({'stage': 'outline', 'progress': 50, 'message': 'ğŸ“ æ­£åœ¨ç”Ÿæˆå¤§çº²...'}, ensure_ascii=False)}\n\n"

            # æ„å»ºå¤§çº²æ•°æ®ä¾›å‰ç«¯æ˜¾ç¤º
            outline_for_frontend = {
                'chapters': outline_data.get('chapters', []),
                'total_chapters': len(chapters),
                'estimated_pages': result.get('metadata', {}).get('total_pages', page_count)
            }
            yield f"data: {json.dumps({'stage': 'outline_completed', 'progress': 60, 'outline_data': outline_for_frontend}, ensure_ascii=False)}\n\n"

            # 6. å¯¼å‡ºWordæ–‡æ¡£
            yield f"data: {json.dumps({'stage': 'export', 'progress': 75, 'message': 'ğŸ’¾ æ­£åœ¨å¯¼å‡ºWordæ–‡æ¡£...'}, ensure_ascii=False)}\n\n"

            from ai_tender_system.modules.outline_generator import WordExporter

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            # ä½¿ç”¨ç»Ÿä¸€çš„è¾“å‡ºç›®å½•å‡½æ•°ï¼Œç›´æ¥ä¿å­˜åˆ° tech_proposal_files/{å¹´}/{æœˆ}/{é¡¹ç›®ID}/
            output_dir = get_tech_proposal_output_dir(project_id)

            # æ–‡ä»¶å‘½åï¼šé¡¹ç›®ID_é¡¹ç›®åç§°_ç±»å‹_æ—¶é—´æˆ³ï¼ˆé¡¹ç›®IDç¡®ä¿å”¯ä¸€æ€§ï¼‰
            project_id_str = f"P{project_id}" if project_id and project_id != 'default' else ''
            name_part = project_name if project_name else output_prefix
            if project_id_str:
                proposal_filename = f"{project_id_str}_{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"
            else:
                proposal_filename = f"{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx"

            proposal_path = output_dir / proposal_filename

            logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘æ–‡ä»¶å°†ä¿å­˜åˆ°: {proposal_path}")

            # æ„å»ºproposalæ•°æ®ç»“æ„
            proposal_data = {
                'metadata': {
                    'title': outline_data.get('title', 'æŠ€æœ¯æ–¹æ¡ˆ'),
                    'generation_time': timestamp,
                    'total_chapters': len(chapters),
                    'estimated_pages': result.get('metadata', {}).get('estimated_pages', 0)
                },
                'chapters': []
            }

            for chapter in chapters:
                # ç±»å‹å®‰å…¨æ£€æŸ¥
                if not isinstance(chapter, dict):
                    logger.warning(f"ã€æ™ºèƒ½ä½“APIã€‘ç« èŠ‚ä¸æ˜¯å­—å…¸ç±»å‹: {type(chapter)}")
                    if isinstance(chapter, list) and len(chapter) > 0:
                        chapter = chapter[0] if isinstance(chapter[0], dict) else {}
                    else:
                        chapter = {}

                # æ™ºèƒ½ä½“è¿”å›çš„å­—æ®µæ˜¯ 'title' å’Œ 'content'
                content = chapter.get('content', '')
                if isinstance(content, list):
                    content = '\n'.join(str(item) for item in content if item)
                elif not isinstance(content, str):
                    content = str(content) if content else ''

                chapter_data = {
                    'level': chapter.get('level', 1),
                    'chapter_number': chapter.get('chapter_number', ''),
                    'title': chapter.get('title', ''),  # æ™ºèƒ½ä½“è¿”å› 'title' è€Œé 'chapter_title'
                    'ai_generated_content': content,
                    'subsections': chapter.get('subsections', []) if isinstance(chapter.get('subsections'), list) else []
                }
                proposal_data['chapters'].append(chapter_data)

            logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘æ„å»ºçš„ç« èŠ‚æ•°é‡: {len(proposal_data['chapters'])}")
            if proposal_data['chapters']:
                first_chapter = proposal_data['chapters'][0]
                logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘ç¬¬ä¸€ç« æ ‡é¢˜: {first_chapter.get('title', 'N/A')}")
                logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘ç¬¬ä¸€ç« å†…å®¹é•¿åº¦: {len(first_chapter.get('ai_generated_content', ''))}")

            exporter = WordExporter()
            exporter.export_proposal(proposal_data, str(proposal_path), show_guidance=False)

            logger.info(f"ã€æ™ºèƒ½ä½“APIã€‘Wordæ–‡ä»¶å·²å¯¼å‡º: {proposal_path}")

            yield f"data: {json.dumps({'stage': 'export', 'progress': 90, 'message': 'âœ“ Wordæ–‡æ¡£å¯¼å‡ºå®Œæˆ'}, ensure_ascii=False)}\n\n"

            # 7. å®Œæˆ
            completed_data = {
                'stage': 'completed',
                'progress': 100,
                'success': True,
                'message': 'âœ… æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼',
                'output_file': str(proposal_path),
                'output_files': {
                    'proposal': f"/api/downloads/{proposal_filename}"
                },
                'sections_count': len(chapters),
                'requirements_count': result.get('metadata', {}).get('requirement_categories_count', 0),
                'coverage_rate': result.get('metadata', {}).get('coverage_rate', 0)
            }
            yield f"data: {json.dumps(completed_data, ensure_ascii=False)}\n\n"

        except Exception as e:
            logger.error(f"ã€æ™ºèƒ½ä½“APIã€‘ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            error_data = {
                'stage': 'error',
                'error': str(e),
                'message': f'âŒ ç”Ÿæˆå¤±è´¥: {str(e)}'
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

    return Response(
        stream_with_context(generate_events()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@api_outline_bp.route('/agent/templates', methods=['GET'])
def list_templates():
    """
    è·å–å¯ç”¨æ¨¡æ¿åˆ—è¡¨

    è¿”å›:
    {
        "success": true,
        "data": [
            {
                "template_id": "æ”¿åºœé‡‡è´­æ ‡å‡†",
                "name": "æ”¿åºœé‡‡è´­æ ‡å‡†æ¨¡æ¿",
                "description": "...",
                "chapters_count": 5,
                "chapters": [...]
            },
            ...
        ]
    }
    """
    try:
        from ai_tender_system.modules.outline_generator.agents import TemplateAgent

        templates = TemplateAgent.list_templates()

        return jsonify({
            'success': True,
            'data': templates
        })

    except Exception as e:
        logger.error(f"è·å–æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@api_outline_bp.route('/agent/modes', methods=['GET'])
def get_generation_modes():
    """
    è·å–å¯ç”¨çš„ç”Ÿæˆæ¨¡å¼

    è¿”å›:
    {
        "success": true,
        "data": {
            "modes": [...],
            "templates": [...]
        }
    }
    """
    try:
        from ai_tender_system.modules.outline_generator.agents import AgentRouter

        router = AgentRouter()
        modes_info = router.get_available_modes()

        return jsonify({
            'success': True,
            'data': modes_info
        })

    except Exception as e:
        logger.error(f"è·å–ç”Ÿæˆæ¨¡å¼å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@api_outline_bp.route('/agent/scoring/extract', methods=['POST'])
def extract_scoring_points():
    """
    ä»æ‹›æ ‡æ–‡æ¡£ä¸­æå–è¯„åˆ†ç‚¹ï¼ˆåœºæ™¯1ï¼‰

    è¯·æ±‚å‚æ•°ï¼ˆJSONï¼‰:
    {
        "tender_doc": "æ‹›æ ‡æ–‡æ¡£æ–‡æœ¬"
    }

    è¿”å›:
    {
        "success": true,
        "data": {
            "scoring_points": [...]
        }
    }
    """
    try:
        from ai_tender_system.modules.outline_generator.agents import ScoringPointAgent

        data = request.json
        tender_doc = data.get('tender_doc', '')

        if not tender_doc:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…å¡«å‚æ•°: tender_doc'
            }), 400

        agent = ScoringPointAgent()
        scoring_points = agent.extract_scoring_points(tender_doc)

        return jsonify({
            'success': True,
            'data': {
                'scoring_points': scoring_points
            }
        })

    except Exception as e:
        logger.error(f"è¯„åˆ†ç‚¹æå–å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@api_outline_bp.route('/agent/scoring/evaluate', methods=['POST'])
def evaluate_tender():
    """
    AIè¯„åˆ†APIï¼ˆåœºæ™¯2ï¼‰

    è¯·æ±‚å‚æ•°ï¼ˆJSONï¼‰:
    {
        "tender_doc": "æ ‡ä¹¦æ–‡æ¡£æ–‡æœ¬",
        "scoring_points": [...]
    }

    è¿”å›:
    {
        "success": true,
        "data": {
            "overall_score": 85.5,
            "dimension_scores": [...],
            "risk_analysis": {...},
            "improvement_suggestions": [...]
        }
    }
    """
    try:
        from ai_tender_system.modules.outline_generator.agents import ScoringPointAgent

        data = request.json
        tender_doc = data.get('tender_doc', '')
        scoring_points = data.get('scoring_points', [])

        if not tender_doc or not scoring_points:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…å¡«å‚æ•°: tender_doc æˆ– scoring_points'
            }), 400

        agent = ScoringPointAgent()
        result = agent.evaluate_tender_document(tender_doc, scoring_points)

        return jsonify({
            'success': True,
            'data': result
        })

    except Exception as e:
        logger.error(f"AIè¯„åˆ†å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@api_outline_bp.route('/agent/generate-crew', methods=['POST'])
def generate_with_crew():
    """
    ä½¿ç”¨ ProposalCrew ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆï¼ˆQuality-First æ¨¡å¼ï¼‰

    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-data æˆ– JSONï¼‰:
    - tender_file / tender_doc: æ‹›æ ‡æ–‡æ¡£
    - page_count: ç›®æ ‡é¡µæ•° (é»˜è®¤200)
    - projectId: é¡¹ç›®ID
    - projectName: é¡¹ç›®åç§°
    - companyId: å…¬å¸ID
    - aiModel: AIæ¨¡å‹
    - crew_config: CrewConfigé…ç½®ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
      - skip_product_matching: bool
      - skip_material_retrieval: bool
      - enable_expert_review: bool
      - max_iterations: int
      - min_review_score: float
    - content_style: å†…å®¹é£æ ¼é…ç½®

    è¿”å›: SSEæµå¼äº‹ä»¶
    """
    # å…ˆè§£æè¯·æ±‚å‚æ•°ï¼ˆåœ¨generatorå¤–éƒ¨ï¼Œé¿å…ä¸Šä¸‹æ–‡é—®é¢˜ï¼‰
    try:
        logger.info("ã€Quality-First APIã€‘æ”¶åˆ°è¯·æ±‚")

        # æ”¯æŒä¸¤ç§æ ¼å¼: FormData å’Œ JSON
        is_json_request = request.is_json
        if is_json_request:
            req_data = request.json
            tender_doc = req_data.get('tender_doc', '')
            page_count = int(req_data.get('page_count', 200))
            company_id = req_data.get('companyId', 1)
            project_id = req_data.get('projectId', 'default')
            project_name = req_data.get('projectName', '')
            customer_name = ''  # å®¢æˆ·åç§°ï¼ˆæ‹›æ ‡æ–¹ï¼‰
            ai_model = req_data.get('aiModel', 'shibing624-gpt4o-mini')
            crew_config_raw = req_data.get('crew_config', {})
            content_style = req_data.get('content_style', {})
        else:
            # FormDataæ ¼å¼
            tender_doc = ''
            page_count = int(request.form.get('page_count', 200))
            company_id = request.form.get('companyId', 1)
            project_id = request.form.get('projectId') or request.form.get('project_id') or 'default'
            project_name = request.form.get('projectName', '')
            customer_name = ''  # å®¢æˆ·åç§°ï¼ˆæ‹›æ ‡æ–¹ï¼‰
            ai_model = request.form.get('aiModel', 'shibing624-gpt4o-mini')

            # crew_config æ˜¯ JSON å­—ç¬¦ä¸²
            crew_config_str = request.form.get('crew_config', '{}')
            try:
                crew_config_raw = json.loads(crew_config_str)
            except:
                crew_config_raw = {}

            # content_style æ˜¯ JSON å­—ç¬¦ä¸²
            content_style_str = request.form.get('content_style', '{}')
            try:
                content_style = json.loads(content_style_str)
            except:
                content_style = {'tables': 'é€‚é‡', 'flowcharts': 'æµç¨‹å›¾', 'images': 'å°‘é‡'}

            # ä»HITLæˆ–ä¸Šä¼ æ–‡ä»¶è·å–æ‹›æ ‡æ–‡æ¡£
            use_hitl_file = request.form.get('use_hitl_technical_file', 'false').lower() == 'true'

            if use_hitl_file and project_id and project_id != 'default':
                # ä½¿ç”¨è¾…åŠ©å‡½æ•°ä»æ•°æ®åº“æŸ¥è¯¢æŠ€æœ¯éœ€æ±‚æ–‡ä»¶è·¯å¾„
                logger.info(f"[Quality-First API] ä»HITLé¡¹ç›®åŠ è½½æŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}")
                tender_path = get_hitl_technical_file_path(project_id)

                if tender_path:
                    logger.info(f"[Quality-First API] æ‰¾åˆ°HITLæŠ€æœ¯éœ€æ±‚æ–‡ä»¶: {tender_path}")
                    from docx import Document
                    doc = Document(str(tender_path))
                    content_parts = []
                    for para in doc.paragraphs:
                        text = para.text.strip()
                        if text:
                            content_parts.append(text)
                    for table in doc.tables:
                        content_parts.append('\n[è¡¨æ ¼å†…å®¹]')
                        for tbl_row in table.rows:
                            row_text = ' | '.join([cell.text.strip() for cell in tbl_row.cells if cell.text.strip()])
                            if row_text:
                                content_parts.append(row_text)
                        content_parts.append('[è¡¨æ ¼ç»“æŸ]\n')
                    tender_doc = '\n'.join(content_parts)
                else:
                    logger.warning(f"[Quality-First API] æœªæ‰¾åˆ°HITLæŠ€æœ¯éœ€æ±‚æ–‡ä»¶: project_id={project_id}")

            elif 'tender_file' in request.files:
                tender_file = request.files['tender_file']
                if allowed_file(tender_file.filename):
                    upload_dir = config.get_path('uploads')
                    upload_dir.mkdir(parents=True, exist_ok=True)
                    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
                    filename = secure_filename(f"{ts}_{tender_file.filename}")
                    tender_path = upload_dir / filename
                    tender_file.save(str(tender_path))

                    from docx import Document
                    doc = Document(str(tender_path))
                    content_parts = []
                    for para in doc.paragraphs:
                        text = para.text.strip()
                        if text:
                            content_parts.append(text)
                    for table in doc.tables:
                        content_parts.append('\n[è¡¨æ ¼å†…å®¹]')
                        for row in table.rows:
                            row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])
                            if row_text:
                                content_parts.append(row_text)
                        content_parts.append('[è¡¨æ ¼ç»“æŸ]\n')
                    tender_doc = '\n'.join(content_parts)
                    logger.info(f"å·²è§£æä¸Šä¼ æ–‡ä»¶: {tender_path}, æ–‡æœ¬é•¿åº¦: {len(tender_doc)}")

        # ä»æ•°æ®åº“æŸ¥è¯¢é¡¹ç›®ä¿¡æ¯ï¼ˆé¡¹ç›®åç§°å’Œå®¢æˆ·åç§°ï¼‰
        if project_id and project_id != 'default':
            try:
                from ai_tender_system.common.database import get_db_connection
                with get_db_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute(
                        "SELECT project_name, tenderer FROM tender_projects WHERE project_id = ?",
                        (project_id,)
                    )
                    row = cursor.fetchone()
                    if row:
                        # ä½¿ç”¨æ•°æ®åº“ä¸­çš„å€¼ä½œä¸ºåå¤‡ï¼ˆå¦‚æœå‰ç«¯æ²¡ä¼ ï¼‰
                        if not project_name and row[0]:
                            project_name = row[0]
                        if row[1]:
                            customer_name = row[1]
                        logger.info(f"ä»æ•°æ®åº“è·å–é¡¹ç›®ä¿¡æ¯: project_name={project_name}, customer_name={customer_name}")
            except Exception as e:
                logger.warning(f"æŸ¥è¯¢é¡¹ç›®ä¿¡æ¯å¤±è´¥: {e}")

        # å‚æ•°éªŒè¯
        param_error = None
        if not tender_doc:
            param_error = 'ç¼ºå°‘å¿…å¡«å‚æ•°: tender_doc æˆ– tender_file'

    except Exception as e:
        param_error = f'å‚æ•°è§£æå¤±è´¥: {str(e)}'
        tender_doc = ''
        page_count = 200
        company_id = 1
        project_id = 'default'
        project_name = ''
        customer_name = ''
        ai_model = 'shibing624-gpt4o-mini'
        crew_config_raw = {}
        content_style = {}

    def generate_events():
        """ç”ŸæˆSSEäº‹ä»¶æµ"""
        nonlocal param_error, tender_doc, page_count, company_id, project_id
        nonlocal project_name, customer_name, ai_model, crew_config_raw, content_style

        try:
            # æ£€æŸ¥å‚æ•°é”™è¯¯
            if param_error:
                yield f"data: {json.dumps({'stage': 'error', 'status': 'error', 'error': param_error, 'message': f'âŒ {param_error}'}, ensure_ascii=False)}\n\n"
                return

            # åˆå§‹åŒ–äº‹ä»¶
            yield f"data: {json.dumps({'stage': 'init', 'status': 'running', 'progress': 0, 'message': 'ğŸš€ åˆå§‹åŒ– Quality-First æ¨¡å¼...'}, ensure_ascii=False)}\n\n"

            # åˆ›å»º ProposalCrew
            from ai_tender_system.modules.outline_generator.agents import ProposalCrew, CrewConfig

            crew_config = CrewConfig(
                model_name=ai_model,
                company_id=int(company_id) if company_id else 1,
                skip_product_matching=crew_config_raw.get('skip_product_matching', False),
                skip_material_retrieval=crew_config_raw.get('skip_material_retrieval', False),
                enable_expert_review=crew_config_raw.get('enable_expert_review', True),
                max_iterations=crew_config_raw.get('max_iterations', 2),
                min_review_score=crew_config_raw.get('min_review_score', 85.0),
                target_word_count=page_count * 700,
                content_style=content_style,
                project_name=project_name,      # é¡¹ç›®åç§°
                customer_name=customer_name     # å®¢æˆ·åç§°ï¼ˆæ‹›æ ‡æ–¹ï¼‰
            )

            crew = ProposalCrew(crew_config)

            logger.info(f"ã€Quality-Firstã€‘å¼€å§‹ç”Ÿæˆ: pages={page_count}, company_id={company_id}")

            # é˜¶æ®µè¿›åº¦æ˜ å°„
            phase_progress = {
                'scoring_extraction': 12,
                'product_matching': 22,
                'strategy_planning': 32,
                'material_retrieval': 42,
                'outline_generation': 55,
                'content_writing': 75,
                'expert_review': 90,
                'iteration': 95,
                'complete': 100
            }

            phase_messages = {
                'scoring_extraction': 'ğŸ¯ æ­£åœ¨æå–è¯„åˆ†ç‚¹...',
                'product_matching': 'ğŸ”— æ­£åœ¨åŒ¹é…äº§å“èƒ½åŠ›...',
                'strategy_planning': 'ğŸ“Š æ­£åœ¨åˆ¶å®šè¯„åˆ†ç­–ç•¥...',
                'material_retrieval': 'ğŸ“š æ­£åœ¨æ£€ç´¢å†å²ç´ æ...',
                'outline_generation': 'ğŸ“ æ­£åœ¨ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆå¤§çº²...',
                'content_writing': 'âœï¸ æ­£åœ¨æ’°å†™æ–¹æ¡ˆå†…å®¹...',
                'expert_review': 'ğŸ‘¨â€ğŸ”¬ ä¸“å®¶è¯„å®¡ä¸­...',
                'iteration': 'ğŸ”„ æ­£åœ¨è¿­ä»£ä¼˜åŒ–...',
                'complete': 'âœ… æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼'
            }

            # æµå¼è¿è¡Œ ProposalCrew
            for event in crew.run_stream(tender_doc, page_count):
                phase = event.get('phase', 'unknown')
                status = event.get('status', 'running')

                # å¤„ç†é”™è¯¯äº‹ä»¶
                if phase == 'error' or status == 'error':
                    error_data = {
                        'stage': 'error',
                        'status': 'error',
                        'progress': 0,
                        'error': event.get('error', 'æœªçŸ¥é”™è¯¯'),
                        'message': event.get('message', f"âŒ {event.get('error', 'æœªçŸ¥é”™è¯¯')}"),
                        'traceback': event.get('traceback', '')
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    return  # é‡åˆ°é”™è¯¯å°±åœæ­¢

                # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                sse_data = {
                    'stage': phase,
                    'phase': phase,  # åŒæ—¶ä¼ é€’ phase å­—æ®µä¾›å‰ç«¯ä½¿ç”¨
                    'status': status,
                    'progress': phase_progress.get(phase, 0),
                    'message': event.get('message') or phase_messages.get(phase, '')
                }

                # ========================================
                # ä¼ é€’ç»†ç²’åº¦è¿›åº¦è¯¦æƒ… (æ–°å¢)
                # ========================================
                if 'detail' in event:
                    sse_data['detail'] = event['detail']

                # ========================================
                # ä¼ é€’ç« èŠ‚æµå¼å†…å®¹é¢„è§ˆ (æ–°å¢)
                # ========================================
                if 'content' in event:
                    sse_data['content'] = event['content']

                # é™„åŠ é˜¶æ®µç‰¹å®šæ•°æ®
                if status == 'complete' and 'result' in event:
                    result = event['result']
                    sse_data['result'] = result  # åŒæ—¶ä¼ é€’åŸå§‹ result
                    if phase == 'scoring_extraction':
                        sse_data['scoring_points'] = result
                    elif phase == 'product_matching':
                        sse_data['product_match'] = result
                    elif phase == 'strategy_planning':
                        sse_data['scoring_strategy'] = result
                    elif phase == 'material_retrieval':
                        sse_data['materials'] = result
                    elif phase == 'outline_generation':
                        sse_data['outline_data'] = result
                        # å…¼å®¹ç°æœ‰å‰ç«¯
                        sse_data['stage'] = 'outline_completed'
                    elif phase == 'expert_review':
                        sse_data['review_result'] = result

                # å†…å®¹æ’°å†™çš„è¿›åº¦äº‹ä»¶
                if phase == 'content_writing' and event.get('event') == 'chapter_progress':
                    chapter_idx = event.get('chapter_index', 0)
                    total_chapters = event.get('total_chapters', 1)
                    sse_data['progress'] = 55 + int(chapter_idx / total_chapters * 20)
                    sse_data['chapter_title'] = event.get('chapter_title', '')
                    sse_data['event'] = 'chapter_progress'

                # ç« èŠ‚å®Œæˆäº‹ä»¶
                if phase == 'content_writing' and event.get('event') == 'chapter_complete':
                    sse_data['chapter'] = event.get('chapter')
                    sse_data['event'] = 'chapter_complete'

                yield f"data: {json.dumps(sse_data, ensure_ascii=False)}\n\n"

            # è·å–æœ€ç»ˆç»“æœ
            final_result = crew._build_final_result()

            if final_result.get('success'):
                # å¯¼å‡º Word æ–‡æ¡£
                from ai_tender_system.modules.outline_generator import WordExporter

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                # ä½¿ç”¨ç»Ÿä¸€çš„è¾“å‡ºç›®å½•å‡½æ•°ï¼Œç›´æ¥ä¿å­˜åˆ° tech_proposal_files/{å¹´}/{æœˆ}/{é¡¹ç›®ID}/
                output_dir = get_tech_proposal_output_dir(project_id)

                # æ–‡ä»¶å‘½åï¼šé¡¹ç›®ID_é¡¹ç›®åç§°_æŠ€æœ¯æ–¹æ¡ˆ_æ—¶é—´æˆ³.docxï¼ˆé¡¹ç›®IDç¡®ä¿å”¯ä¸€æ€§ï¼‰
                project_id_str = f"P{project_id}" if project_id and project_id != 'default' else ''
                name_part = project_name if project_name else 'æŠ€æœ¯æ–¹æ¡ˆ'
                proposal_filename = f"{project_id_str}_{name_part}_æŠ€æœ¯æ–¹æ¡ˆ_{timestamp}.docx" if project_id_str else f"{name_part}_{timestamp}.docx"
                proposal_path = output_dir / proposal_filename

                exporter = WordExporter()
                proposal_content = final_result.get('proposal_content', {})

                # è½¬æ¢ç« èŠ‚æ ¼å¼ä»¥åŒ¹é… WordExporter çš„æœŸæœ›
                def convert_chapter(chapter, prefix: str = '') -> dict:
                    """å°† ContentWriterAgent è¾“å‡ºè½¬æ¢ä¸º WordExporter æœŸæœ›çš„æ ¼å¼"""
                    # ç±»å‹å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ chapter æ˜¯å­—å…¸
                    if not isinstance(chapter, dict):
                        logger.warning(f"convert_chapter: æ”¶åˆ°éå­—å…¸ç±»å‹çš„chapter: {type(chapter)}")
                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        if isinstance(chapter, list) and len(chapter) > 0:
                            chapter = chapter[0] if isinstance(chapter[0], dict) else {}
                        else:
                            chapter = {}

                    # ç”Ÿæˆç« èŠ‚ç¼–å·
                    chapter_num = prefix or chapter.get('id', '') or ''

                    # å®‰å…¨æå– contentï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                    content = chapter.get('content', '')
                    if isinstance(content, dict):
                        content = content.get('content', '') or content.get('text', '') or str(content)
                    elif isinstance(content, list):
                        # å¦‚æœ content æ˜¯åˆ—è¡¨ï¼Œåˆå¹¶ä¸ºå­—ç¬¦ä¸²
                        content = '\n'.join(str(item) for item in content if item)
                    if not isinstance(content, str):
                        content = str(content) if content else ''

                    converted = {
                        'chapter_number': chapter_num,
                        'title': chapter.get('title', ''),
                        'level': chapter.get('level', 1),
                        'ai_generated_content': content,
                        'subsections': []
                    }

                    # é€’å½’è½¬æ¢å­ç« èŠ‚
                    children = chapter.get('children', [])
                    if isinstance(children, list):
                        for i, child in enumerate(children, 1):
                            child_prefix = f"{chapter_num}.{i}" if chapter_num else str(i)
                            converted['subsections'].append(convert_chapter(child, child_prefix))

                    return converted

                # è½¬æ¢æ‰€æœ‰ç« èŠ‚
                converted_chapters = []
                chapters_data = proposal_content.get('chapters', [])
                if isinstance(chapters_data, list):
                    for i, chapter in enumerate(chapters_data, 1):
                        converted_chapters.append(convert_chapter(chapter, str(i)))
                else:
                    logger.warning(f"proposal_content['chapters'] ä¸æ˜¯åˆ—è¡¨: {type(chapters_data)}")

                # æ„å»º WordExporter æœŸæœ›çš„æ•°æ®ç»“æ„ï¼ˆæ·»åŠ  metadataï¼‰
                proposal_for_export = {
                    'metadata': {
                        'title': project_name or 'Quality-FirstæŠ€æœ¯æ–¹æ¡ˆ',
                        'generation_time': timestamp,
                        'total_chapters': len(converted_chapters),
                        'estimated_pages': final_result.get('metadata', {}).get('total_words', 0) // 700
                    },
                    'chapters': converted_chapters
                }
                exporter.export_proposal(proposal_for_export, str(proposal_path), show_guidance=False)

                logger.info(f"ã€Quality-Firstã€‘å¯¼å‡ºå®Œæˆ: {proposal_path}")

                # å‘é€å®Œæˆäº‹ä»¶
                completed_data = {
                    'stage': 'completed',
                    'status': 'complete',
                    'progress': 100,
                    'success': True,
                    'message': 'âœ… Quality-First æŠ€æœ¯æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼',
                    'output_file': str(proposal_path),  # å®é™…æ–‡ä»¶ç³»ç»Ÿè·¯å¾„ï¼Œç”¨äºåŒæ­¥åˆ°HITL
                    'output_files': {
                        'proposal': f'/api/downloads/{proposal_filename}'  # ä¸‹è½½URL
                    },
                    'final_result': {
                        'total_words': final_result.get('metadata', {}).get('total_words', 0),
                        'chapter_count': final_result.get('metadata', {}).get('chapter_count', 0),
                        'final_score': final_result.get('metadata', {}).get('final_score', 0),
                        'pass_recommendation': final_result.get('metadata', {}).get('pass_recommendation', False),
                        'elapsed_time': final_result.get('elapsed_time', 0)
                    }
                }
                yield f"data: {json.dumps(completed_data, ensure_ascii=False)}\n\n"
            else:
                yield f"data: {json.dumps({'stage': 'error', 'status': 'error', 'error': final_result.get('error', 'æœªçŸ¥é”™è¯¯')}, ensure_ascii=False)}\n\n"

        except Exception as e:
            import traceback
            error_msg = str(e) if str(e) else 'æœªçŸ¥é”™è¯¯'
            error_trace = traceback.format_exc()
            logger.error(f"ã€Quality-First APIã€‘ç”Ÿæˆå¤±è´¥: {error_msg}\n{error_trace}")
            error_data = {
                'stage': 'error',
                'status': 'error',
                'progress': 0,
                'error': error_msg,
                'message': f'âŒ ç”Ÿæˆå¤±è´¥: {error_msg}',
                'traceback': error_trace[:500] if error_trace else ''  # æˆªæ–­é¿å…è¿‡é•¿
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

    return Response(
        stream_with_context(generate_events()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@api_outline_bp.route('/tech-proposal-files', methods=['GET'])
def list_tech_proposal_files():
    """
    è·å–æŠ€æœ¯æ–¹æ¡ˆæ–‡ä»¶åˆ—è¡¨

    æŸ¥è¯¢å‚æ•°:
    - project_id: é¡¹ç›®IDï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªè¿”å›è¯¥é¡¹ç›®çš„æ–‡ä»¶ï¼‰

    è¿”å›:
    {
        "success": true,
        "files": [
            {
                "filename": "xxx_æŠ€æœ¯æ–¹æ¡ˆ_20251222_110612_æŠ€æœ¯æ–¹æ¡ˆ.docx",
                "size": "46K",
                "date": "2025-12-22 11:06:12",
                "download_url": "/api/files/download/xxx.docx",
                "project_id": "61",
                "created": "2025-12-22T11:06:12",
                "modified": "2025-12-22T11:06:12"
            },
            ...
        ]
    }
    """
    try:
        import os
        from datetime import datetime

        def format_size(size_bytes):
            """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
            for unit in ['B', 'KB', 'MB', 'GB']:
                if size_bytes < 1024.0:
                    return f"{size_bytes:.1f} {unit}"
                size_bytes /= 1024.0
            return f"{size_bytes:.1f} TB"

        project_id = request.args.get('project_id')
        files = []

        # æŠ€æœ¯æ–¹æ¡ˆæ–‡ä»¶ä¿å­˜åœ¨ tech_proposal_files/{å¹´ä»½}/{æœˆä»½}/{é¡¹ç›®ID}/ ç›®å½•ä¸‹
        tech_proposal_base = config.get_path('upload') / 'tech_proposal_files'

        if tech_proposal_base.exists():
            # éå†å¹´ä»½ç›®å½•
            for year_dir in tech_proposal_base.glob('*'):
                if not year_dir.is_dir():
                    continue

                # éå†æœˆä»½ç›®å½•
                for month_dir in year_dir.glob('*'):
                    if not month_dir.is_dir():
                        continue

                    # éå†é¡¹ç›®ç›®å½•
                    for proj_dir in month_dir.glob('*'):
                        if not proj_dir.is_dir():
                            continue

                        # å¦‚æœæŒ‡å®šäº†project_id,åªå¤„ç†è¯¥é¡¹ç›®
                        if project_id and proj_dir.name != str(project_id):
                            continue

                        # éå†é¡¹ç›®ç›®å½•ä¸‹çš„æ–‡ä»¶
                        for file_path in proj_dir.glob('*.docx'):
                            try:
                                stat = file_path.stat()
                                modified_time = datetime.fromtimestamp(stat.st_mtime)

                                # æ„å»ºç›¸å¯¹äºuploadsç›®å½•çš„è·¯å¾„ç”¨äºä¸‹è½½
                                relative_path = file_path.relative_to(config.get_path('upload'))

                                files.append({
                                    'filename': file_path.name,
                                    'size': format_size(stat.st_size),
                                    'date': modified_time.strftime('%Y-%m-%d %H:%M:%S'),
                                    'download_url': f'/api/files/download/{file_path.name}',
                                    'file_path': str(file_path),  # å®Œæ•´è·¯å¾„ç”¨äºé¢„è§ˆ
                                    'project_id': proj_dir.name,
                                    'created': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                                    'modified': modified_time.isoformat()
                                })
                            except Exception as e:
                                logger.warning(f"è¯»å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")

        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        files.sort(key=lambda x: x.get('modified', ''), reverse=True)

        logger.info(f"æ‰¾åˆ°{len(files)}ä¸ªæŠ€æœ¯æ–¹æ¡ˆæ–‡ä»¶" + (f" (project_id={project_id})" if project_id else ""))

        return jsonify({'success': True, 'files': files})

    except Exception as e:
        logger.error(f"è·å–æŠ€æœ¯æ–¹æ¡ˆæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


# =========================
# ä»»åŠ¡ç®¡ç†APIï¼ˆæ–­ç‚¹ç»­ä¼ æ”¯æŒï¼‰
# =========================

@api_outline_bp.route('/tasks', methods=['GET'])
def list_tasks():
    """
    è·å–ä»»åŠ¡åˆ—è¡¨

    æŸ¥è¯¢å‚æ•°:
    - project_id: é¡¹ç›®IDï¼ˆå¯é€‰ï¼‰
    - status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼ˆå¯é€‰: pending/running/completed/failedï¼‰
    - limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤20ï¼‰

    è¿”å›:
    {
        "success": true,
        "tasks": [...],
        "total": 10
    }
    """
    try:
        from modules.outline_generator.task_manager import get_task_manager

        task_manager = get_task_manager()
        project_id = request.args.get('project_id', type=int)
        limit = request.args.get('limit', 20, type=int)

        if project_id:
            tasks = task_manager.get_tasks_by_project(project_id, limit=limit)
        else:
            # è·å–æ‰€æœ‰å¯æ¢å¤çš„ä»»åŠ¡
            tasks = task_manager.get_resumable_tasks()

        return jsonify({
            'success': True,
            'tasks': tasks,
            'total': len(tasks)
        })

    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


@api_outline_bp.route('/tasks/<task_id>', methods=['GET'])
def get_task_detail(task_id):
    """
    è·å–ä»»åŠ¡è¯¦æƒ…

    è¿”å›:
    {
        "success": true,
        "task": {...},
        "logs": [...],
        "stats": {...}
    }
    """
    try:
        from modules.outline_generator.task_manager import get_task_manager

        task_manager = get_task_manager()

        task = task_manager.get_task(task_id)
        if not task:
            return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        logs = task_manager.get_execution_logs(task_id)
        stats = task_manager.get_task_stats(task_id)

        return jsonify({
            'success': True,
            'task': task,
            'logs': logs,
            'stats': stats
        })

    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


@api_outline_bp.route('/tasks/<task_id>/resume', methods=['POST'])
def resume_task(task_id):
    """
    æ¢å¤ä»»åŠ¡æ‰§è¡Œ

    è¿”å›:
    {
        "success": true,
        "task_id": "xxx",
        "message": "ä»»åŠ¡å·²æ¢å¤ï¼Œè¯·è¿æ¥æµå¼æ¥å£è·å–è¿›åº¦"
    }
    """
    try:
        from modules.outline_generator.task_manager import get_task_manager

        task_manager = get_task_manager()

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¯æ¢å¤
        if not task_manager.can_resume(task_id):
            task = task_manager.get_task(task_id)
            if not task:
                return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
            return jsonify({
                'success': False,
                'error': f'ä»»åŠ¡çŠ¶æ€ä¸º {task.get("overall_status")}ï¼Œæ— æ³•æ¢å¤'
            }), 400

        return jsonify({
            'success': True,
            'task_id': task_id,
            'message': 'ä»»åŠ¡å·²å‡†å¤‡æ¢å¤ï¼Œè¯·è°ƒç”¨ /api/agent/generate-with-recovery æ¥å£'
        })

    except Exception as e:
        logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


@api_outline_bp.route('/tasks/<task_id>/cancel', methods=['POST'])
def cancel_task(task_id):
    """å–æ¶ˆä»»åŠ¡"""
    try:
        from modules.outline_generator.task_manager import get_task_manager

        task_manager = get_task_manager()

        if task_manager.cancel_task(task_id):
            return jsonify({'success': True, 'message': 'ä»»åŠ¡å·²å–æ¶ˆ'})
        else:
            return jsonify({'success': False, 'error': 'å–æ¶ˆå¤±è´¥'}), 400

    except Exception as e:
        logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


@api_outline_bp.route('/agent/generate-with-recovery', methods=['POST'])
def generate_with_recovery():
    """
    æ”¯æŒæ–­ç‚¹æ¢å¤çš„æŠ€æœ¯æ–¹æ¡ˆç”ŸæˆAPI

    è¯·æ±‚å‚æ•°:
    - task_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œç”¨äºæ¢å¤å·²æœ‰ä»»åŠ¡ï¼‰
    - tender_file: æ‹›æ ‡æ–‡ä»¶ï¼ˆæ–°ä»»åŠ¡å¿…éœ€ï¼‰
    - project_id: é¡¹ç›®ID
    - company_id: å…¬å¸ID
    - page_count: ç›®æ ‡é¡µæ•°
    - ai_model: AIæ¨¡å‹
    - crew_config: Crewé…ç½®ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰

    è¿”å›:
    SSEæµå¼å“åº”
    """
    try:
        from modules.outline_generator.task_manager import get_task_manager
        from modules.outline_generator.agents.proposal_crew import ProposalCrew, CrewConfig

        task_manager = get_task_manager()

        # è·å–å‚æ•°
        task_id = request.form.get('task_id')
        project_id = request.form.get('projectId', type=int)
        company_id = request.form.get('companyId', 1, type=int)
        page_count = request.form.get('page_count', 200, type=int)
        ai_model = request.form.get('aiModel', 'deepseek-v3')

        # Crewé…ç½®
        crew_config_str = request.form.get('crew_config', '{}')
        try:
            crew_config_dict = json.loads(crew_config_str)
        except:
            crew_config_dict = {}

        # å¤„ç†æ‹›æ ‡æ–‡ä»¶
        tender_doc = None
        tender_file_path = None

        if task_id:
            # æ¢å¤æ¨¡å¼ï¼šä»ä»»åŠ¡ä¸­è·å–æ–‡ä»¶è·¯å¾„
            task = task_manager.get_task(task_id)
            if not task:
                return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

            # å¹¶å‘é”ï¼šä½¿ç”¨åŸå­æ“ä½œæŠ¢å ä»»åŠ¡ï¼Œé˜²æ­¢é‡å¤æ¢å¤
            # åªæœ‰é running çŠ¶æ€æ‰èƒ½æŠ¢å 
            lock_acquired = task_manager.try_acquire_task_lock(task_id)
            if not lock_acquired:
                return jsonify({
                    'success': False,
                    'error': 'ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè¯·å‹¿é‡å¤æ“ä½œ'
                }), 409  # 409 Conflict

            tender_file_path = task.get('tender_file_path')
            if tender_file_path and Path(tender_file_path).exists():
                # è¯»å–æ–‡ä»¶å†…å®¹
                tender_doc = read_document_content(tender_file_path)
            else:
                # é‡Šæ”¾é”
                task_manager.fail_task(task_id, 'æ‹›æ ‡æ–‡ä»¶ä¸å­˜åœ¨')
                return jsonify({'success': False, 'error': 'æ‹›æ ‡æ–‡ä»¶ä¸å­˜åœ¨'}), 400

            project_id = task.get('project_id')
            company_id = task.get('company_id', 1)

        else:
            # æ–°ä»»åŠ¡æ¨¡å¼
            if 'tender_file' not in request.files:
                return jsonify({'success': False, 'error': 'ç¼ºå°‘æ‹›æ ‡æ–‡ä»¶'}), 400

            tender_file = request.files['tender_file']

            # ä¿å­˜æ–‡ä»¶
            upload_dir = config.get_path('upload') / 'tech_proposal_uploads'
            upload_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_name = secure_filename(tender_file.filename)
            saved_filename = f"{timestamp}_{safe_name}"
            tender_file_path = str(upload_dir / saved_filename)
            tender_file.save(tender_file_path)

            # è¯»å–æ–‡ä»¶å†…å®¹
            tender_doc = read_document_content(tender_file_path)

            # åˆ›å»ºæ–°ä»»åŠ¡
            task_id = task_manager.create_task(
                project_id=project_id or 0,
                company_id=company_id,
                generation_mode="quality_first",
                ai_model=ai_model,
                crew_config=crew_config_dict,
                tender_file_path=tender_file_path,
                page_count=page_count
            )

        if not tender_doc:
            return jsonify({'success': False, 'error': 'æ— æ³•è¯»å–æ‹›æ ‡æ–‡ä»¶å†…å®¹'}), 400

        # åˆ›å»ºCrewé…ç½®
        crew_config = CrewConfig(
            model_name=ai_model,
            company_id=company_id,
            skip_product_matching=crew_config_dict.get('skip_product_matching', False),
            skip_material_retrieval=crew_config_dict.get('skip_material_retrieval', False),
            enable_expert_review=crew_config_dict.get('enable_expert_review', True),
            max_iterations=crew_config_dict.get('max_iterations', 2),
            min_review_score=crew_config_dict.get('min_review_score', 70.0)
        )

        # åˆ›å»ºCrew
        crew = ProposalCrew(config=crew_config, task_manager=task_manager)

        def generate_events():
            try:
                # å‘é€ä»»åŠ¡ID
                yield f"data: {json.dumps({'stage': 'init', 'task_id': task_id, 'message': 'ä»»åŠ¡å·²åˆ›å»º'}, ensure_ascii=False)}\n\n"

                # ä½¿ç”¨æ”¯æŒæ¢å¤çš„æµå¼è¿è¡Œ
                for event in crew.run_stream_with_recovery(task_id, tender_doc, page_count):
                    phase = event.get('phase', 'unknown')
                    status = event.get('status', 'running')

                    # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                    sse_data = {
                        'stage': phase,
                        'phase': phase,  # åŒæ—¶ä¼ é€’ phase å­—æ®µä¾›å‰ç«¯ä½¿ç”¨
                        'status': status,
                        'task_id': task_id,
                        'message': event.get('message', ''),
                        'can_resume': event.get('can_resume', False)
                    }

                    # ä¼ é€’ç»†ç²’åº¦è¿›åº¦è¯¦æƒ… (æ–°å¢)
                    if 'detail' in event:
                        sse_data['detail'] = event['detail']

                    # ä¼ é€’ç« èŠ‚æµå¼å†…å®¹é¢„è§ˆ (æ–°å¢)
                    if 'content' in event:
                        sse_data['content'] = event['content']

                    # æ·»åŠ ç»“æœæ•°æ®
                    if 'result' in event:
                        sse_data['result'] = event['result']
                    if 'error' in event:
                        sse_data['error'] = event['error']

                    yield f"data: {json.dumps(sse_data, ensure_ascii=False)}\n\n"

            except Exception as e:
                import traceback
                error_msg = str(e) if str(e) else 'æœªçŸ¥é”™è¯¯'
                error_trace = traceback.format_exc()
                logger.error(f"ç”Ÿæˆå¤±è´¥: {error_msg}\n{error_trace}")

                yield f"data: {json.dumps({'stage': 'error', 'status': 'error', 'error': error_msg, 'task_id': task_id, 'can_resume': True}, ensure_ascii=False)}\n\n"

        return Response(
            stream_with_context(generate_events()),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        logger.error(f"ç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500


def read_document_content(file_path: str) -> str:
    """è¯»å–æ–‡æ¡£å†…å®¹"""
    try:
        from modules.outline_generator import RequirementAnalyzer

        # ä½¿ç”¨RequirementAnalyzerçš„æ–‡æ¡£è¯»å–åŠŸèƒ½
        analyzer = RequirementAnalyzer()

        # è§£ææ–‡æ¡£
        file_ext = Path(file_path).suffix.lower()
        if file_ext in ['.docx', '.doc']:
            return analyzer._read_docx(file_path)
        elif file_ext == '.pdf':
            return analyzer._read_pdf(file_path)
        elif file_ext in ['.xlsx', '.xls']:
            return analyzer._read_excel(file_path)
        else:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()

    except Exception as e:
        logger.error(f"è¯»å–æ–‡æ¡£å¤±è´¥: {e}")
        return None


# å¯¼å‡ºè“å›¾
__all__ = ['api_outline_bp']
