#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤æ¡ˆä¾‹é™„ä»¶è·¯å¾„å¹¶é‡æ–°è½¬æ¢å›¾ç‰‡
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
# __file__ = /path/to/ai_tender_system/scripts/fix_case_attachments_paths.py
# parent = /path/to/ai_tender_system/scripts
# parent.parent = /path/to/ai_tender_system
project_root = Path(__file__).parent.parent  # ai_tender_system ç›®å½•
sys.path.insert(0, str(project_root))

from common.database import get_knowledge_base_db
from common.logger import get_module_logger
from common.document_image_extractor import extract_images_from_document

logger = get_module_logger("fix_paths")

def fix_and_convert():
    """ä¿®å¤è·¯å¾„å¹¶è½¬æ¢"""
    db = get_knowledge_base_db()

    # æŸ¥è¯¢æ‰€æœ‰é™„ä»¶
    query = """
        SELECT attachment_id, case_id, original_filename, file_path, file_type, file_name
        FROM case_attachments
        WHERE file_type IN ('pdf', 'docx', 'doc')
        ORDER BY attachment_id
    """

    attachments = db.execute_query(query)

    logger.info(f"æ‰¾åˆ° {len(attachments)} ä¸ªé™„ä»¶è®°å½•")

    success_count = 0
    fixed_count = 0
    skip_count = 0

    for idx, att in enumerate(attachments, 1):
        attachment_id = att['attachment_id']
        original_filename = att['original_filename']
        file_path = att['file_path']
        file_name = att['file_name']

        logger.info(f"\n[{idx}/{len(attachments)}] æ£€æŸ¥: {original_filename} (ID: {attachment_id})")
        logger.info(f"  å½“å‰è·¯å¾„: {file_path}")

        # å°è¯•å¤šç§è·¯å¾„
        possible_paths = []

        # 1. åŸè·¯å¾„
        possible_paths.append(Path(file_path))

        # 2. å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ä½†é”™è¯¯ï¼Œå°è¯•æå–æ–‡ä»¶å
        if file_path.startswith('/Users/') or file_path.startswith('/var/www/'):
            filename = Path(file_path).name
            # åœ¨æ ‡å‡†ä½ç½®æŸ¥æ‰¾
            standard_path = project_root / 'data' / 'uploads' / 'case_attachments'
            for year_dir in standard_path.glob('*/'):
                for month_dir in year_dir.glob('*/'):
                    test_path = month_dir / filename
                    if test_path not in possible_paths:
                        possible_paths.append(test_path)

        # 3. ä½¿ç”¨file_nameå­—æ®µ
        if file_name:
            standard_path = project_root / 'data' / 'uploads' / 'case_attachments'
            for year_dir in standard_path.glob('*/'):
                for month_dir in year_dir.glob('*/'):
                    test_path = month_dir / file_name
                    if test_path not in possible_paths:
                        possible_paths.append(test_path)

        # 4. ç›¸å¯¹è·¯å¾„
        if not Path(file_path).is_absolute():
            possible_paths.append(project_root / file_path)

        # æŸ¥æ‰¾å­˜åœ¨çš„æ–‡ä»¶
        actual_file = None
        for test_path in possible_paths:
            if test_path.exists():
                actual_file = test_path
                break

        if not actual_file:
            logger.warning(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            skip_count += 1
            continue

        logger.info(f"  âœ… æ‰¾åˆ°æ–‡ä»¶: {actual_file}")

        # æ›´æ–°æ•°æ®åº“ä¸­çš„è·¯å¾„ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
        try:
            relative_path = actual_file.relative_to(project_root)
            new_path = str(relative_path)
        except ValueError:
            # å¦‚æœæ— æ³•è½¬ä¸ºç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
            new_path = str(actual_file)

        if new_path != file_path:
            logger.info(f"  ğŸ”§ æ›´æ–°è·¯å¾„: {new_path}")
            update_path_query = "UPDATE case_attachments SET file_path = ? WHERE attachment_id = ?"
            with db.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(update_path_query, (new_path, attachment_id))
                conn.commit()
            fixed_count += 1

        # æå–/è½¬æ¢å›¾ç‰‡
        try:
            logger.info(f"  ğŸ“¸ å¼€å§‹æå–å›¾ç‰‡...")
            result = extract_images_from_document(
                file_path=str(actual_file),
                base_name=f"case_{att['case_id']}_{actual_file.stem}",
                dpi=200
            )

            if result['success'] and result['images']:
                converted_images = result['images']
                conversion_info = result['conversion_info']

                logger.info(f"  âœ… æå–æˆåŠŸ: {len(converted_images)} å¼ å›¾ç‰‡")

                # æ›´æ–°æ•°æ®åº“
                update_query = """
                    UPDATE case_attachments
                    SET converted_images = ?,
                        conversion_info = ?,
                        conversion_date = ?,
                        original_file_type = ?
                    WHERE attachment_id = ?
                """

                update_values = (
                    json.dumps(converted_images, ensure_ascii=False),
                    json.dumps(conversion_info, ensure_ascii=False),
                    datetime.now(),
                    att['file_type'].upper(),
                    attachment_id
                )

                with db.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute(update_query, update_values)
                    conn.commit()

                success_count += 1
            else:
                logger.warning(f"  âš ï¸ æå–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        except Exception as e:
            logger.error(f"  âŒ å¤„ç†å¤±è´¥: {e}")

    # è¾“å‡ºç»Ÿè®¡
    logger.info("\n" + "=" * 60)
    logger.info("ä¿®å¤å’Œè½¬æ¢å®Œæˆ")
    logger.info("=" * 60)
    logger.info(f"  - æ€»è®°å½•æ•°: {len(attachments)}")
    logger.info(f"  - è·¯å¾„ä¿®å¤: {fixed_count}")
    logger.info(f"  - è½¬æ¢æˆåŠŸ: {success_count}")
    logger.info(f"  - æ–‡ä»¶ä¸å­˜åœ¨: {skip_count}")
    logger.info("=" * 60)


if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("ä¿®å¤æ¡ˆä¾‹é™„ä»¶è·¯å¾„å¹¶è½¬æ¢å›¾ç‰‡")
    logger.info("=" * 60)
    fix_and_convert()
