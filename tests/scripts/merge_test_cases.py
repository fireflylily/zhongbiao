#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆå¹¶æµ‹è¯•ç”¨ä¾‹JSONæ–‡ä»¶

ç”¨é€”:
- å°†è‡ªåŠ¨æå–çš„æµ‹è¯•ç”¨ä¾‹åˆå¹¶åˆ°ä¸»JSONæ–‡ä»¶
- è‡ªåŠ¨å»é‡(åŸºäºfield_alias)
- ä¿ç•™æ¥æºä¿¡æ¯

ä½¿ç”¨æ–¹æ³•:
    python tests/scripts/merge_test_cases.py

ä½œè€…:AI Tender System
æ—¥æœŸ:2025-12-02
"""

import json
import sys
from pathlib import Path
from datetime import datetime


def load_json(file_path):
    """åŠ è½½JSONæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_json(data, file_path):
    """ä¿å­˜JSONæ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def merge_test_cases(main_file, extracted_file, output_file):
    """åˆå¹¶æµ‹è¯•ç”¨ä¾‹"""

    print("=" * 70)
    print("ğŸ“¥ åˆå¹¶æµ‹è¯•ç”¨ä¾‹")
    print("=" * 70)
    print()

    # åŠ è½½ä¸¤ä¸ªJSONæ–‡ä»¶
    print(f"ğŸ“– åŠ è½½ä¸»æ–‡ä»¶: {main_file.name}")
    main_data = load_json(main_file)

    print(f"ğŸ“– åŠ è½½æå–æ–‡ä»¶: {extracted_file.name}")
    extracted_data = load_json(extracted_file)

    # ç»Ÿè®¡ä¿¡æ¯
    main_count_before = sum(len(suite['test_cases']) for suite in main_data['test_suites'].values())
    extracted_count = sum(len(suite['test_cases']) for suite in extracted_data['test_suites'].values())

    print(f"ğŸ“Š ä¸»æ–‡ä»¶ç°æœ‰æµ‹è¯•ç”¨ä¾‹: {main_count_before} ä¸ª")
    print(f"ğŸ“Š æå–æ–‡ä»¶æµ‹è¯•ç”¨ä¾‹: {extracted_count} ä¸ª")
    print()

    # åˆå¹¶æµ‹è¯•å¥—ä»¶
    merged_count = 0
    duplicate_count = 0

    # æ”¶é›†æ‰€æœ‰å·²å­˜åœ¨çš„field_alias (ç”¨äºå»é‡)
    existing_fields = set()
    for suite_data in main_data['test_suites'].values():
        for test_case in suite_data['test_cases']:
            if 'field_alias' in test_case:
                existing_fields.add(test_case['field_alias'])

    # åˆå¹¶æå–çš„æµ‹è¯•å¥—ä»¶
    for suite_name, suite_data in extracted_data['test_suites'].items():
        # æ˜ å°„æå–çš„å¥—ä»¶ååˆ°ä¸»æ–‡ä»¶çš„å¥—ä»¶å
        # ä¾‹å¦‚: field_recognition_company_name_extracted -> field_recognition_company
        base_suite_name = suite_name.replace('_extracted', '').replace('_name', '')

        # å¦‚æœä¸»æ–‡ä»¶ä¸­ä¸å­˜åœ¨è¿™ä¸ªå¥—ä»¶,åˆ›å»ºå®ƒ
        if base_suite_name not in main_data['test_suites']:
            # å°è¯•æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å¥—ä»¶
            similar_suites = []
            for s in main_data['test_suites'].keys():
                parts_s = s.split('_')
                parts_suite = suite_name.split('_')
                if len(parts_s) >= 3 and len(parts_suite) >= 3 and parts_s[2] == parts_suite[2]:
                    similar_suites.append(s)

            if similar_suites:
                base_suite_name = similar_suites[0]
            else:
                # åˆ›å»ºæ–°å¥—ä»¶
                main_data['test_suites'][base_suite_name] = {
                    "description": suite_data['description'],
                    "test_cases": []
                }

        # åˆå¹¶æµ‹è¯•ç”¨ä¾‹
        for test_case in suite_data['test_cases']:
            field_alias = test_case.get('field_alias')

            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if field_alias in existing_fields:
                duplicate_count += 1
                print(f"  âš ï¸  è·³è¿‡é‡å¤å­—æ®µ: {field_alias}")
                continue

            # æ·»åŠ åˆ°ä¸»æ–‡ä»¶
            main_data['test_suites'][base_suite_name]['test_cases'].append(test_case)
            existing_fields.add(field_alias)
            merged_count += 1
            print(f"  âœ“ æ·»åŠ æ–°å­—æ®µ: {field_alias} -> {base_suite_name}")

    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    main_count_after = sum(len(suite['test_cases']) for suite in main_data['test_suites'].values())

    main_data['version'] = '2.0'
    main_data['last_updated'] = datetime.now().strftime('%Y-%m-%d')

    # æ›´æ–°source_statistics
    if 'source_statistics' not in main_data:
        main_data['source_statistics'] = {}

    main_data['source_statistics']['total_cases'] = main_count_after
    main_data['source_statistics']['by_source_type'] = {
        'manual': main_count_before,
        'template': merged_count,
        'user_feedback': 0
    }

    # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    print()
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")
    save_json(main_data, output_file)

    # æ˜¾ç¤ºç»Ÿè®¡
    print()
    print("=" * 70)
    print("âœ… åˆå¹¶å®Œæˆï¼")
    print("=" * 70)
    print(f"ğŸ“Š åˆå¹¶å‰æµ‹è¯•ç”¨ä¾‹æ•°: {main_count_before}")
    print(f"â• æ–°å¢æµ‹è¯•ç”¨ä¾‹æ•°: {merged_count}")
    print(f"âŠ—  è·³è¿‡é‡å¤ç”¨ä¾‹æ•°: {duplicate_count}")
    print(f"ğŸ“Š åˆå¹¶åæµ‹è¯•ç”¨ä¾‹æ•°: {main_count_after}")
    print()
    print("ğŸ“ åç»­æ­¥éª¤:")
    print("  1. æŸ¥çœ‹åˆå¹¶ç»“æœ: cat tests/data/business_response_test_cases.json")
    print("  2. è¿è¡Œæµ‹è¯•éªŒè¯: pytest tests/unit/modules/test_business_response_text_filling.py -v")
    print("=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent.parent.parent
    main_file = base_dir / "tests" / "data" / "business_response_test_cases.json"
    extracted_file = base_dir / "tests" / "data" / "business_response_test_cases_extracted.json"
    output_file = main_file  # ç›´æ¥è¦†ç›–ä¸»æ–‡ä»¶

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not main_file.exists():
        print(f"âŒ ä¸»æ–‡ä»¶ä¸å­˜åœ¨: {main_file}")
        sys.exit(1)

    if not extracted_file.exists():
        print(f"âŒ æå–æ–‡ä»¶ä¸å­˜åœ¨: {extracted_file}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python tests/scripts/extract_test_cases_from_templates.py")
        sys.exit(1)

    # å¤‡ä»½ä¸»æ–‡ä»¶
    backup_file = main_file.with_suffix('.json.backup')
    print(f"ğŸ’¾ å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_file}")
    import shutil
    shutil.copy(main_file, backup_file)

    # åˆå¹¶
    merge_test_cases(main_file, extracted_file, output_file)


if __name__ == "__main__":
    main()
