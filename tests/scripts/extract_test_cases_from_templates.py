#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»å•†åŠ¡åº”ç­”æ¨¡æ¿è‡ªåŠ¨æå–æµ‹è¯•ç”¨ä¾‹

ç”¨é€”:
- æ‰«æ ai_tender_system/data/uploads/response_files/ ç›®å½•
- æå–æ‰€æœ‰æ‹¬å·å­—æ®µ
- è‡ªåŠ¨åˆ†ç±»å¹¶ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹JSON

ä½¿ç”¨æ–¹æ³•:
    python tests/scripts/extract_test_cases_from_templates.py

è¾“å‡º:
    tests/data/business_response_test_cases_extracted.json (ä¸è¦†ç›–åŸæ–‡ä»¶)

ä½œè€…:AI Tender System
æ—¥æœŸ:2025-12-02
"""

import re
import json
import sys
from pathlib import Path
from datetime import datetime
from collections import defaultdict

try:
    from docx import Document
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–åŒ…ï¼Œè¯·å…ˆå®‰è£…ï¼š")
    print("   pip install python-docx")
    sys.exit(1)


class TemplateFieldExtractor:
    """æ¨¡æ¿å­—æ®µæå–å™¨"""

    # å­—æ®µåˆ†ç±»è§„åˆ™ (å…³é”®è¯åŒ¹é…)
    FIELD_CATEGORIES = {
        'company_name': ['ä¾›åº”å•†', 'å…¬å¸', 'å•ä½', 'ä¼ä¸š', 'åº”ç­”äºº', 'å“åº”æ–¹', 'æŠ•æ ‡äºº'],
        'address': ['åœ°å€'],
        'legal_person': ['æ³•å®šä»£è¡¨äºº', 'æ³•äºº', 'è´Ÿè´£äºº'],
        'representative': ['æˆæƒ', 'ä»£è¡¨', 'å§”æ‰˜', 'è¢«æˆæƒäºº'],
        'date': ['æ—¥æœŸ', 'å¹´', 'æœˆ', 'æ—¥'],
        'phone': ['ç”µè¯', 'è”ç³»æ–¹å¼', 'æ‰‹æœº'],
        'email': ['é‚®ç®±', 'email', 'Email', 'E-mail'],
    }

    # éœ€è¦è¿‡æ»¤çš„å™ªéŸ³å…³é”®è¯
    NOISE_KEYWORDS = [
        'å¯é€‰', 'å¦‚æœ‰', 'é€‰å¡«', 'å¿…å¡«', 'åŠ ç›–', 'ç›–ç« ', 'ç­¾å­—',
        'å°åˆ·ä½“', 'å¤å°ä»¶', 'åŸä»¶', 'ä»½', 'é¡µ', 'é¡¹', 'æ ',
        'æ ¼å¼', 'è¦æ±‚', 'è¯´æ˜', 'æ³¨', 'http', 'www', 'æŸ¥è¯¢',
        'æˆªå›¾', 'æŠ¥å‘Š', 'è¯æ˜', 'ææ–™', 'æ–‡ä»¶', 'é™„ä»¶'
    ]

    def __init__(self, template_dir):
        self.template_dir = Path(template_dir)
        self.all_fields = defaultdict(list)  # category -> [(field, source_info), ...]
        self.field_to_sources = defaultdict(list)  # field -> [source_info, ...]

    def is_noise_field(self, field):
        """åˆ¤æ–­æ˜¯å¦æ˜¯å™ªéŸ³å­—æ®µ"""
        # è¿‡æ»¤çº¯æ•°å­—
        if field.isdigit():
            return True

        # è¿‡æ»¤å¤ªé•¿çš„å­—æ®µ (è¶…è¿‡50ä¸ªå­—ç¬¦)
        if len(field) > 50:
            return True

        # è¿‡æ»¤åŒ…å«å™ªéŸ³å…³é”®è¯çš„å­—æ®µ
        for noise in self.NOISE_KEYWORDS:
            if noise in field:
                return True

        return False

    def extract_project_name(self, doc):
        """ä»æ–‡æ¡£ä¸­æå–é¡¹ç›®åç§°"""
        # å°è¯•ä»å‰å‡ æ®µæ‰¾åˆ°"é¡¹ç›®åç§°"
        for para in doc.paragraphs[:20]:
            text = para.text.strip()
            if 'é¡¹ç›®åç§°' in text:
                # æå–é¡¹ç›®åç§°
                match = re.search(r'é¡¹ç›®åç§°[ï¼š:]\s*(.+?)[\nï¼Œ,]?', text)
                if match:
                    return match.group(1).strip()

        return "æœªçŸ¥é¡¹ç›®"

    def extract_from_docx(self, docx_path):
        """ä»å•ä¸ªdocxæå–å­—æ®µ"""
        try:
            doc = Document(docx_path)
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•è¯»å– {docx_path.name}: {e}")
            return []

        # æå–é¡¹ç›®ä¿¡æ¯
        path_parts = docx_path.parts
        project_id = path_parts[-2] if len(path_parts) >= 2 else "unknown"
        project_name = self.extract_project_name(doc)

        # æ‹¬å·æ¨¡å¼
        patterns = [
            r'\(([^)]+)\)',   # è‹±æ–‡æ‹¬å·
            r'ï¼ˆ([^ï¼‰]+)ï¼‰',   # ä¸­æ–‡æ‹¬å·
            r'\[([^\]]+)\]',  # æ–¹æ‹¬å·
        ]

        extracted_fields = []
        for para_idx, para in enumerate(doc.paragraphs):
            for pattern in patterns:
                matches = re.findall(pattern, para.text)
                for match in matches:
                    field = match.strip()

                    # è¿‡æ»¤å™ªéŸ³
                    if self.is_noise_field(field):
                        continue

                    source_info = {
                        "type": "template",
                        "project_name": project_name,
                        "project_id": project_id,
                        "template_file": docx_path.name,
                        "template_path": str(docx_path.relative_to(Path.cwd())),
                        "paragraph_index": para_idx,
                        "extracted_date": datetime.now().strftime("%Y-%m-%d"),
                        "extract_method": "auto"
                    }

                    extracted_fields.append((field, source_info))

        return extracted_fields

    def classify_field(self, field):
        """åˆ†ç±»å­—æ®µ"""
        field_lower = field.lower()

        for category, keywords in self.FIELD_CATEGORIES.items():
            for keyword in keywords:
                if keyword in field:
                    return category

        return None  # è¿”å›Noneè¡¨ç¤ºæ— æ³•åˆ†ç±»

    def map_to_standard_field(self, category):
        """æ˜ å°„åˆ°æ ‡å‡†å­—æ®µå"""
        mapping = {
            'company_name': 'companyName',
            'address': 'address',
            'legal_person': 'legalRepresentative',
            'representative': 'representativeName',
            'date': 'date',
            'phone': 'phone',
            'email': 'email',
        }
        return mapping.get(category)

    def scan_all_templates(self, max_files=50):
        """æ‰«ææ‰€æœ‰æ¨¡æ¿"""
        docx_files = list(self.template_dir.rglob('*.docx'))

        # è¿‡æ»¤ä¸´æ—¶æ–‡ä»¶
        docx_files = [f for f in docx_files if not f.name.startswith('~$')]

        print(f"ğŸ“‚ æ‰¾åˆ° {len(docx_files)} ä¸ªæ¨¡æ¿æ–‡ä»¶")

        if len(docx_files) > max_files:
            print(f"âš ï¸  æ–‡ä»¶æ•°é‡è¿‡å¤šï¼Œåªå¤„ç†æœ€æ–°çš„ {max_files} ä¸ªæ–‡ä»¶")
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
            docx_files = sorted(docx_files, key=lambda f: f.stat().st_mtime, reverse=True)[:max_files]

        total_extracted = 0
        for docx_file in docx_files:
            print(f"  ğŸ“„ å¤„ç†: {docx_file.name}")
            fields = self.extract_from_docx(docx_file)

            for field, source_info in fields:
                category = self.classify_field(field)
                if category:
                    self.all_fields[category].append((field, source_info))
                    self.field_to_sources[field].append(source_info)
                    total_extracted += 1

        print(f"âœ… æå–å®Œæˆï¼Œå…± {total_extracted} ä¸ªå­—æ®µ(å·²åˆ†ç±»)")
        print(f"ğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        for category, fields in self.all_fields.items():
            print(f"   - {category}: {len(fields)} ä¸ª")

    def generate_test_cases_json(self):
        """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹JSON"""
        test_suites = {}

        # ä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆæµ‹è¯•å¥—ä»¶
        for category, field_list in self.all_fields.items():
            std_field = self.map_to_standard_field(category)
            if not std_field:
                continue

            # å»é‡ï¼šä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„å­—æ®µ
            seen_fields = {}
            for field, source_info in field_list:
                if field not in seen_fields:
                    seen_fields[field] = source_info

            test_cases = []
            for idx, (field, source_info) in enumerate(seen_fields.items(), 1):
                test_cases.append({
                    "id": f"{category}_{idx:03d}_auto",
                    "field_alias": field,
                    "expected_standard_field": std_field,
                    "note": f"ä»{source_info['project_name']}æ¨¡æ¿è‡ªåŠ¨æå–",
                    "source": source_info
                })

            if test_cases:
                test_suites[f"field_recognition_{category}_extracted"] = {
                    "description": f"{category}å­—æ®µè¯†åˆ«æµ‹è¯•(ä»æ¨¡æ¿è‡ªåŠ¨æå–)",
                    "test_cases": test_cases
                }

        # ç»Ÿè®¡ä¿¡æ¯
        total_cases = sum(len(suite['test_cases']) for suite in test_suites.values())
        by_source_type = {"template": total_cases}

        # æŒ‰é¡¹ç›®ç»Ÿè®¡
        by_project = defaultdict(int)
        for category_fields in self.all_fields.values():
            for field, source_info in category_fields:
                by_project[source_info['project_name']] += 1

        return {
            "version": "2.0-extracted",
            "last_updated": datetime.now().strftime("%Y-%m-%d"),
            "description": "ä»å•†åŠ¡åº”ç­”æ¨¡æ¿è‡ªåŠ¨æå–çš„æµ‹è¯•ç”¨ä¾‹",
            "extraction_info": {
                "extraction_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "template_count": len(list(self.template_dir.rglob('*.docx'))),
                "extracted_fields": total_cases
            },
            "test_suites": test_suites,
            "source_statistics": {
                "total_cases": total_cases,
                "by_source_type": by_source_type,
                "by_project": dict(by_project)
            }
        }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ“¤ ä»å•†åŠ¡åº”ç­”æ¨¡æ¿æå–æµ‹è¯•ç”¨ä¾‹")
    print("=" * 70)
    print()

    # è·¯å¾„é…ç½®
    base_dir = Path(__file__).parent.parent.parent
    template_dir = base_dir / "ai_tender_system" / "data" / "uploads" / "response_files"
    output_file = base_dir / "tests" / "data" / "business_response_test_cases_extracted.json"

    # æ£€æŸ¥æ¨¡æ¿ç›®å½•æ˜¯å¦å­˜åœ¨
    if not template_dir.exists():
        print(f"âŒ æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {template_dir}")
        sys.exit(1)

    # åˆ›å»ºæå–å™¨
    extractor = TemplateFieldExtractor(template_dir)

    # æ‰«ææ¨¡æ¿
    extractor.scan_all_templates(max_files=20)  # é™åˆ¶æœ€å¤šå¤„ç†20ä¸ªæ–‡ä»¶

    # ç”ŸæˆJSON
    print()
    print("ğŸ“ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹JSON...")
    test_cases_json = extractor.generate_test_cases_json()

    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(test_cases_json, f, ensure_ascii=False, indent=2)

    print(f"âœ… å·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š æ€»è®¡æå– {test_cases_json['source_statistics']['total_cases']} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print()
    print("ğŸ“‹ æµ‹è¯•å¥—ä»¶:")
    for suite_name, suite_data in test_cases_json['test_suites'].items():
        print(f"   - {suite_name}: {len(suite_data['test_cases'])} ä¸ªç”¨ä¾‹")

    print()
    print("=" * 70)
    print("âœ… æå–å®Œæˆï¼")
    print()
    print("ğŸ“ åç»­æ­¥éª¤:")
    print("  1. æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶: cat tests/data/business_response_test_cases_extracted.json")
    print("  2. äººå·¥å®¡æ ¸æµ‹è¯•ç”¨ä¾‹,ç¡®è®¤åˆ†ç±»æ­£ç¡®")
    print("  3. åˆå¹¶åˆ°ä¸»æ–‡ä»¶: python tests/scripts/merge_test_cases.py")
    print("=" * 70)


if __name__ == "__main__":
    main()
